{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a2c9947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv, re, argparse, sys, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "import pickle\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "import pickle\n",
    "import unicodedata\n",
    "import requests\n",
    "from io import BytesIO  # [FIX] load_image_any 需要 BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c77ab0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved offsets_for_tf.csv  rows=29\n",
      "Columns: ['image_id', 'title_len', 'bullets_len', 'bullets_lines', 'vip_digits', 'unit_digits', 'nonvip_digits', 'has_badge', 'Sales Period Position_dx', 'Sales Period Position_dy', 'Sales Period Position_dlogw', 'Sales Period Position_dlogh', 'Brand Position_dx', 'Brand Position_dy', 'Brand Position_dlogw', 'Brand Position_dlogh', 'Product Position_dx', 'Product Position_dy', 'Product Position_dlogw', 'Product Position_dlogh', 'FAB Position_dx', 'FAB Position_dy', 'FAB Position_dlogw', 'FAB Position_dlogh', 'Product Image Position_dx', 'Product Image Position_dy', 'Product Image Position_dlogw', 'Product Image Position_dlogh', 'VIP Price Position_dx', 'VIP Price Position_dy', 'VIP Price Position_dlogw', 'VIP Price Position_dlogh', 'Non VIP Price Position_dx', 'Non VIP Price Position_dy', 'Non VIP Price Position_dlogw', 'Non VIP Price Position_dlogh', 'Original Price Position_dx', 'Original Price Position_dy', 'Original Price Position_dlogw', 'Original Price Position_dlogh', 'Icon Position_dx', 'Icon Position_dy', 'Icon Position_dlogw', 'Icon Position_dlogh']\n",
      "[INFO] Saved class order -> offsets_for_tf.classes.json\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/boardclick/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0680 - mean_absolute_error: 0.1592 - mean_squared_error: 0.0680 - val_loss: 0.0647 - val_mean_absolute_error: 0.1542 - val_mean_squared_error: 0.0647\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0675 - mean_absolute_error: 0.1581 - mean_squared_error: 0.0675 - val_loss: 0.0643 - val_mean_absolute_error: 0.1535 - val_mean_squared_error: 0.0643\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0670 - mean_absolute_error: 0.1571 - mean_squared_error: 0.0670 - val_loss: 0.0639 - val_mean_absolute_error: 0.1528 - val_mean_squared_error: 0.0639\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0665 - mean_absolute_error: 0.1561 - mean_squared_error: 0.0665 - val_loss: 0.0634 - val_mean_absolute_error: 0.1523 - val_mean_squared_error: 0.0634\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0661 - mean_absolute_error: 0.1552 - mean_squared_error: 0.0661 - val_loss: 0.0630 - val_mean_absolute_error: 0.1518 - val_mean_squared_error: 0.0630\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0656 - mean_absolute_error: 0.1545 - mean_squared_error: 0.0656 - val_loss: 0.0626 - val_mean_absolute_error: 0.1514 - val_mean_squared_error: 0.0626\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0651 - mean_absolute_error: 0.1538 - mean_squared_error: 0.0651 - val_loss: 0.0622 - val_mean_absolute_error: 0.1509 - val_mean_squared_error: 0.0622\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0647 - mean_absolute_error: 0.1531 - mean_squared_error: 0.0647 - val_loss: 0.0618 - val_mean_absolute_error: 0.1504 - val_mean_squared_error: 0.0618\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0642 - mean_absolute_error: 0.1524 - mean_squared_error: 0.0642 - val_loss: 0.0614 - val_mean_absolute_error: 0.1499 - val_mean_squared_error: 0.0614\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0638 - mean_absolute_error: 0.1517 - mean_squared_error: 0.0638 - val_loss: 0.0610 - val_mean_absolute_error: 0.1493 - val_mean_squared_error: 0.0610\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0634 - mean_absolute_error: 0.1510 - mean_squared_error: 0.0634 - val_loss: 0.0606 - val_mean_absolute_error: 0.1488 - val_mean_squared_error: 0.0606\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0630 - mean_absolute_error: 0.1503 - mean_squared_error: 0.0630 - val_loss: 0.0602 - val_mean_absolute_error: 0.1483 - val_mean_squared_error: 0.0602\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0625 - mean_absolute_error: 0.1497 - mean_squared_error: 0.0625 - val_loss: 0.0598 - val_mean_absolute_error: 0.1478 - val_mean_squared_error: 0.0598\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0621 - mean_absolute_error: 0.1491 - mean_squared_error: 0.0621 - val_loss: 0.0595 - val_mean_absolute_error: 0.1473 - val_mean_squared_error: 0.0595\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0617 - mean_absolute_error: 0.1485 - mean_squared_error: 0.0617 - val_loss: 0.0591 - val_mean_absolute_error: 0.1468 - val_mean_squared_error: 0.0591\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0613 - mean_absolute_error: 0.1479 - mean_squared_error: 0.0613 - val_loss: 0.0587 - val_mean_absolute_error: 0.1463 - val_mean_squared_error: 0.0587\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0609 - mean_absolute_error: 0.1473 - mean_squared_error: 0.0609 - val_loss: 0.0584 - val_mean_absolute_error: 0.1457 - val_mean_squared_error: 0.0584\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0605 - mean_absolute_error: 0.1467 - mean_squared_error: 0.0605 - val_loss: 0.0580 - val_mean_absolute_error: 0.1452 - val_mean_squared_error: 0.0580\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0601 - mean_absolute_error: 0.1462 - mean_squared_error: 0.0601 - val_loss: 0.0577 - val_mean_absolute_error: 0.1447 - val_mean_squared_error: 0.0577\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0598 - mean_absolute_error: 0.1456 - mean_squared_error: 0.0598 - val_loss: 0.0573 - val_mean_absolute_error: 0.1443 - val_mean_squared_error: 0.0573\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0594 - mean_absolute_error: 0.1450 - mean_squared_error: 0.0594 - val_loss: 0.0570 - val_mean_absolute_error: 0.1438 - val_mean_squared_error: 0.0570\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0590 - mean_absolute_error: 0.1445 - mean_squared_error: 0.0590 - val_loss: 0.0566 - val_mean_absolute_error: 0.1433 - val_mean_squared_error: 0.0566\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0586 - mean_absolute_error: 0.1439 - mean_squared_error: 0.0586 - val_loss: 0.0563 - val_mean_absolute_error: 0.1428 - val_mean_squared_error: 0.0563\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0583 - mean_absolute_error: 0.1434 - mean_squared_error: 0.0583 - val_loss: 0.0559 - val_mean_absolute_error: 0.1424 - val_mean_squared_error: 0.0559\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0579 - mean_absolute_error: 0.1428 - mean_squared_error: 0.0579 - val_loss: 0.0556 - val_mean_absolute_error: 0.1419 - val_mean_squared_error: 0.0556\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0576 - mean_absolute_error: 0.1423 - mean_squared_error: 0.0576 - val_loss: 0.0553 - val_mean_absolute_error: 0.1415 - val_mean_squared_error: 0.0553\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0572 - mean_absolute_error: 0.1418 - mean_squared_error: 0.0572 - val_loss: 0.0550 - val_mean_absolute_error: 0.1410 - val_mean_squared_error: 0.0550\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0569 - mean_absolute_error: 0.1413 - mean_squared_error: 0.0569 - val_loss: 0.0546 - val_mean_absolute_error: 0.1407 - val_mean_squared_error: 0.0546\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0565 - mean_absolute_error: 0.1408 - mean_squared_error: 0.0565 - val_loss: 0.0543 - val_mean_absolute_error: 0.1403 - val_mean_squared_error: 0.0543\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0562 - mean_absolute_error: 0.1404 - mean_squared_error: 0.0562 - val_loss: 0.0540 - val_mean_absolute_error: 0.1400 - val_mean_squared_error: 0.0540\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0559 - mean_absolute_error: 0.1399 - mean_squared_error: 0.0559 - val_loss: 0.0537 - val_mean_absolute_error: 0.1396 - val_mean_squared_error: 0.0537\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0555 - mean_absolute_error: 0.1395 - mean_squared_error: 0.0555 - val_loss: 0.0534 - val_mean_absolute_error: 0.1392 - val_mean_squared_error: 0.0534\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0552 - mean_absolute_error: 0.1390 - mean_squared_error: 0.0552 - val_loss: 0.0531 - val_mean_absolute_error: 0.1389 - val_mean_squared_error: 0.0531\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0549 - mean_absolute_error: 0.1386 - mean_squared_error: 0.0549 - val_loss: 0.0528 - val_mean_absolute_error: 0.1385 - val_mean_squared_error: 0.0528\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0546 - mean_absolute_error: 0.1381 - mean_squared_error: 0.0546 - val_loss: 0.0525 - val_mean_absolute_error: 0.1382 - val_mean_squared_error: 0.0525\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0543 - mean_absolute_error: 0.1377 - mean_squared_error: 0.0543 - val_loss: 0.0522 - val_mean_absolute_error: 0.1378 - val_mean_squared_error: 0.0522\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0540 - mean_absolute_error: 0.1372 - mean_squared_error: 0.0540 - val_loss: 0.0519 - val_mean_absolute_error: 0.1375 - val_mean_squared_error: 0.0519\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0537 - mean_absolute_error: 0.1368 - mean_squared_error: 0.0537 - val_loss: 0.0517 - val_mean_absolute_error: 0.1371 - val_mean_squared_error: 0.0517\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0534 - mean_absolute_error: 0.1363 - mean_squared_error: 0.0534 - val_loss: 0.0514 - val_mean_absolute_error: 0.1368 - val_mean_squared_error: 0.0514\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0531 - mean_absolute_error: 0.1359 - mean_squared_error: 0.0531 - val_loss: 0.0511 - val_mean_absolute_error: 0.1364 - val_mean_squared_error: 0.0511\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0528 - mean_absolute_error: 0.1355 - mean_squared_error: 0.0528 - val_loss: 0.0508 - val_mean_absolute_error: 0.1361 - val_mean_squared_error: 0.0508\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0525 - mean_absolute_error: 0.1351 - mean_squared_error: 0.0525 - val_loss: 0.0506 - val_mean_absolute_error: 0.1358 - val_mean_squared_error: 0.0506\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0522 - mean_absolute_error: 0.1347 - mean_squared_error: 0.0522 - val_loss: 0.0503 - val_mean_absolute_error: 0.1354 - val_mean_squared_error: 0.0503\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0519 - mean_absolute_error: 0.1343 - mean_squared_error: 0.0519 - val_loss: 0.0500 - val_mean_absolute_error: 0.1350 - val_mean_squared_error: 0.0500\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0516 - mean_absolute_error: 0.1339 - mean_squared_error: 0.0516 - val_loss: 0.0498 - val_mean_absolute_error: 0.1347 - val_mean_squared_error: 0.0498\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0513 - mean_absolute_error: 0.1335 - mean_squared_error: 0.0513 - val_loss: 0.0495 - val_mean_absolute_error: 0.1343 - val_mean_squared_error: 0.0495\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0511 - mean_absolute_error: 0.1331 - mean_squared_error: 0.0511 - val_loss: 0.0493 - val_mean_absolute_error: 0.1340 - val_mean_squared_error: 0.0493\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0508 - mean_absolute_error: 0.1327 - mean_squared_error: 0.0508 - val_loss: 0.0490 - val_mean_absolute_error: 0.1337 - val_mean_squared_error: 0.0490\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0505 - mean_absolute_error: 0.1323 - mean_squared_error: 0.0505 - val_loss: 0.0488 - val_mean_absolute_error: 0.1334 - val_mean_squared_error: 0.0488\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0503 - mean_absolute_error: 0.1320 - mean_squared_error: 0.0503 - val_loss: 0.0485 - val_mean_absolute_error: 0.1331 - val_mean_squared_error: 0.0485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Predicted offsets (sample): [[ 0.02965896 -0.00730552 -0.08992435 -0.08055161 -0.00929787 -0.01223102\n",
      "  -0.09284696  0.02358253 -0.00659306 -0.01765774 -0.0770481   0.09184836\n",
      "   0.08168853 -0.01725495 -0.09594507 -0.09384886 -0.08458871  0.06104938\n",
      "   0.03769862 -0.06936193 -0.01089    -0.00718983  0.0455856   0.09498767\n",
      "  -0.0071234   0.02997855 -0.09444729 -0.08882797  0.00728447  0.0098993\n",
      "  -0.09425125 -0.08957915  0.01641266  0.01968212 -0.06981368  0.0296913 ]]\n",
      "Model saved to layout_model.keras\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 小工具 --------------------\n",
    "def safe_str(x): \n",
    "    \"\"\"NaN 轉空字串，再轉成 str\"\"\"\n",
    "    return \"\" if (x is None or (isinstance(x, float) and pd.isna(x))) else str(x)\n",
    "\n",
    "def count_digits(s): \n",
    "    \"\"\"計算字串中的數字個數\"\"\"\n",
    "    return sum(ch.isdigit() for ch in safe_str(s))\n",
    "\n",
    "def read_json_file(path: Path):\n",
    "    \"\"\"讀 JSON（加上存在與空檔檢查）\"\"\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    text = path.read_text(encoding=\"utf-8\").strip()\n",
    "    if not text:\n",
    "        raise ValueError(f\"File is empty: {path}\")\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        preview = text[:200]\n",
    "        raise ValueError(f\"Invalid JSON in {path} (preview: {preview!r})\") from e\n",
    "\n",
    "def parse_ls_rect(item):\n",
    "    \"\"\"\n",
    "    從 Label Studio 的 result item 取出：\n",
    "      - label: 類別名\n",
    "      - rect_pct: {x,y,w,h} 百分比(0~100)\n",
    "      - ow, oh: 原圖寬高（int）\n",
    "    \"\"\"\n",
    "    v = item[\"value\"]\n",
    "    label = v[\"rectanglelabels\"][0] if isinstance(v.get(\"rectanglelabels\"), list) else v.get(\"labels\", [\"\"])[0]\n",
    "    rect_pct = dict(x=v[\"x\"], y=v[\"y\"], w=v[\"width\"], h=v[\"height\"])\n",
    "    ow = item.get(\"original_width\") or item.get(\"image_original_width\")\n",
    "    oh = item.get(\"original_height\") or item.get(\"image_original_height\")\n",
    "    if ow is None or oh is None:\n",
    "        raise KeyError(\"Label Studio item missing original_width/original_height.\")\n",
    "    return label, rect_pct, int(ow), int(oh)\n",
    "\n",
    "def pct_to_px(rpct, ow, oh):\n",
    "    \"\"\"百分比座標 → 像素座標（以原圖 ow,oh 為基）\"\"\"\n",
    "    return {\n",
    "        \"x\": rpct[\"x\"] / 100.0 * ow,\n",
    "        \"y\": rpct[\"y\"] / 100.0 * oh,\n",
    "        \"w\": rpct[\"w\"] / 100.0 * ow,\n",
    "        \"h\": rpct[\"h\"] / 100.0 * oh,\n",
    "    }\n",
    "\n",
    "def resize_rect(rect, from_w, from_h, to_w, to_h):\n",
    "    \"\"\"把矩形框從原圖尺寸等比映射到 template 尺寸\"\"\"\n",
    "    sx, sy = to_w / float(from_w), to_h / float(from_h)\n",
    "    return {\n",
    "        \"x\": rect[\"x\"] * sx,\n",
    "        \"y\": rect[\"y\"] * sy,\n",
    "        \"w\": rect[\"w\"] * sx,\n",
    "        \"h\": rect[\"h\"] * sy,\n",
    "    }\n",
    "\n",
    "def delta_from(gt, init, W, H):\n",
    "    \"\"\"\n",
    "    計算 offset：\n",
    "      dx = (x_gt - x0) / W\n",
    "      dy = (y_gt - y0) / H\n",
    "      dlogw = log(w_gt / w0)\n",
    "      dlogh = log(h_gt / h0)\n",
    "    \"\"\"\n",
    "    w0 = max(1e-6, float(init[\"w\"]))\n",
    "    h0 = max(1e-6, float(init[\"h\"]))\n",
    "    return {\n",
    "        \"dx\":   (float(gt[\"x\"]) - float(init[\"x\"])) / float(W),\n",
    "        \"dy\":   (float(gt[\"y\"]) - float(init[\"y\"])) / float(H),\n",
    "        \"dlogw\": float(np.log(max(1e-6, float(gt[\"w\"])) / w0)),\n",
    "        \"dlogh\": float(np.log(max(1e-6, float(gt[\"h\"])) / h0)),\n",
    "    }\n",
    "\n",
    "def build_features(meta_row: dict):\n",
    "    \"\"\"\n",
    "    從 meta.csv 的一列資料建特徵（可自行擴充）\n",
    "    欄位建議：title, bullets, vip_price, unit_price, non_vip_price, has_badge\n",
    "    \"\"\"\n",
    "    title  = safe_str(meta_row.get(\"title\", \"\"))\n",
    "    bullets = safe_str(meta_row.get(\"bullets\", \"\"))\n",
    "    vip    = safe_str(meta_row.get(\"vip_price\", \"\"))\n",
    "    unitp  = safe_str(meta_row.get(\"unit_price\", \"\"))\n",
    "    nonvip = safe_str(meta_row.get(\"non_vip_price\", \"\"))\n",
    "    has_badge = int(str(meta_row.get(\"has_badge\", 0)).strip() not in [\"\", \"0\", \"False\", \"false\"])\n",
    "\n",
    "    feats = {\n",
    "        \"title_len\": len(title),\n",
    "        \"bullets_len\": len(bullets),\n",
    "        \"bullets_lines\": len([b for b in re.split(r\"[;\\n]\", bullets) if b.strip()]),\n",
    "        \"vip_digits\": count_digits(vip),\n",
    "        \"unit_digits\": count_digits(unitp),\n",
    "        \"nonvip_digits\": count_digits(nonvip),\n",
    "        \"has_badge\": has_badge,\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "# -------------------- 主流程：產生訓練 CSV --------------------\n",
    "def run_preprocess(label_studio_json: Path, initial_boxes_json: Path, out_csv: Path, meta_csv: Path|None=None):\n",
    "    # 讀 initial boxes（baseline）\n",
    "    init_cfg = read_json_file(initial_boxes_json)\n",
    "    Tw = int(init_cfg[\"canvas\"][\"width\"])\n",
    "    Th = int(init_cfg[\"canvas\"][\"height\"])\n",
    "    init_boxes = init_cfg[\"boxes\"]             # dict: class -> {x,y,w,h}\n",
    "    classes = list(init_boxes.keys())          # 固定輸出順序以 initial_boxes 為準\n",
    "\n",
    "    # 讀 meta（可選）\n",
    "    meta_df = None\n",
    "    if meta_csv and Path(meta_csv).exists():\n",
    "        meta_df = pd.read_csv(meta_csv)\n",
    "\n",
    "    # 讀 Label Studio 匯出（Common JSON）\n",
    "    tasks = read_json_file(label_studio_json)\n",
    "\n",
    "    rows = []\n",
    "    for t in tasks:\n",
    "        img_field = t.get(\"file_upload\") or t.get(\"data\", {}).get(\"image\") or t.get(\"id\")\n",
    "        image_id = Path(str(img_field)).stem\n",
    "\n",
    "        annos = t.get(\"annotations\") or t.get(\"completions\") or []\n",
    "        if not annos:\n",
    "            continue\n",
    "        res = annos[0].get(\"result\", [])\n",
    "\n",
    "        # 收集每一類的 GT（縮放到 template 尺寸）\n",
    "        gt_scaled = {}\n",
    "        for r in res:\n",
    "            if r.get(\"type\") not in (\"rectanglelabels\", \"rectangles\"):\n",
    "                continue\n",
    "            label, rpct, ow, oh = parse_ls_rect(r)\n",
    "            if label not in classes:\n",
    "                continue\n",
    "            rect_px = pct_to_px(rpct, ow, oh)\n",
    "            rect_tpl = resize_rect(rect_px, from_w=ow, from_h=oh, to_w=Tw, to_h=Th)\n",
    "            gt_scaled[label] = rect_tpl\n",
    "\n",
    "        # 準備一行輸出\n",
    "        row = {\"image_id\": image_id}\n",
    "\n",
    "        # 合併 meta 特徵\n",
    "        if meta_df is not None and \"image_id\" in meta_df.columns:\n",
    "            m = meta_df.loc[meta_df[\"image_id\"] == image_id]\n",
    "            feats = build_features(m.iloc[0].to_dict()) if not m.empty else build_features({})\n",
    "        else:\n",
    "            feats = build_features({})\n",
    "        row.update(feats)\n",
    "\n",
    "        # 依 classes 順序寫 offsets\n",
    "        for cls in classes:\n",
    "            init = init_boxes[cls]\n",
    "            gt = gt_scaled.get(cls)\n",
    "            if gt is None:\n",
    "                d = {\"dx\": 0.0, \"dy\": 0.0, \"dlogw\": 0.0, \"dlogh\": 0.0}\n",
    "            else:\n",
    "                d = delta_from(gt, init, Tw, Th)\n",
    "            row[f\"{cls}_dx\"]    = d[\"dx\"]\n",
    "            row[f\"{cls}_dy\"]    = d[\"dy\"]\n",
    "            row[f\"{cls}_dlogw\"] = d[\"dlogw\"]\n",
    "            row[f\"{cls}_dlogh\"] = d[\"dlogh\"]\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    # 輸出 CSV\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv, index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "    print(f\"[OK] Saved {out_csv}  rows={len(df)}\")\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "\n",
    "    # [NEW] 同步存下「訓練時」的類別順序，供推論讀回\n",
    "    class_order_path = Path(out_csv).with_suffix(\".classes.json\")  # e.g., offsets_for_tf.classes.json\n",
    "    with open(class_order_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(classes, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"[INFO] Saved class order -> {class_order_path}\")\n",
    "    return df\n",
    "\n",
    "# -------------------- 入口（命令列 / Notebook 皆可） --------------------\n",
    "def main_cli():\n",
    "    \"\"\"命令列用法：python preprocess_layout_v3.py --label_studio_json ... --initial_boxes_json ... --out_csv ... [--meta_csv ...]\"\"\"\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--label_studio_json\", required=True, help=\"Label Studio Common JSON export\")\n",
    "    ap.add_argument(\"--initial_boxes_json\", required=True, help=\"Initial boxes JSON (template baseline)\")\n",
    "    ap.add_argument(\"--out_csv\", required=True, help=\"Output CSV path\")\n",
    "    ap.add_argument(\"--meta_csv\", default=\"\", help=\"(Optional) meta CSV with image_id + product fields\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    run_preprocess(\n",
    "        label_studio_json=Path(args.label_studio_json),\n",
    "        initial_boxes_json=Path(args.initial_boxes_json),\n",
    "        out_csv=Path(args.out_csv),\n",
    "        meta_csv=Path(args.meta_csv) if args.meta_csv else None\n",
    "    )\n",
    "\n",
    "# 若在命令列執行：走 argparse\n",
    "if __name__ == \"__main__\" and not hasattr(sys.modules[\"__main__\"], \"__file__\"):\n",
    "    pass\n",
    "elif __name__ == \"__main__\":\n",
    "    main_cli()\n",
    "\n",
    "# -------------------- 下面開始：訓練 + 產圖 --------------------\n",
    "from pathlib import Path\n",
    "df_FeatureEngineering = run_preprocess(\n",
    "    label_studio_json=Path(\"Objects_positions.json\"),\n",
    "    initial_boxes_json=Path(\"Initial_boxes.json\"),\n",
    "    out_csv=Path(\"offsets_for_tf.csv\"),\n",
    "    meta_csv=None\n",
    ")\n",
    "df_FeatureEngineering.head(15)\n",
    "\n",
    "# =====Model Building=====\n",
    "df = pd.read_csv(\"offsets_for_tf.csv\")\n",
    "\n",
    "# features (X) = 除了 image_id 以外的欄位，且不含 offsets\n",
    "X = df.drop(columns=[c for c in df.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\")) or c==\"image_id\"])\n",
    "# targets (Y) = offsets\n",
    "Y = df[[c for c in df.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\"))]]\n",
    "\n",
    "# 切分資料\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 標準化（重要，避免不同尺度影響）\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(Y_train.shape[1])  # 輸出數量 = offsets 欄位數\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss='mse',   # 回歸問題\n",
    "    metrics=[MeanSquaredError(), MeanAbsoluteError()]\n",
    ")\n",
    "\n",
    "# 訓練\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=50,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# 假設有一筆新產品的 meta feature\n",
    "sample = X_val[0:1]\n",
    "pred_offset = model.predict(sample)\n",
    "print(\"Predicted offsets (sample):\", pred_offset[:1])\n",
    "\n",
    "# 存模型 & scaler\n",
    "model.save(\"layout_model.keras\")   # 存成 Keras 格式\n",
    "print(\"Model saved to layout_model.keras\")\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7d24205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred deltas (first row after blend): [ 0.9903074   0.8369056  -0.7444322  -0.91772836  0.2106682   0.8673276\n",
      " -0.99901277 -0.29051143  0.9815127  -0.9967992  -0.8292238   0.6552934 ]\n",
      "Saved: out_cards_cn/card_cn_001.png\n",
      "Saved: out_cards_cn/card_cn_002.png\n"
     ]
    }
   ],
   "source": [
    "# ============ 基本路徑 ============\n",
    "EXCEL_PATH = \"Board Click SKU.xlsx\"\n",
    "SHEET_USER = \"User_Input\"\n",
    "SHEET_IMG  = \"SKU_Image\"\n",
    "SHEET_ICON = \"SKU_Icon\"\n",
    "\n",
    "TEMPLATE_PATH = \"sasa_pink_1280.png\"\n",
    "INITIAL_BOXES_PATH = \"Initial_boxes.json\"\n",
    "\n",
    "MODEL_PATH = \"layout_model.keras\"\n",
    "SCALER_PATH = \"scaler.pkl\"\n",
    "\n",
    "OUTPUT_DIR = Path(\"out_cards_cn\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ============ 偵錯選項（可關閉） ============\n",
    "DRAW_DEBUG_BOXES = True   # [NEW] 想看框是否飛出，可設 True\n",
    "PRINT_FIRST_PRED = True   # [NEW] 印第一列的預測 delta\n",
    "BLEND = 1              # [NEW] 降暴：只採用 35% 的模型偏移量\n",
    "\n",
    "# ============ 欄位映射 ============\n",
    "MAP_TEXT = {\n",
    "    \"Brand Position\":          \"Brand\",\n",
    "    \"VIP Price Position\":      \"VIP價\",\n",
    "    \"Non VIP Price Position\":  \"優惠價\",\n",
    "    \"Original Price Position\": \"建議價\",\n",
    "    \"Product Position\":        \"Product name\",\n",
    "    \"Sales Period Position\":   \"優惠期\",\n",
    "    \"FAB Position\":            \"FAB\",\n",
    "}\n",
    "COL_PRODUCT_SKU = \"Product SKU\"\n",
    "COL_ICON_NAME   = \"Icon\"\n",
    "\n",
    "# 若你的欄位名不是 link，請改成正確的欄位名\n",
    "SKU_IMG_SKU_COL   = \"Product SKU\"\n",
    "SKU_IMG_LINK_COL  = \"Image\"\n",
    "SKU_ICON_NAME_COL = \"Icon\"\n",
    "SKU_ICON_LINK_COL = \"Icon Image\"\n",
    "\n",
    "# ============ 字型（請把路徑改成你電腦實際有的檔） ============\n",
    "FONT_REGULAR_PATH = Path.home() / \"Library/Fonts/NotoSansCJKsc-Regular.otf\"\n",
    "FONT_BOLD_PATH    = Path.home() / \"Library/Fonts/NotoSansCJKsc-Bold.otf\"\n",
    "\n",
    "def _load_font(path, size):\n",
    "    return ImageFont.truetype(str(path), size)\n",
    "\n",
    "# ============ 常用工具 ============\n",
    "def _safe(s):\n",
    "    return \"\" if (s is None or (isinstance(s, float) and pd.isna(s))) else str(s)\n",
    "\n",
    "def _count_digits(s):\n",
    "    return sum(ch.isdigit() for ch in _safe(s))\n",
    "\n",
    "def _norm_key(x):\n",
    "    s = \"\" if pd.isna(x) else str(x)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)  # 全形 → 半形\n",
    "    return s.strip().casefold()\n",
    "\n",
    "def _drive_share_to_direct(u: str) -> str:\n",
    "    # 轉 Google Drive 分享連結 → 直接下載\n",
    "    if not u: return u\n",
    "    m = re.search(r\"/d/([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    m = re.search(r\"[?&]id=([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    return u\n",
    "\n",
    "def load_image_any(path_or_url: str):\n",
    "    if not path_or_url:\n",
    "        return None\n",
    "    s = str(path_or_url).strip()\n",
    "    try:\n",
    "        if s.startswith(\"http://\") or s.startswith(\"https://\"):\n",
    "            s2 = _drive_share_to_direct(s)\n",
    "            resp = requests.get(s2, timeout=15)\n",
    "            resp.raise_for_status()\n",
    "            return Image.open(BytesIO(resp.content)).convert(\"RGBA\")\n",
    "        p = Path(s)\n",
    "        if p.exists():\n",
    "            return Image.open(p).convert(\"RGBA\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] cannot load image:\", s, e)\n",
    "    return None\n",
    "\n",
    "# ============ 特徵工程（需與訓練時一致） ============\n",
    "FEATURE_ORDER = [\n",
    "    \"title_len\", \"bullets_len\", \"bullets_lines\",\n",
    "    \"vip_digits\", \"unit_digits\", \"nonvip_digits\",\n",
    "    \"has_badge\",\n",
    "]\n",
    "\n",
    "def build_features_from_row(row: pd.Series, resolved_icon_path: str) -> dict:\n",
    "    title   = _safe(row.get(MAP_TEXT[\"Product Position\"], \"\"))\n",
    "    bullets = _safe(row.get(MAP_TEXT[\"FAB Position\"], \"\"))\n",
    "    vip     = _safe(row.get(MAP_TEXT[\"VIP Price Position\"], \"\"))\n",
    "    unitp   = _safe(row.get(MAP_TEXT[\"Non VIP Price Position\"], \"\"))\n",
    "    orig    = _safe(row.get(MAP_TEXT[\"Original Price Position\"], \"\"))\n",
    "    has_icon = int(Path(_safe(resolved_icon_path)).exists()) if resolved_icon_path else 0\n",
    "\n",
    "    return {\n",
    "        \"title_len\": len(title),\n",
    "        \"bullets_len\": len(bullets),\n",
    "        \"bullets_lines\": len([b for b in bullets.split(\";\") if b.strip()]),\n",
    "        \"vip_digits\": _count_digits(vip),\n",
    "        \"unit_digits\": _count_digits(unitp),\n",
    "        \"nonvip_digits\": _count_digits(unitp),  # [FIX] 與訓練時一致：non_vip_price，而不是 orig(建議價)\n",
    "        \"has_badge\": has_icon,\n",
    "    }\n",
    "\n",
    "# ============ 幾何 / 佈局 ============\n",
    "def _clip(v, lo, hi):  # [NEW] 便於做邊界裁切\n",
    "    return max(lo, min(hi, v))\n",
    "\n",
    "def apply_offset(init_box, delta, W, H):\n",
    "    dx, dy, dlogw, dlogh = map(float, delta)\n",
    "\n",
    "    # [NEW] 位移限制（避免飛出半張圖；可依據你的資料再調整）\n",
    "    dx = _clip(dx, -0.5, 0.5)\n",
    "    dy = _clip(dy, -0.5, 0.5)\n",
    "\n",
    "    # [NEW] 尺寸縮放限制（0.5x ~ 2x），用裁好的 dlog 區間再 exp\n",
    "    sx = math.exp(_clip(dlogw, math.log(0.5), math.log(2.0)))\n",
    "    sy = math.exp(_clip(dlogh, math.log(0.5), math.log(2.0)))\n",
    "\n",
    "    x = init_box[\"x\"] + dx * W\n",
    "    y = init_box[\"y\"] + dy * H\n",
    "    w = max(24, init_box[\"w\"] * sx)  # [NEW] 最小寬/高，避免太小導致無法排版\n",
    "    h = max(24, init_box[\"h\"] * sy)\n",
    "\n",
    "    # [NEW] 把盒子裁進畫布，避免完全跑出可視區\n",
    "    x = _clip(x, 0, W - w)\n",
    "    y = _clip(y, 0, H - h)\n",
    "\n",
    "    return {\"x\": x, \"y\": y, \"w\": w, \"h\": h}\n",
    "\n",
    "def paste_image_into_box(canvas_rgba, path_or_url, box, padding=6):\n",
    "    im = load_image_any(path_or_url)\n",
    "    if im is None:\n",
    "        print(\"[WARN] image not found:\", path_or_url)\n",
    "        return\n",
    "    x, y, w, h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    w2, h2 = max(1, w - padding*2), max(1, h - padding*2)\n",
    "    ratio = min(w2 / im.width, h2 / im.height)\n",
    "    im = im.resize((max(1,int(im.width*ratio)), max(1,int(im.height*ratio))), Image.LANCZOS)\n",
    "    ox = x + (w - im.width)//2\n",
    "    oy = y + (h - im.height)//2\n",
    "    canvas_rgba.alpha_composite(im, (ox, oy))\n",
    "\n",
    "def draw_text_in_box(draw, text, box, font_path, max_font=64, min_font=16, align=\"left\", line_spacing=1.15):\n",
    "    if not text or str(text).strip()==\"\":\n",
    "        return\n",
    "    x, y, w, h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    text = str(text)\n",
    "\n",
    "    for fs in range(max_font, min_font-1, -2):\n",
    "        font = _load_font(font_path, fs)\n",
    "        approx_chars = max(1, int(w / (fs * 0.55)))\n",
    "        lines = []\n",
    "        for raw in text.split(\"\\n\"):\n",
    "            lines += (textwrap.wrap(raw, width=approx_chars) if approx_chars>1 else [raw])\n",
    "\n",
    "        bboxes = [draw.textbbox((0,0), ln, font=font) for ln in lines]\n",
    "        line_heights = [bb[3]-bb[1] for bb in bboxes]\n",
    "        total_h = int(sum(line_heights) + (len(lines)-1)*fs*(line_spacing-1))\n",
    "        if total_h <= h:\n",
    "            cur_y = y + (h - total_h)//2\n",
    "            for ln in lines:\n",
    "                bb = draw.textbbox((0,0), ln, font=font)\n",
    "                lw = bb[2]-bb[0]\n",
    "                if align == \"center\":\n",
    "                    cur_x = x + (w - lw)//2\n",
    "                elif align == \"right\":\n",
    "                    cur_x = x + (w - lw)\n",
    "                else:\n",
    "                    cur_x = x\n",
    "                draw.text((cur_x, cur_y), ln, font=font, fill=(0,0,0,255))\n",
    "                cur_y += int(fs * line_spacing)\n",
    "            return\n",
    "    # 放不下就畫第一行\n",
    "    draw.text((x, y), text.split(\"\\n\")[0][:30]+\"…\", font=_load_font(font_path, min_font), fill=(0,0,0,255))\n",
    "\n",
    "# [NEW] 偵錯：描框\n",
    "def _stroke(draw, box, color=(0,0,0,255), width=2):\n",
    "    x,y,w,h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    draw.rectangle([x,y,x+w,y+h], outline=color, width=width)\n",
    "\n",
    "# ============ 載入模板 & 初始盒 & 模型 ============\n",
    "def load_template_and_boxes():\n",
    "    tpl = Image.open(TEMPLATE_PATH).convert(\"RGBA\")\n",
    "    tw, th = tpl.size\n",
    "    init_cfg = json.loads(Path(INITIAL_BOXES_PATH).read_text(encoding=\"utf-8\"))\n",
    "    cw, ch = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    if (tw, th) != (cw, ch):\n",
    "        sx, sy = tw/float(cw), th/float(ch)\n",
    "        for _, r in init_cfg[\"boxes\"].items():\n",
    "            r[\"x\"], r[\"y\"] = r[\"x\"]*sx, r[\"y\"]*sy\n",
    "            r[\"w\"], r[\"h\"] = r[\"w\"]*sx, r[\"h\"]*sy\n",
    "        init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"] = tw, th\n",
    "        print(f\"[INFO] Scaled initial boxes to {tw}x{th}\")\n",
    "    return tpl, init_cfg\n",
    "\n",
    "def load_model_and_scaler():\n",
    "    model = None\n",
    "    scaler = None\n",
    "    if Path(MODEL_PATH).exists():\n",
    "        model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    else:\n",
    "        print(\"[WARN] MODEL not found → 使用 zero offsets\")\n",
    "    if Path(SCALER_PATH).exists():\n",
    "        with open(SCALER_PATH, \"rb\") as f:\n",
    "            scaler = pickle.load(f)\n",
    "    else:\n",
    "        print(\"[WARN] SCALER not found → 直接用原始特徵\")\n",
    "    return model, scaler\n",
    "\n",
    "# ============ 主流程（推論 & 畫圖） ============\n",
    "def main():\n",
    "    # 讀 Excel\n",
    "    xls = pd.ExcelFile(EXCEL_PATH)\n",
    "    df_user = pd.read_excel(xls, sheet_name=SHEET_USER)\n",
    "    df_img  = pd.read_excel(xls, sheet_name=SHEET_IMG)\n",
    "    df_icon = pd.read_excel(xls, sheet_name=SHEET_ICON)\n",
    "\n",
    "    # 建查表（SKU / ICON）\n",
    "    img_lookup  = {_norm_key(r[SKU_IMG_SKU_COL]): str(r[SKU_IMG_LINK_COL]).strip()\n",
    "                   for _, r in df_img.iterrows() if SKU_IMG_SKU_COL in r and SKU_IMG_LINK_COL in r}\n",
    "    icon_lookup = {_norm_key(r[SKU_ICON_NAME_COL]): str(r[SKU_ICON_LINK_COL]).strip()\n",
    "                   for _, r in df_icon.iterrows() if SKU_ICON_NAME_COL in r and SKU_ICON_LINK_COL in r}\n",
    "\n",
    "    # 載入模板與模型\n",
    "    template_rgba, init_cfg = load_template_and_boxes()\n",
    "    W, H = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    INIT_BOXES = init_cfg[\"boxes\"]\n",
    "\n",
    "    # [NEW] 強制使用「訓練時」的類別順序，防止對錯框\n",
    "    CLASS_ORDER_FILE = Path(\"offsets_for_tf.classes.json\")\n",
    "    if CLASS_ORDER_FILE.exists():\n",
    "        train_classes = json.loads(CLASS_ORDER_FILE.read_text(encoding=\"utf-8\"))\n",
    "        if set(train_classes) != set(INIT_BOXES.keys()):\n",
    "            raise ValueError(\n",
    "                \"Classes mismatch between training and inference.\\n\"\n",
    "                f\"Train: {train_classes}\\nInfer: {list(INIT_BOXES.keys())}\\n\"\n",
    "                \"請確認 Initial_boxes.json 與訓練時一致（或重新產生資料與模型）。\"\n",
    "            )\n",
    "        CLASSES = train_classes[:]  # [NEW]\n",
    "    else:\n",
    "        CLASSES = list(INIT_BOXES.keys())  # 後備\n",
    "\n",
    "    model, scaler = load_model_and_scaler()\n",
    "\n",
    "    printed_pred_once = False\n",
    "\n",
    "    # 逐列生成\n",
    "    for idx, row in df_user.iterrows():\n",
    "        # 解析圖片路徑\n",
    "        sku_key  = _norm_key(row.get(COL_PRODUCT_SKU, \"\"))\n",
    "        icon_key = _norm_key(row.get(COL_ICON_NAME, \"\"))\n",
    "        prod_img_path = img_lookup.get(sku_key, \"\")\n",
    "        icon_img_path = icon_lookup.get(icon_key, \"\")\n",
    "\n",
    "        # 特徵 → DataFrame（與訓練欄位同名同序）\n",
    "        feats = build_features_from_row(row, resolved_icon_path=icon_img_path)\n",
    "        X_df = pd.DataFrame([feats], columns=FEATURE_ORDER).astype(float)  # [FIX] 保留欄名避免 sklearn warning\n",
    "        X_scaled = scaler.transform(X_df) if scaler is not None else X_df.values\n",
    "\n",
    "        # 預測 offsets\n",
    "        if model is not None:\n",
    "            pred = model.predict(X_scaled, verbose=0)[0]\n",
    "        else:\n",
    "            pred = np.zeros(len(CLASSES)*4, dtype=float)\n",
    "\n",
    "        # [NEW] 降暴：blend 回初始框，避免剛訓練完偏移過猛\n",
    "        pred = pred * BLEND\n",
    "\n",
    "        if PRINT_FIRST_PRED and (not printed_pred_once):\n",
    "            print(\"Pred deltas (first row after blend):\", pred[:min(12, len(pred))])\n",
    "            printed_pred_once = True\n",
    "\n",
    "        # 重組每個類別的 4 維 offset\n",
    "        deltas = {cls: pred[i*4:(i+1)*4] for i, cls in enumerate(CLASSES)}\n",
    "        final_boxes = {cls: apply_offset(INIT_BOXES[cls], deltas[cls], W, H) for cls in CLASSES}\n",
    "\n",
    "        # 渲染\n",
    "        canvas = template_rgba.copy()\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "        if DRAW_DEBUG_BOXES:\n",
    "            for k,b in final_boxes.items():\n",
    "                _stroke(draw, b)  # [NEW] 畫出預測框方便檢查是否飛出畫布\n",
    "\n",
    "        # 圖片\n",
    "        paste_image_into_box(canvas, prod_img_path, final_boxes[\"Product Image Position\"])\n",
    "        paste_image_into_box(canvas, icon_img_path,  final_boxes[\"Icon Position\"])\n",
    "\n",
    "        # 文字（黑色，Noto/蘋方）\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Brand Position\"], \"\"),          final_boxes[\"Brand Position\"],          font_path=FONT_BOLD_PATH,   max_font=72)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Product Position\"], \"\"),        final_boxes[\"Product Position\"],        font_path=FONT_REGULAR_PATH, max_font=64)\n",
    "        fab_text = str(row.get(MAP_TEXT[\"FAB Position\"], \"\") or \"\").replace(\";\", \"\\n\")\n",
    "        draw_text_in_box(draw, fab_text,                                        final_boxes[\"FAB Position\"],            font_path=FONT_REGULAR_PATH, max_font=44)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"VIP Price Position\"], \"\"),      final_boxes[\"VIP Price Position\"],      font_path=FONT_BOLD_PATH,    max_font=100)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Non VIP Price Position\"], \"\"),  final_boxes[\"Non VIP Price Position\"],  font_path=FONT_REGULAR_PATH, max_font=36)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Original Price Position\"], \"\"), final_boxes[\"Original Price Position\"], font_path=FONT_REGULAR_PATH, max_font=32)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Sales Period Position\"], \"\"),   final_boxes[\"Sales Period Position\"],   font_path=FONT_REGULAR_PATH, max_font=28, align=\"right\")\n",
    "\n",
    "        out_path = OUTPUT_DIR / f\"card_cn_{idx+1:03d}.png\"\n",
    "        canvas.convert(\"RGB\").save(out_path, quality=95)\n",
    "        print(\"Saved:\", out_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8949abf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved offsets_for_tf.csv  rows=29\n",
      "Columns: ['image_id', 'title_len', 'bullets_len', 'bullets_lines', 'vip_digits', 'unit_digits', 'nonvip_digits', 'has_badge', 'Sales Period Position_dx', 'Sales Period Position_dy', 'Sales Period Position_dlogw', 'Sales Period Position_dlogh', 'Brand Position_dx', 'Brand Position_dy', 'Brand Position_dlogw', 'Brand Position_dlogh', 'Product Position_dx', 'Product Position_dy', 'Product Position_dlogw', 'Product Position_dlogh', 'FAB Position_dx', 'FAB Position_dy', 'FAB Position_dlogw', 'FAB Position_dlogh', 'Product Image Position_dx', 'Product Image Position_dy', 'Product Image Position_dlogw', 'Product Image Position_dlogh', 'VIP Price Position_dx', 'VIP Price Position_dy', 'VIP Price Position_dlogw', 'VIP Price Position_dlogh', 'Non VIP Price Position_dx', 'Non VIP Price Position_dy', 'Non VIP Price Position_dlogw', 'Non VIP Price Position_dlogh', 'Original Price Position_dx', 'Original Price Position_dy', 'Original Price Position_dlogw', 'Original Price Position_dlogh', 'Icon Position_dx', 'Icon Position_dy', 'Icon Position_dlogw', 'Icon Position_dlogh']\n",
      "[INFO] Saved class order -> offsets_for_tf.classes.json\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/boardclick/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0680 - mean_absolute_error: 0.1592 - mean_squared_error: 0.0680 - val_loss: 0.0647 - val_mean_absolute_error: 0.1542 - val_mean_squared_error: 0.0647\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0675 - mean_absolute_error: 0.1581 - mean_squared_error: 0.0675 - val_loss: 0.0643 - val_mean_absolute_error: 0.1535 - val_mean_squared_error: 0.0643\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0670 - mean_absolute_error: 0.1571 - mean_squared_error: 0.0670 - val_loss: 0.0639 - val_mean_absolute_error: 0.1528 - val_mean_squared_error: 0.0639\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0665 - mean_absolute_error: 0.1561 - mean_squared_error: 0.0665 - val_loss: 0.0634 - val_mean_absolute_error: 0.1523 - val_mean_squared_error: 0.0634\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0660 - mean_absolute_error: 0.1552 - mean_squared_error: 0.0660 - val_loss: 0.0630 - val_mean_absolute_error: 0.1517 - val_mean_squared_error: 0.0630\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0656 - mean_absolute_error: 0.1544 - mean_squared_error: 0.0656 - val_loss: 0.0626 - val_mean_absolute_error: 0.1513 - val_mean_squared_error: 0.0626\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0651 - mean_absolute_error: 0.1537 - mean_squared_error: 0.0651 - val_loss: 0.0622 - val_mean_absolute_error: 0.1508 - val_mean_squared_error: 0.0622\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0647 - mean_absolute_error: 0.1529 - mean_squared_error: 0.0647 - val_loss: 0.0618 - val_mean_absolute_error: 0.1503 - val_mean_squared_error: 0.0618\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0642 - mean_absolute_error: 0.1522 - mean_squared_error: 0.0642 - val_loss: 0.0614 - val_mean_absolute_error: 0.1498 - val_mean_squared_error: 0.0614\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0638 - mean_absolute_error: 0.1516 - mean_squared_error: 0.0638 - val_loss: 0.0610 - val_mean_absolute_error: 0.1492 - val_mean_squared_error: 0.0610\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0634 - mean_absolute_error: 0.1509 - mean_squared_error: 0.0634 - val_loss: 0.0606 - val_mean_absolute_error: 0.1487 - val_mean_squared_error: 0.0606\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0629 - mean_absolute_error: 0.1502 - mean_squared_error: 0.0629 - val_loss: 0.0602 - val_mean_absolute_error: 0.1482 - val_mean_squared_error: 0.0602\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0625 - mean_absolute_error: 0.1496 - mean_squared_error: 0.0625 - val_loss: 0.0598 - val_mean_absolute_error: 0.1477 - val_mean_squared_error: 0.0598\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0621 - mean_absolute_error: 0.1491 - mean_squared_error: 0.0621 - val_loss: 0.0594 - val_mean_absolute_error: 0.1473 - val_mean_squared_error: 0.0594\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0617 - mean_absolute_error: 0.1485 - mean_squared_error: 0.0617 - val_loss: 0.0591 - val_mean_absolute_error: 0.1468 - val_mean_squared_error: 0.0591\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0613 - mean_absolute_error: 0.1479 - mean_squared_error: 0.0613 - val_loss: 0.0587 - val_mean_absolute_error: 0.1463 - val_mean_squared_error: 0.0587\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0609 - mean_absolute_error: 0.1473 - mean_squared_error: 0.0609 - val_loss: 0.0583 - val_mean_absolute_error: 0.1458 - val_mean_squared_error: 0.0583\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0605 - mean_absolute_error: 0.1468 - mean_squared_error: 0.0605 - val_loss: 0.0580 - val_mean_absolute_error: 0.1453 - val_mean_squared_error: 0.0580\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0601 - mean_absolute_error: 0.1462 - mean_squared_error: 0.0601 - val_loss: 0.0576 - val_mean_absolute_error: 0.1448 - val_mean_squared_error: 0.0576\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0598 - mean_absolute_error: 0.1456 - mean_squared_error: 0.0598 - val_loss: 0.0573 - val_mean_absolute_error: 0.1443 - val_mean_squared_error: 0.0573\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0594 - mean_absolute_error: 0.1451 - mean_squared_error: 0.0594 - val_loss: 0.0569 - val_mean_absolute_error: 0.1439 - val_mean_squared_error: 0.0569\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0590 - mean_absolute_error: 0.1445 - mean_squared_error: 0.0590 - val_loss: 0.0566 - val_mean_absolute_error: 0.1434 - val_mean_squared_error: 0.0566\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0586 - mean_absolute_error: 0.1440 - mean_squared_error: 0.0586 - val_loss: 0.0563 - val_mean_absolute_error: 0.1429 - val_mean_squared_error: 0.0563\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0583 - mean_absolute_error: 0.1434 - mean_squared_error: 0.0583 - val_loss: 0.0559 - val_mean_absolute_error: 0.1425 - val_mean_squared_error: 0.0559\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0579 - mean_absolute_error: 0.1429 - mean_squared_error: 0.0579 - val_loss: 0.0556 - val_mean_absolute_error: 0.1420 - val_mean_squared_error: 0.0556\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0576 - mean_absolute_error: 0.1423 - mean_squared_error: 0.0576 - val_loss: 0.0553 - val_mean_absolute_error: 0.1415 - val_mean_squared_error: 0.0553\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0572 - mean_absolute_error: 0.1418 - mean_squared_error: 0.0572 - val_loss: 0.0550 - val_mean_absolute_error: 0.1410 - val_mean_squared_error: 0.0550\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0569 - mean_absolute_error: 0.1413 - mean_squared_error: 0.0569 - val_loss: 0.0547 - val_mean_absolute_error: 0.1406 - val_mean_squared_error: 0.0547\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0565 - mean_absolute_error: 0.1408 - mean_squared_error: 0.0565 - val_loss: 0.0543 - val_mean_absolute_error: 0.1402 - val_mean_squared_error: 0.0543\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0562 - mean_absolute_error: 0.1403 - mean_squared_error: 0.0562 - val_loss: 0.0540 - val_mean_absolute_error: 0.1398 - val_mean_squared_error: 0.0540\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0559 - mean_absolute_error: 0.1398 - mean_squared_error: 0.0559 - val_loss: 0.0537 - val_mean_absolute_error: 0.1394 - val_mean_squared_error: 0.0537\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0555 - mean_absolute_error: 0.1393 - mean_squared_error: 0.0555 - val_loss: 0.0534 - val_mean_absolute_error: 0.1391 - val_mean_squared_error: 0.0534\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0552 - mean_absolute_error: 0.1389 - mean_squared_error: 0.0552 - val_loss: 0.0531 - val_mean_absolute_error: 0.1388 - val_mean_squared_error: 0.0531\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0549 - mean_absolute_error: 0.1384 - mean_squared_error: 0.0549 - val_loss: 0.0528 - val_mean_absolute_error: 0.1384 - val_mean_squared_error: 0.0528\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0546 - mean_absolute_error: 0.1380 - mean_squared_error: 0.0546 - val_loss: 0.0525 - val_mean_absolute_error: 0.1381 - val_mean_squared_error: 0.0525\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0543 - mean_absolute_error: 0.1375 - mean_squared_error: 0.0543 - val_loss: 0.0522 - val_mean_absolute_error: 0.1377 - val_mean_squared_error: 0.0522\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0539 - mean_absolute_error: 0.1371 - mean_squared_error: 0.0539 - val_loss: 0.0520 - val_mean_absolute_error: 0.1374 - val_mean_squared_error: 0.0520\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0536 - mean_absolute_error: 0.1366 - mean_squared_error: 0.0536 - val_loss: 0.0517 - val_mean_absolute_error: 0.1370 - val_mean_squared_error: 0.0517\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0533 - mean_absolute_error: 0.1362 - mean_squared_error: 0.0533 - val_loss: 0.0514 - val_mean_absolute_error: 0.1366 - val_mean_squared_error: 0.0514\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0530 - mean_absolute_error: 0.1358 - mean_squared_error: 0.0530 - val_loss: 0.0511 - val_mean_absolute_error: 0.1363 - val_mean_squared_error: 0.0511\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0528 - mean_absolute_error: 0.1354 - mean_squared_error: 0.0528 - val_loss: 0.0508 - val_mean_absolute_error: 0.1359 - val_mean_squared_error: 0.0508\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0524 - mean_absolute_error: 0.1349 - mean_squared_error: 0.0524 - val_loss: 0.0506 - val_mean_absolute_error: 0.1356 - val_mean_squared_error: 0.0506\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0522 - mean_absolute_error: 0.1345 - mean_squared_error: 0.0522 - val_loss: 0.0503 - val_mean_absolute_error: 0.1353 - val_mean_squared_error: 0.0503\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0519 - mean_absolute_error: 0.1342 - mean_squared_error: 0.0519 - val_loss: 0.0501 - val_mean_absolute_error: 0.1349 - val_mean_squared_error: 0.0501\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0516 - mean_absolute_error: 0.1338 - mean_squared_error: 0.0516 - val_loss: 0.0498 - val_mean_absolute_error: 0.1346 - val_mean_squared_error: 0.0498\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0513 - mean_absolute_error: 0.1334 - mean_squared_error: 0.0513 - val_loss: 0.0495 - val_mean_absolute_error: 0.1343 - val_mean_squared_error: 0.0495\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0511 - mean_absolute_error: 0.1331 - mean_squared_error: 0.0511 - val_loss: 0.0493 - val_mean_absolute_error: 0.1340 - val_mean_squared_error: 0.0493\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0508 - mean_absolute_error: 0.1327 - mean_squared_error: 0.0508 - val_loss: 0.0490 - val_mean_absolute_error: 0.1338 - val_mean_squared_error: 0.0490\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0505 - mean_absolute_error: 0.1323 - mean_squared_error: 0.0505 - val_loss: 0.0488 - val_mean_absolute_error: 0.1335 - val_mean_squared_error: 0.0488\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0503 - mean_absolute_error: 0.1320 - mean_squared_error: 0.0503 - val_loss: 0.0485 - val_mean_absolute_error: 0.1332 - val_mean_squared_error: 0.0485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Model & scaler saved.\n",
      "Pred deltas (first row, after BLEND): [-0.01434847 -0.6464848   2.687656   -0.84796405 -4.838881    4.4194365\n",
      "  1.4483395  -0.12756734 -0.8728312  -0.64684445 -1.8858486  -5.2842455 ]\n",
      "Saved: out_cards_cn/card_cn_001.png\n",
      "Saved: out_cards_cn/card_cn_002.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json, csv, re, argparse, sys, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "import pickle\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "import unicodedata\n",
    "import requests\n",
    "from io import BytesIO  # [FIX] load_image_any 需要 BytesIO\n",
    "\n",
    "# =================== 全域設定 ===================\n",
    "# 模型/推論控制\n",
    "USE_MODEL = True          # [NEW] 先關掉可做「零偏移」基準測試\n",
    "BLEND = 1              # [NEW] 讓模型偏移更保守；零偏移時設 0\n",
    "DRAW_DEBUG_BOXES = True   # [NEW] 畫出預測框方便對位除錯\n",
    "PRINT_FIRST_PRED = True   # [NEW] 印第一筆的預測 delta\n",
    "\n",
    "# 檔名/路徑\n",
    "EXCEL_PATH = \"Board Click SKU.xlsx\"\n",
    "SHEET_USER = \"User_Input\"\n",
    "SHEET_IMG  = \"SKU_Image\"\n",
    "SHEET_ICON = \"SKU_Icon\"\n",
    "\n",
    "TEMPLATE_PATH = \"sasa_pink_1280.png\"\n",
    "INITIAL_BOXES_PATH = \"Initial_boxes.json\"\n",
    "\n",
    "MODEL_PATH = \"layout_model.keras\"\n",
    "SCALER_PATH = \"scaler.pkl\"\n",
    "\n",
    "OUT_CSV = \"offsets_for_tf.csv\"     # [NEW] 訓練資料輸出名（也用來找 .classes.json）\n",
    "CLASS_ORDER_FILE = Path(OUT_CSV).with_suffix(\".classes.json\")  # [NEW]\n",
    "\n",
    "OUTPUT_DIR = Path(\"out_cards_cn\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 欄位映射（Excel→語義）\n",
    "MAP_TEXT = {\n",
    "    \"Brand Position\":          \"Brand\",\n",
    "    \"VIP Price Position\":      \"VIP價\",\n",
    "    \"Non VIP Price Position\":  \"優惠價\",\n",
    "    \"Original Price Position\": \"建議價\",\n",
    "    \"Product Position\":        \"Product name\",\n",
    "    \"Sales Period Position\":   \"優惠期\",\n",
    "    \"FAB Position\":            \"FAB\",\n",
    "}\n",
    "COL_PRODUCT_SKU = \"Product SKU\"\n",
    "COL_ICON_NAME   = \"Icon\"\n",
    "\n",
    "# 圖片連結欄位\n",
    "SKU_IMG_SKU_COL   = \"Product SKU\"\n",
    "SKU_IMG_LINK_COL  = \"Image\"\n",
    "SKU_ICON_NAME_COL = \"Icon\"\n",
    "SKU_ICON_LINK_COL = \"Icon Image\"\n",
    "\n",
    "# 字型（請指到你機器上存在的字型）\n",
    "FONT_REGULAR_PATH = Path.home() / \"Library/Fonts/NotoSansCJKsc-Regular.otf\"\n",
    "FONT_BOLD_PATH    = Path.home() / \"Library/Fonts/NotoSansCJKsc-Bold.otf\"\n",
    "\n",
    "# =================== 工具函式 ===================\n",
    "def safe_str(x): \n",
    "    return \"\" if (x is None or (isinstance(x, float) and pd.isna(x))) else str(x)\n",
    "\n",
    "def count_digits(s): \n",
    "    return sum(ch.isdigit() for ch in safe_str(s))\n",
    "\n",
    "def read_json_file(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    text = path.read_text(encoding=\"utf-8\").strip()\n",
    "    if not text:\n",
    "        raise ValueError(f\"File is empty: {path}\")\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Invalid JSON in {path}\") from e\n",
    "\n",
    "def parse_ls_rect(item):\n",
    "    v = item[\"value\"]\n",
    "    label = v[\"rectanglelabels\"][0] if isinstance(v.get(\"rectanglelabels\"), list) else v.get(\"labels\", [\"\"])[0]\n",
    "    rect_pct = dict(x=v[\"x\"], y=v[\"y\"], w=v[\"width\"], h=v[\"height\"])\n",
    "    ow = item.get(\"original_width\") or item.get(\"image_original_width\")\n",
    "    oh = item.get(\"original_height\") or item.get(\"image_original_height\")\n",
    "    if ow is None or oh is None:\n",
    "        raise KeyError(\"Label Studio item missing original_width/original_height.\")\n",
    "    return label, rect_pct, int(ow), int(oh)\n",
    "\n",
    "def pct_to_px(rpct, ow, oh):\n",
    "    return {\n",
    "        \"x\": rpct[\"x\"] / 100.0 * ow,\n",
    "        \"y\": rpct[\"y\"] / 100.0 * oh,\n",
    "        \"w\": rpct[\"w\"] / 100.0 * ow,\n",
    "        \"h\": rpct[\"h\"] / 100.0 * oh,\n",
    "    }\n",
    "\n",
    "def resize_rect(rect, from_w, from_h, to_w, to_h):\n",
    "    sx, sy = to_w / float(from_w), to_h / float(from_h)\n",
    "    return {\n",
    "        \"x\": rect[\"x\"] * sx,\n",
    "        \"y\": rect[\"y\"] * sy,\n",
    "        \"w\": rect[\"w\"] * sx,\n",
    "        \"h\": rect[\"h\"] * sy,\n",
    "    }\n",
    "\n",
    "def delta_from(gt, init, W, H):\n",
    "    w0 = max(1e-6, float(init[\"w\"]))\n",
    "    h0 = max(1e-6, float(init[\"h\"]))\n",
    "    return {\n",
    "        \"dx\":   (float(gt[\"x\"]) - float(init[\"x\"])) / float(W),\n",
    "        \"dy\":   (float(gt[\"y\"]) - float(init[\"y\"])) / float(H),\n",
    "        \"dlogw\": float(np.log(max(1e-6, float(gt[\"w\"])) / w0)),\n",
    "        \"dlogh\": float(np.log(max(1e-6, float(gt[\"h\"])) / h0)),\n",
    "    }\n",
    "\n",
    "def build_features(meta_row: dict):\n",
    "    title  = safe_str(meta_row.get(\"title\", \"\"))\n",
    "    bullets = safe_str(meta_row.get(\"bullets\", \"\"))\n",
    "    vip    = safe_str(meta_row.get(\"vip_price\", \"\"))\n",
    "    unitp  = safe_str(meta_row.get(\"unit_price\", \"\"))\n",
    "    nonvip = safe_str(meta_row.get(\"non_vip_price\", \"\"))\n",
    "    has_badge = int(str(meta_row.get(\"has_badge\", 0)).strip() not in [\"\", \"0\", \"False\", \"false\"])\n",
    "\n",
    "    feats = {\n",
    "        \"title_len\": len(title),\n",
    "        \"bullets_len\": len(bullets),\n",
    "        \"bullets_lines\": len([b for b in re.split(r\"[;\\n]\", bullets) if b.strip()]),\n",
    "        \"vip_digits\": count_digits(vip),\n",
    "        \"unit_digits\": count_digits(unitp),\n",
    "        \"nonvip_digits\": count_digits(nonvip),\n",
    "        \"has_badge\": has_badge,\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "# =================== 產生訓練 CSV ===================\n",
    "def run_preprocess(label_studio_json: Path, initial_boxes_json: Path, out_csv: Path, meta_csv: Path|None=None):\n",
    "    init_cfg = read_json_file(initial_boxes_json)\n",
    "    Tw = int(init_cfg[\"canvas\"][\"width\"])\n",
    "    Th = int(init_cfg[\"canvas\"][\"height\"])\n",
    "    init_boxes = init_cfg[\"boxes\"]\n",
    "    classes = list(init_boxes.keys())  # 訓練目標順序\n",
    "\n",
    "    meta_df = None\n",
    "    if meta_csv and Path(meta_csv).exists():\n",
    "        meta_df = pd.read_csv(meta_csv)\n",
    "\n",
    "    tasks = read_json_file(label_studio_json)\n",
    "\n",
    "    rows = []\n",
    "    for t in tasks:\n",
    "        img_field = t.get(\"file_upload\") or t.get(\"data\", {}).get(\"image\") or t.get(\"id\")\n",
    "        image_id = Path(str(img_field)).stem\n",
    "\n",
    "        annos = t.get(\"annotations\") or t.get(\"completions\") or []\n",
    "        if not annos:\n",
    "            continue\n",
    "        res = annos[0].get(\"result\", [])\n",
    "\n",
    "        gt_scaled = {}\n",
    "        for r in res:\n",
    "            if r.get(\"type\") not in (\"rectanglelabels\", \"rectangles\"):\n",
    "                continue\n",
    "            label, rpct, ow, oh = parse_ls_rect(r)\n",
    "            if label not in classes:\n",
    "                continue\n",
    "            rect_px = pct_to_px(rpct, ow, oh)\n",
    "            rect_tpl = resize_rect(rect_px, from_w=ow, from_h=oh, to_w=Tw, to_h=Th)\n",
    "            gt_scaled[label] = rect_tpl\n",
    "\n",
    "        row = {\"image_id\": image_id}\n",
    "\n",
    "        if meta_df is not None and \"image_id\" in meta_df.columns:\n",
    "            m = meta_df.loc[meta_df[\"image_id\"] == image_id]\n",
    "            feats = build_features(m.iloc[0].to_dict()) if not m.empty else build_features({})\n",
    "        else:\n",
    "            feats = build_features({})\n",
    "        row.update(feats)\n",
    "\n",
    "        for cls in classes:\n",
    "            init = init_boxes[cls]\n",
    "            gt = gt_scaled.get(cls)\n",
    "            d = {\"dx\": 0.0, \"dy\": 0.0, \"dlogw\": 0.0, \"dlogh\": 0.0} if gt is None else delta_from(gt, init, Tw, Th)\n",
    "            row[f\"{cls}_dx\"]    = d[\"dx\"]\n",
    "            row[f\"{cls}_dy\"]    = d[\"dy\"]\n",
    "            row[f\"{cls}_dlogw\"] = d[\"dlogw\"]\n",
    "            row[f\"{cls}_dlogh\"] = d[\"dlogh\"]\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv, index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "    print(f\"[OK] Saved {out_csv}  rows={len(df)}\")\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "\n",
    "    # 存「訓練時」的類別順序\n",
    "    with open(Path(out_csv).with_suffix(\".classes.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(classes, f, ensure_ascii=False, indent=2)  # [NEW]\n",
    "    print(f\"[INFO] Saved class order -> {Path(out_csv).with_suffix('.classes.json')}\")\n",
    "    return df\n",
    "\n",
    "# 命令列入口\n",
    "def main_cli():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--label_studio_json\", required=True)\n",
    "    ap.add_argument(\"--initial_boxes_json\", required=True)\n",
    "    ap.add_argument(\"--out_csv\", required=True)\n",
    "    ap.add_argument(\"--meta_csv\", default=\"\")\n",
    "    args = ap.parse_args()\n",
    "    run_preprocess(\n",
    "        label_studio_json=Path(args.label_studio_json),\n",
    "        initial_boxes_json=Path(args.initial_boxes_json),\n",
    "        out_csv=Path(args.out_csv),\n",
    "        meta_csv=Path(args.meta_csv) if args.meta_csv else None\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\" and not hasattr(sys.modules[\"__main__\"], \"__file__\"):\n",
    "    pass\n",
    "elif __name__ == \"__main__\":\n",
    "    main_cli()\n",
    "\n",
    "# =================== （可選）重新產生訓練資料 ===================\n",
    "df_FeatureEngineering = run_preprocess(\n",
    "    label_studio_json=Path(\"Objects_positions.json\"),\n",
    "    initial_boxes_json=Path(INITIAL_BOXES_PATH),\n",
    "    out_csv=Path(OUT_CSV),\n",
    "    meta_csv=None\n",
    ")\n",
    "\n",
    "# ===== 建模 =====\n",
    "df = pd.read_csv(OUT_CSV)\n",
    "X = df.drop(columns=[c for c in df.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\")) or c==\"image_id\"])\n",
    "Y = df[[c for c in df.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\"))]]\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(Y_train.shape[1])\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss='mse',\n",
    "              metrics=[MeanSquaredError(), MeanAbsoluteError()])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=50,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# 簡單 sanity check\n",
    "_ = model.predict(X_val[0:1])\n",
    "model.save(MODEL_PATH)\n",
    "with open(SCALER_PATH, \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Model & scaler saved.\")\n",
    "\n",
    "# =================== 產圖所需常用工具 ===================\n",
    "def _load_font(path, size):\n",
    "    return ImageFont.truetype(str(path), size)\n",
    "\n",
    "def _safe(s): return \"\" if (s is None or (isinstance(s, float) and pd.isna(s))) else str(s)\n",
    "def _count_digits(s): return sum(ch.isdigit() for ch in _safe(s))\n",
    "\n",
    "def _norm_key(x):\n",
    "    s = \"\" if pd.isna(x) else str(x)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    return s.strip().casefold()\n",
    "\n",
    "def _drive_share_to_direct(u: str) -> str:\n",
    "    if not u: return u\n",
    "    m = re.search(r\"/d/([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    m = re.search(r\"[?&]id=([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    return u\n",
    "\n",
    "def load_image_any(path_or_url: str):\n",
    "    if not path_or_url:\n",
    "        return None\n",
    "    s = str(path_or_url).strip()\n",
    "    try:\n",
    "        if s.startswith(\"http://\") or s.startswith(\"https://\"):\n",
    "            s2 = _drive_share_to_direct(s)\n",
    "            resp = requests.get(s2, timeout=15)\n",
    "            resp.raise_for_status()\n",
    "            return Image.open(BytesIO(resp.content)).convert(\"RGBA\")\n",
    "        p = Path(s)\n",
    "        if p.exists():\n",
    "            return Image.open(p).convert(\"RGBA\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] cannot load image:\", s, e)\n",
    "    return None\n",
    "\n",
    "FEATURE_ORDER = [\n",
    "    \"title_len\", \"bullets_len\", \"bullets_lines\",\n",
    "    \"vip_digits\", \"unit_digits\", \"nonvip_digits\",\n",
    "    \"has_badge\",\n",
    "]\n",
    "\n",
    "def build_features_from_row(row: pd.Series, resolved_icon_path: str) -> dict:\n",
    "    title   = _safe(row.get(MAP_TEXT[\"Product Position\"], \"\"))\n",
    "    bullets = _safe(row.get(MAP_TEXT[\"FAB Position\"], \"\"))\n",
    "    vip     = _safe(row.get(MAP_TEXT[\"VIP Price Position\"], \"\"))\n",
    "    unitp   = _safe(row.get(MAP_TEXT[\"Non VIP Price Position\"], \"\"))\n",
    "    orig    = _safe(row.get(MAP_TEXT[\"Original Price Position\"], \"\"))\n",
    "    has_icon = int(Path(_safe(resolved_icon_path)).exists()) if resolved_icon_path else 0\n",
    "\n",
    "    return {\n",
    "        \"title_len\": len(title),\n",
    "        \"bullets_len\": len(bullets),\n",
    "        \"bullets_lines\": len([b for b in bullets.split(\";\") if b.strip()]),\n",
    "        \"vip_digits\": _count_digits(vip),\n",
    "        \"unit_digits\": _count_digits(unitp),\n",
    "        \"nonvip_digits\": _count_digits(unitp),  # [FIX] 與訓練時一致（non_vip_price）\n",
    "        \"has_badge\": has_icon,\n",
    "    }\n",
    "\n",
    "def _clip(v, lo, hi):  # [NEW]\n",
    "    return max(lo, min(hi, v))\n",
    "\n",
    "def apply_offset(init_box, delta, W, H):\n",
    "    dx, dy, dlogw, dlogh = map(float, delta)\n",
    "\n",
    "    # [NEW] 位移±0.5 畫布；可按資料調整\n",
    "    dx = _clip(dx, -0.5, 0.5)\n",
    "    dy = _clip(dy, -0.5, 0.5)\n",
    "\n",
    "    # [NEW] 尺寸限制 0.5x~2x\n",
    "    sx = math.exp(_clip(dlogw, math.log(0.5), math.log(2.0)))\n",
    "    sy = math.exp(_clip(dlogh, math.log(0.5), math.log(2.0)))\n",
    "\n",
    "    x = init_box[\"x\"] + dx * W\n",
    "    y = init_box[\"y\"] + dy * H\n",
    "    w = max(24, init_box[\"w\"] * sx)   # [NEW] 最小寬高\n",
    "    h = max(24, init_box[\"h\"] * sy)\n",
    "\n",
    "    # [NEW] 裁進畫布\n",
    "    x = _clip(x, 0, W - w)\n",
    "    y = _clip(y, 0, H - h)\n",
    "\n",
    "    return {\"x\": x, \"y\": y, \"w\": w, \"h\": h}\n",
    "\n",
    "def paste_image_into_box(canvas_rgba, path_or_url, box, padding=6):\n",
    "    im = load_image_any(path_or_url)\n",
    "    if im is None:\n",
    "        print(\"[WARN] image not found:\", path_or_url)\n",
    "        return\n",
    "    x, y, w, h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    w2, h2 = max(1, w - padding*2), max(1, h - padding*2)\n",
    "    ratio = min(w2 / im.width, h2 / im.height)\n",
    "    im = im.resize((max(1,int(im.width*ratio)), max(1,int(im.height*ratio))), Image.LANCZOS)\n",
    "    ox = x + (w - im.width)//2\n",
    "    oy = y + (h - im.height)//2\n",
    "    canvas_rgba.alpha_composite(im, (ox, oy))\n",
    "\n",
    "def draw_text_in_box(draw, text, box, font_path, max_font=64, min_font=16, align=\"left\", line_spacing=1.15):\n",
    "    if not text or str(text).strip()==\"\":\n",
    "        return\n",
    "    x, y, w, h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    text = str(text)\n",
    "\n",
    "    for fs in range(max_font, min_font-1, -2):\n",
    "        font = _load_font(font_path, fs)\n",
    "        approx_chars = max(1, int(w / (fs * 0.55)))\n",
    "        lines = []\n",
    "        for raw in text.split(\"\\n\"):\n",
    "            lines += (textwrap.wrap(raw, width=approx_chars) if approx_chars>1 else [raw])\n",
    "\n",
    "        bboxes = [draw.textbbox((0,0), ln, font=font) for ln in lines]\n",
    "        line_heights = [bb[3]-bb[1] for bb in bboxes]\n",
    "        total_h = int(sum(line_heights) + (len(lines)-1)*fs*(line_spacing-1))\n",
    "        if total_h <= h:\n",
    "            cur_y = y + (h - total_h)//2\n",
    "            for ln in lines:\n",
    "                bb = draw.textbbox((0,0), ln, font=font)\n",
    "                lw = bb[2]-bb[0]\n",
    "                if align == \"center\":\n",
    "                    cur_x = x + (w - lw)//2\n",
    "                elif align == \"right\":\n",
    "                    cur_x = x + (w - lw)\n",
    "                else:\n",
    "                    cur_x = x\n",
    "                draw.text((cur_x, cur_y), ln, font=font, fill=(0,0,0,255))\n",
    "                cur_y += int(fs * line_spacing)\n",
    "            return\n",
    "    draw.text((x, y), text.split(\"\\n\")[0][:30]+\"…\", font=_load_font(font_path, min_font), fill=(0,0,0,255))\n",
    "\n",
    "def _stroke(draw, box, color=(0,0,0,255), width=2):  # [NEW]\n",
    "    x,y,w,h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    draw.rectangle([x,y,x+w,y+h], outline=color, width=width)\n",
    "\n",
    "def load_template_and_boxes():\n",
    "    tpl = Image.open(TEMPLATE_PATH).convert(\"RGBA\")\n",
    "    tw, th = tpl.size\n",
    "    init_cfg = json.loads(Path(INITIAL_BOXES_PATH).read_text(encoding=\"utf-8\"))\n",
    "    cw, ch = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    if (tw, th) != (cw, ch):\n",
    "        sx, sy = tw/float(cw), th/float(ch)\n",
    "        for _, r in init_cfg[\"boxes\"].items():\n",
    "            r[\"x\"], r[\"y\"] = r[\"x\"]*sx, r[\"y\"]*sy\n",
    "            r[\"w\"], r[\"h\"] = r[\"w\"]*sx, r[\"h\"]*sy\n",
    "        init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"] = tw, th\n",
    "        print(f\"[INFO] Scaled initial boxes to {tw}x{th}\")\n",
    "    return tpl, init_cfg\n",
    "\n",
    "def load_model_and_scaler():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH) if Path(MODEL_PATH).exists() else None\n",
    "    scaler = pickle.load(open(SCALER_PATH, \"rb\")) if Path(SCALER_PATH).exists() else None\n",
    "    if model is None:  print(\"[WARN] MODEL not found -> zero offsets\")\n",
    "    if scaler is None: print(\"[WARN] SCALER not found -> use raw features\")\n",
    "    return model, scaler\n",
    "\n",
    "# [NEW] 把目前框存成新的 baseline（可選）\n",
    "def save_as_new_initial_boxes(path, canvas_size, boxes_dict):\n",
    "    data = {\"canvas\": {\"width\": canvas_size[0], \"height\": canvas_size[1]}, \"boxes\": boxes_dict}\n",
    "    Path(path).write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(\"Saved new Initial_boxes to:\", path)\n",
    "\n",
    "# =================== 產圖主流程 ===================\n",
    "def main():\n",
    "    # 讀 Excel\n",
    "    xls = pd.ExcelFile(EXCEL_PATH)\n",
    "    df_user = pd.read_excel(xls, sheet_name=SHEET_USER)\n",
    "    df_img  = pd.read_excel(xls, sheet_name=SHEET_IMG)\n",
    "    df_icon = pd.read_excel(xls, sheet_name=SHEET_ICON)\n",
    "\n",
    "    img_lookup  = {_norm_key(r[SKU_IMG_SKU_COL]): str(r[SKU_IMG_LINK_COL]).strip()\n",
    "                   for _, r in df_img.iterrows() if SKU_IMG_SKU_COL in r and SKU_IMG_LINK_COL in r}\n",
    "    icon_lookup = {_norm_key(r[SKU_ICON_NAME_COL]): str(r[SKU_ICON_LINK_COL]).strip()\n",
    "                   for _, r in df_icon.iterrows() if SKU_ICON_NAME_COL in r and SKU_ICON_LINK_COL in r}\n",
    "\n",
    "    template_rgba, init_cfg = load_template_and_boxes()\n",
    "    W, H = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    INIT_BOXES = init_cfg[\"boxes\"]\n",
    "\n",
    "    # 讀回訓練時的類別順序（避免對錯框）\n",
    "    if CLASS_ORDER_FILE.exists():\n",
    "        train_classes = json.loads(CLASS_ORDER_FILE.read_text(encoding=\"utf-8\"))\n",
    "        if set(train_classes) != set(INIT_BOXES.keys()):\n",
    "            raise ValueError(f\"Classes mismatch.\\nTrain:{train_classes}\\nInfer:{list(INIT_BOXES.keys())}\")\n",
    "        CLASSES = train_classes[:]  # [NEW]\n",
    "    else:\n",
    "        CLASSES = list(INIT_BOXES.keys())\n",
    "\n",
    "    model, scaler = load_model_and_scaler()\n",
    "    printed_pred_once = False\n",
    "\n",
    "    for idx, row in df_user.iterrows():\n",
    "        sku_key  = _norm_key(row.get(COL_PRODUCT_SKU, \"\"))\n",
    "        icon_key = _norm_key(row.get(COL_ICON_NAME, \"\"))\n",
    "\n",
    "        prod_img_path = img_lookup.get(sku_key, \"\")\n",
    "        icon_img_path = icon_lookup.get(icon_key, \"\")\n",
    "\n",
    "        # ==== 特徵 & 預測 ====\n",
    "        if USE_MODEL and (model is not None) and (scaler is not None):\n",
    "            feats = build_features_from_row(row, resolved_icon_path=icon_img_path)\n",
    "            X_df = pd.DataFrame([feats], columns=FEATURE_ORDER).astype(float)   # [FIX] DataFrame 保欄名\n",
    "            X_scaled = scaler.transform(X_df)\n",
    "            pred = model.predict(X_scaled, verbose=0)[0]\n",
    "            pred = pred * BLEND                                                # [NEW] 降暴\n",
    "            if PRINT_FIRST_PRED and (not printed_pred_once):\n",
    "                print(\"Pred deltas (first row, after BLEND):\", pred[:min(12, len(pred))])\n",
    "                printed_pred_once = True\n",
    "            deltas = {cls: pred[i*4:(i+1)*4] for i, cls in enumerate(CLASSES)}\n",
    "        else:\n",
    "            # 零偏移：用 baseline 直接渲染（做對位基準檢查）\n",
    "            deltas = {cls: np.array([0.0, 0.0, 0.0, 0.0]) for cls in CLASSES}  # [NEW]\n",
    "\n",
    "        final_boxes = {cls: apply_offset(INIT_BOXES[cls], deltas[cls], W, H) for cls in CLASSES}\n",
    "\n",
    "        # ==== 繪圖 ====\n",
    "        canvas = template_rgba.copy()\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "        if DRAW_DEBUG_BOXES:\n",
    "            for k,b in final_boxes.items():\n",
    "                _stroke(draw, b)\n",
    "\n",
    "        paste_image_into_box(canvas, prod_img_path, final_boxes[\"Product Image Position\"])\n",
    "        paste_image_into_box(canvas, icon_img_path,  final_boxes[\"Icon Position\"])\n",
    "\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Brand Position\"], \"\"),          final_boxes[\"Brand Position\"],          font_path=FONT_BOLD_PATH,   max_font=72)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Product Position\"], \"\"),        final_boxes[\"Product Position\"],        font_path=FONT_REGULAR_PATH, max_font=64)\n",
    "        fab_text = str(row.get(MAP_TEXT[\"FAB Position\"], \"\") or \"\").replace(\";\", \"\\n\")\n",
    "        draw_text_in_box(draw, fab_text,                                        final_boxes[\"FAB Position\"],            font_path=FONT_REGULAR_PATH, max_font=44)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"VIP Price Position\"], \"\"),      final_boxes[\"VIP Price Position\"],      font_path=FONT_BOLD_PATH,    max_font=100)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Non VIP Price Position\"], \"\"),  final_boxes[\"Non VIP Price Position\"],  font_path=FONT_REGULAR_PATH, max_font=36)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Original Price Position\"], \"\"), final_boxes[\"Original Price Position\"], font_path=FONT_REGULAR_PATH, max_font=32)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Sales Period Position\"], \"\"),   final_boxes[\"Sales Period Position\"],   font_path=FONT_REGULAR_PATH, max_font=28, align=\"right\")\n",
    "\n",
    "        out_path = OUTPUT_DIR / f\"card_cn_{idx+1:03d}.png\"\n",
    "        canvas.convert(\"RGB\").save(out_path, quality=95)\n",
    "        print(\"Saved:\", out_path)\n",
    "\n",
    "    # 想把目前的 final_boxes 存成新的 baseline（人工調好後再解註）：\n",
    "    # save_as_new_initial_boxes(INITIAL_BOXES_PATH, (W, H), final_boxes)  # [NEW]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dcfc2561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved offsets_for_tf.csv  rows=29\n",
      "Columns: ['image_id', 'title_len', 'bullets_len', 'bullets_lines', 'vip_digits', 'unit_digits', 'nonvip_digits', 'has_badge', 'Sales Period Position_dx', 'Sales Period Position_dy', 'Sales Period Position_dlogw', 'Sales Period Position_dlogh', 'Brand Position_dx', 'Brand Position_dy', 'Brand Position_dlogw', 'Brand Position_dlogh', 'Product Position_dx', 'Product Position_dy', 'Product Position_dlogw', 'Product Position_dlogh', 'FAB Position_dx', 'FAB Position_dy', 'FAB Position_dlogw', 'FAB Position_dlogh', 'Product Image Position_dx', 'Product Image Position_dy', 'Product Image Position_dlogw', 'Product Image Position_dlogh', 'VIP Price Position_dx', 'VIP Price Position_dy', 'VIP Price Position_dlogw', 'VIP Price Position_dlogh', 'Non VIP Price Position_dx', 'Non VIP Price Position_dy', 'Non VIP Price Position_dlogw', 'Non VIP Price Position_dlogh', 'Original Price Position_dx', 'Original Price Position_dy', 'Original Price Position_dlogw', 'Original Price Position_dlogh', 'Icon Position_dx', 'Icon Position_dy', 'Icon Position_dlogw', 'Icon Position_dlogh']\n",
      "[INFO] Saved class order -> offsets_for_tf.classes.json\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/boardclick/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.4400 - mean_absolute_error: 0.4151 - mean_squared_error: 0.4400 - val_loss: 0.4119 - val_mean_absolute_error: 0.3985 - val_mean_squared_error: 0.4119\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4387 - mean_absolute_error: 0.4140 - mean_squared_error: 0.4387 - val_loss: 0.4107 - val_mean_absolute_error: 0.3976 - val_mean_squared_error: 0.4107\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4374 - mean_absolute_error: 0.4129 - mean_squared_error: 0.4374 - val_loss: 0.4096 - val_mean_absolute_error: 0.3967 - val_mean_squared_error: 0.4096\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4362 - mean_absolute_error: 0.4118 - mean_squared_error: 0.4362 - val_loss: 0.4085 - val_mean_absolute_error: 0.3959 - val_mean_squared_error: 0.4085\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.4349 - mean_absolute_error: 0.4108 - mean_squared_error: 0.4349 - val_loss: 0.4074 - val_mean_absolute_error: 0.3951 - val_mean_squared_error: 0.4074\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4337 - mean_absolute_error: 0.4097 - mean_squared_error: 0.4337 - val_loss: 0.4063 - val_mean_absolute_error: 0.3944 - val_mean_squared_error: 0.4063\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4325 - mean_absolute_error: 0.4087 - mean_squared_error: 0.4325 - val_loss: 0.4052 - val_mean_absolute_error: 0.3936 - val_mean_squared_error: 0.4052\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4313 - mean_absolute_error: 0.4077 - mean_squared_error: 0.4313 - val_loss: 0.4041 - val_mean_absolute_error: 0.3929 - val_mean_squared_error: 0.4041\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4300 - mean_absolute_error: 0.4067 - mean_squared_error: 0.4300 - val_loss: 0.4030 - val_mean_absolute_error: 0.3922 - val_mean_squared_error: 0.4030\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4288 - mean_absolute_error: 0.4057 - mean_squared_error: 0.4288 - val_loss: 0.4019 - val_mean_absolute_error: 0.3916 - val_mean_squared_error: 0.4019\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4276 - mean_absolute_error: 0.4047 - mean_squared_error: 0.4276 - val_loss: 0.4008 - val_mean_absolute_error: 0.3910 - val_mean_squared_error: 0.4008\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4264 - mean_absolute_error: 0.4038 - mean_squared_error: 0.4264 - val_loss: 0.3997 - val_mean_absolute_error: 0.3903 - val_mean_squared_error: 0.3997\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4252 - mean_absolute_error: 0.4029 - mean_squared_error: 0.4252 - val_loss: 0.3986 - val_mean_absolute_error: 0.3897 - val_mean_squared_error: 0.3986\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4241 - mean_absolute_error: 0.4020 - mean_squared_error: 0.4241 - val_loss: 0.3975 - val_mean_absolute_error: 0.3892 - val_mean_squared_error: 0.3975\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4229 - mean_absolute_error: 0.4011 - mean_squared_error: 0.4229 - val_loss: 0.3965 - val_mean_absolute_error: 0.3886 - val_mean_squared_error: 0.3965\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4217 - mean_absolute_error: 0.4003 - mean_squared_error: 0.4217 - val_loss: 0.3954 - val_mean_absolute_error: 0.3881 - val_mean_squared_error: 0.3954\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4205 - mean_absolute_error: 0.3995 - mean_squared_error: 0.4205 - val_loss: 0.3944 - val_mean_absolute_error: 0.3875 - val_mean_squared_error: 0.3944\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4194 - mean_absolute_error: 0.3987 - mean_squared_error: 0.4194 - val_loss: 0.3933 - val_mean_absolute_error: 0.3870 - val_mean_squared_error: 0.3933\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4183 - mean_absolute_error: 0.3979 - mean_squared_error: 0.4183 - val_loss: 0.3923 - val_mean_absolute_error: 0.3864 - val_mean_squared_error: 0.3923\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.4171 - mean_absolute_error: 0.3971 - mean_squared_error: 0.4171 - val_loss: 0.3913 - val_mean_absolute_error: 0.3859 - val_mean_squared_error: 0.3913\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4160 - mean_absolute_error: 0.3964 - mean_squared_error: 0.4160 - val_loss: 0.3903 - val_mean_absolute_error: 0.3854 - val_mean_squared_error: 0.3903\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.4149 - mean_absolute_error: 0.3956 - mean_squared_error: 0.4149 - val_loss: 0.3892 - val_mean_absolute_error: 0.3849 - val_mean_squared_error: 0.3892\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4138 - mean_absolute_error: 0.3949 - mean_squared_error: 0.4138 - val_loss: 0.3882 - val_mean_absolute_error: 0.3843 - val_mean_squared_error: 0.3882\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.4127 - mean_absolute_error: 0.3942 - mean_squared_error: 0.4127 - val_loss: 0.3873 - val_mean_absolute_error: 0.3838 - val_mean_squared_error: 0.3873\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4116 - mean_absolute_error: 0.3934 - mean_squared_error: 0.4116 - val_loss: 0.3863 - val_mean_absolute_error: 0.3833 - val_mean_squared_error: 0.3863\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4105 - mean_absolute_error: 0.3927 - mean_squared_error: 0.4105 - val_loss: 0.3853 - val_mean_absolute_error: 0.3827 - val_mean_squared_error: 0.3853\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.4094 - mean_absolute_error: 0.3920 - mean_squared_error: 0.4094 - val_loss: 0.3843 - val_mean_absolute_error: 0.3822 - val_mean_squared_error: 0.3843\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4083 - mean_absolute_error: 0.3914 - mean_squared_error: 0.4083 - val_loss: 0.3833 - val_mean_absolute_error: 0.3817 - val_mean_squared_error: 0.3833\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4072 - mean_absolute_error: 0.3907 - mean_squared_error: 0.4072 - val_loss: 0.3824 - val_mean_absolute_error: 0.3812 - val_mean_squared_error: 0.3824\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4062 - mean_absolute_error: 0.3900 - mean_squared_error: 0.4062 - val_loss: 0.3814 - val_mean_absolute_error: 0.3807 - val_mean_squared_error: 0.3814\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4051 - mean_absolute_error: 0.3893 - mean_squared_error: 0.4051 - val_loss: 0.3805 - val_mean_absolute_error: 0.3801 - val_mean_squared_error: 0.3805\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4041 - mean_absolute_error: 0.3887 - mean_squared_error: 0.4041 - val_loss: 0.3795 - val_mean_absolute_error: 0.3796 - val_mean_squared_error: 0.3795\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4030 - mean_absolute_error: 0.3881 - mean_squared_error: 0.4030 - val_loss: 0.3786 - val_mean_absolute_error: 0.3791 - val_mean_squared_error: 0.3786\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4020 - mean_absolute_error: 0.3874 - mean_squared_error: 0.4020 - val_loss: 0.3776 - val_mean_absolute_error: 0.3786 - val_mean_squared_error: 0.3776\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4009 - mean_absolute_error: 0.3868 - mean_squared_error: 0.4009 - val_loss: 0.3767 - val_mean_absolute_error: 0.3781 - val_mean_squared_error: 0.3767\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3999 - mean_absolute_error: 0.3862 - mean_squared_error: 0.3999 - val_loss: 0.3758 - val_mean_absolute_error: 0.3776 - val_mean_squared_error: 0.3758\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3989 - mean_absolute_error: 0.3856 - mean_squared_error: 0.3989 - val_loss: 0.3748 - val_mean_absolute_error: 0.3771 - val_mean_squared_error: 0.3748\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3978 - mean_absolute_error: 0.3850 - mean_squared_error: 0.3978 - val_loss: 0.3739 - val_mean_absolute_error: 0.3766 - val_mean_squared_error: 0.3739\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3969 - mean_absolute_error: 0.3844 - mean_squared_error: 0.3969 - val_loss: 0.3730 - val_mean_absolute_error: 0.3761 - val_mean_squared_error: 0.3730\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3958 - mean_absolute_error: 0.3838 - mean_squared_error: 0.3958 - val_loss: 0.3721 - val_mean_absolute_error: 0.3757 - val_mean_squared_error: 0.3721\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3948 - mean_absolute_error: 0.3832 - mean_squared_error: 0.3948 - val_loss: 0.3712 - val_mean_absolute_error: 0.3753 - val_mean_squared_error: 0.3712\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3938 - mean_absolute_error: 0.3827 - mean_squared_error: 0.3938 - val_loss: 0.3703 - val_mean_absolute_error: 0.3748 - val_mean_squared_error: 0.3703\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3928 - mean_absolute_error: 0.3821 - mean_squared_error: 0.3928 - val_loss: 0.3694 - val_mean_absolute_error: 0.3744 - val_mean_squared_error: 0.3694\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3919 - mean_absolute_error: 0.3816 - mean_squared_error: 0.3919 - val_loss: 0.3685 - val_mean_absolute_error: 0.3739 - val_mean_squared_error: 0.3685\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3909 - mean_absolute_error: 0.3810 - mean_squared_error: 0.3909 - val_loss: 0.3677 - val_mean_absolute_error: 0.3735 - val_mean_squared_error: 0.3677\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3899 - mean_absolute_error: 0.3805 - mean_squared_error: 0.3899 - val_loss: 0.3668 - val_mean_absolute_error: 0.3730 - val_mean_squared_error: 0.3668\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3889 - mean_absolute_error: 0.3799 - mean_squared_error: 0.3889 - val_loss: 0.3659 - val_mean_absolute_error: 0.3726 - val_mean_squared_error: 0.3659\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3880 - mean_absolute_error: 0.3794 - mean_squared_error: 0.3880 - val_loss: 0.3651 - val_mean_absolute_error: 0.3722 - val_mean_squared_error: 0.3651\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3871 - mean_absolute_error: 0.3788 - mean_squared_error: 0.3871 - val_loss: 0.3642 - val_mean_absolute_error: 0.3717 - val_mean_squared_error: 0.3642\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3861 - mean_absolute_error: 0.3783 - mean_squared_error: 0.3861 - val_loss: 0.3634 - val_mean_absolute_error: 0.3713 - val_mean_squared_error: 0.3634\n",
      "[OK] Model & scaler saved.\n",
      "Pred deltas (first row, after BLEND): [-0.03588129  0.08974856  0.11206853 -0.11995057 -0.07746484  0.08568255\n",
      "  0.11995746  0.10999213  0.08874054  0.06154571  0.11638038 -0.11581073]\n",
      "Saved: out_cards_cn/card_cn_001.png\n",
      "Saved: out_cards_cn/card_cn_002.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "完整版：Label Studio → offsets_for_tf.csv → 訓練(tanh+label scaling) → 版面推論與出圖\n",
    "已含：\n",
    "- [FIX] nonvip_digits 特徵與訓練一致\n",
    "- [FIX] sklearn warning：推論時用 DataFrame 給 scaler.transform()\n",
    "- [NEW] 類別順序 *.classes.json 存取，避免訓練/推論順序不一致\n",
    "- [NEW] 模型輸出層 tanh + 標籤縮放（dx,dy=0.3；dlog=0.4）\n",
    "- [NEW] USE_MODEL/BLEND 開關、有描框除錯\n",
    "- [NEW] 邊界保護：位移/縮放/最小尺寸/裁進畫布\n",
    "\"\"\"\n",
    "\n",
    "import json, csv, re, argparse, sys, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "import pickle\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "import unicodedata\n",
    "import requests\n",
    "from io import BytesIO  # [FIX] 給 load_image_any 使用\n",
    "\n",
    "# =================== 全域設定 ===================\n",
    "# 模型/推論控制\n",
    "USE_MODEL = True        # [NEW] 先關掉可做「零偏移」基準測試\n",
    "BLEND = 0.3             # [NEW] 讓模型偏移更保守；零偏移時設 0\n",
    "DRAW_DEBUG_BOXES = True   # [NEW] 畫出預測框方便對位除錯\n",
    "PRINT_FIRST_PRED = True   # [NEW] 印第一筆的預測 delta\n",
    "\n",
    "# Label scaling（對應 tanh 輸出）\n",
    "DX_DY_SCALE = 0.3         # [NEW] dx,dy 的尺度\n",
    "DLOG_SCALE  = 0.4         # [NEW] dlogw,dlogh 的尺度\n",
    "\n",
    "# 檔名/路徑\n",
    "EXCEL_PATH = \"Board Click SKU.xlsx\"\n",
    "SHEET_USER = \"User_Input\"\n",
    "SHEET_IMG  = \"SKU_Image\"\n",
    "SHEET_ICON = \"SKU_Icon\"\n",
    "\n",
    "TEMPLATE_PATH = \"sasa_pink_1280.png\"\n",
    "INITIAL_BOXES_PATH = \"Initial_boxes.json\"\n",
    "\n",
    "MODEL_PATH = \"layout_model.keras\"\n",
    "SCALER_PATH = \"scaler.pkl\"\n",
    "\n",
    "OUT_CSV = \"offsets_for_tf.csv\"     # 訓練資料輸出名（也用來找 .classes.json）\n",
    "CLASS_ORDER_FILE = Path(OUT_CSV).with_suffix(\".classes.json\")  # [NEW]\n",
    "\n",
    "OUTPUT_DIR = Path(\"out_cards_cn\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 欄位映射（Excel→語義）\n",
    "MAP_TEXT = {\n",
    "    \"Brand Position\":          \"Brand\",\n",
    "    \"VIP Price Position\":      \"VIP價\",\n",
    "    \"Non VIP Price Position\":  \"優惠價\",\n",
    "    \"Original Price Position\": \"建議價\",\n",
    "    \"Product Position\":        \"Product name\",\n",
    "    \"Sales Period Position\":   \"優惠期\",\n",
    "    \"FAB Position\":            \"FAB\",\n",
    "}\n",
    "COL_PRODUCT_SKU = \"Product SKU\"\n",
    "COL_ICON_NAME   = \"Icon\"\n",
    "\n",
    "# 圖片連結欄位\n",
    "SKU_IMG_SKU_COL   = \"Product SKU\"\n",
    "SKU_IMG_LINK_COL  = \"Image\"\n",
    "SKU_ICON_NAME_COL = \"Icon\"\n",
    "SKU_ICON_LINK_COL = \"Icon Image\"\n",
    "\n",
    "# 字型（請指到你機器上存在的字型）\n",
    "FONT_REGULAR_PATH = Path.home() / \"Library/Fonts/NotoSansCJKsc-Regular.otf\"\n",
    "FONT_BOLD_PATH    = Path.home() / \"Library/Fonts/NotoSansCJKsc-Bold.otf\"\n",
    "\n",
    "# =================== 共用小工具 ===================\n",
    "def safe_str(x): \n",
    "    return \"\" if (x is None or (isinstance(x, float) and pd.isna(x))) else str(x)\n",
    "\n",
    "def count_digits(s): \n",
    "    return sum(ch.isdigit() for ch in safe_str(s))\n",
    "\n",
    "def read_json_file(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    text = path.read_text(encoding=\"utf-8\").strip()\n",
    "    if not text:\n",
    "        raise ValueError(f\"File is empty: {path}\")\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        preview = text[:200]\n",
    "        raise ValueError(f\"Invalid JSON in {path} (preview: {preview!r})\") from e\n",
    "\n",
    "def parse_ls_rect(item):\n",
    "    v = item[\"value\"]\n",
    "    label = v[\"rectanglelabels\"][0] if isinstance(v.get(\"rectanglelabels\"), list) else v.get(\"labels\", [\"\"])[0]\n",
    "    rect_pct = dict(x=v[\"x\"], y=v[\"y\"], w=v[\"width\"], h=v[\"height\"])\n",
    "    ow = item.get(\"original_width\") or item.get(\"image_original_width\")\n",
    "    oh = item.get(\"original_height\") or item.get(\"image_original_height\")\n",
    "    if ow is None or oh is None:\n",
    "        raise KeyError(\"Label Studio item missing original_width/original_height.\")\n",
    "    return label, rect_pct, int(ow), int(oh)\n",
    "\n",
    "def pct_to_px(rpct, ow, oh):\n",
    "    return {\"x\": rpct[\"x\"]/100.0*ow, \"y\": rpct[\"y\"]/100.0*oh, \"w\": rpct[\"w\"]/100.0*ow, \"h\": rpct[\"h\"]/100.0*oh}\n",
    "\n",
    "def resize_rect(rect, from_w, from_h, to_w, to_h):\n",
    "    sx, sy = to_w/float(from_w), to_h/float(from_h)\n",
    "    return {\"x\": rect[\"x\"]*sx, \"y\": rect[\"y\"]*sy, \"w\": rect[\"w\"]*sx, \"h\": rect[\"h\"]*sy}\n",
    "\n",
    "def delta_from(gt, init, W, H):\n",
    "    w0 = max(1e-6, float(init[\"w\"]))\n",
    "    h0 = max(1e-6, float(init[\"h\"]))\n",
    "    return {\n",
    "        \"dx\":   (float(gt[\"x\"]) - float(init[\"x\"])) / float(W),\n",
    "        \"dy\":   (float(gt[\"y\"]) - float(init[\"y\"])) / float(H),\n",
    "        \"dlogw\": float(np.log(max(1e-6, float(gt[\"w\"])) / w0)),\n",
    "        \"dlogh\": float(np.log(max(1e-6, float(gt[\"h\"])) / h0)),\n",
    "    }\n",
    "\n",
    "def _load_font(path, size): return ImageFont.truetype(str(path), size)\n",
    "def _safe(s): return \"\" if (s is None or (isinstance(s, float) and pd.isna(s))) else str(s)\n",
    "def _count_digits(s): return sum(ch.isdigit() for ch in _safe(s))\n",
    "\n",
    "def _norm_key(x):\n",
    "    s = \"\" if pd.isna(x) else str(x)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    return s.strip().casefold()\n",
    "\n",
    "def _drive_share_to_direct(u: str) -> str:\n",
    "    if not u: return u\n",
    "    m = re.search(r\"/d/([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    m = re.search(r\"[?&]id=([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    return u\n",
    "\n",
    "def load_image_any(path_or_url: str):\n",
    "    if not path_or_url:\n",
    "        return None\n",
    "    s = str(path_or_url).strip()\n",
    "    try:\n",
    "        if s.startswith(\"http://\") or s.startswith(\"https://\"):\n",
    "            s2 = _drive_share_to_direct(s)\n",
    "            resp = requests.get(s2, timeout=15)\n",
    "            resp.raise_for_status()\n",
    "            return Image.open(BytesIO(resp.content)).convert(\"RGBA\")\n",
    "        p = Path(s)\n",
    "        if p.exists():\n",
    "            return Image.open(p).convert(\"RGBA\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] cannot load image:\", s, e)\n",
    "    return None\n",
    "\n",
    "def paste_image_into_box(canvas_rgba, path_or_url, box, padding=6):\n",
    "    im = load_image_any(path_or_url)\n",
    "    if im is None:\n",
    "        print(\"[WARN] image not found:\", path_or_url)\n",
    "        return\n",
    "    x, y, w, h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    w2, h2 = max(1, w - padding*2), max(1, h - padding*2)\n",
    "    ratio = min(w2 / im.width, h2 / im.height)\n",
    "    im = im.resize((max(1,int(im.width*ratio)), max(1,int(im.height*ratio))), Image.LANCZOS)\n",
    "    ox = x + (w - im.width)//2\n",
    "    oy = y + (h - im.height)//2\n",
    "    canvas_rgba.alpha_composite(im, (ox, oy))\n",
    "\n",
    "def draw_text_in_box(draw, text, box, font_path, max_font=64, min_font=16, align=\"left\", line_spacing=1.15):\n",
    "    if not text or str(text).strip()==\"\":\n",
    "        return\n",
    "    x, y, w, h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    text = str(text)\n",
    "\n",
    "    for fs in range(max_font, min_font-1, -2):\n",
    "        font = _load_font(font_path, fs)\n",
    "        approx_chars = max(1, int(w / (fs * 0.55)))\n",
    "        lines = []\n",
    "        for raw in text.split(\"\\n\"):\n",
    "            lines += (textwrap.wrap(raw, width=approx_chars) if approx_chars>1 else [raw])\n",
    "\n",
    "        bboxes = [draw.textbbox((0,0), ln, font=font) for ln in lines]\n",
    "        line_heights = [bb[3]-bb[1] for bb in bboxes]\n",
    "        total_h = int(sum(line_heights) + (len(lines)-1)*fs*(line_spacing-1))\n",
    "        if total_h <= h:\n",
    "            cur_y = y + (h - total_h)//2\n",
    "            for ln in lines:\n",
    "                bb = draw.textbbox((0,0), ln, font=font)\n",
    "                lw = bb[2]-bb[0]\n",
    "                if align == \"center\":\n",
    "                    cur_x = x + (w - lw)//2\n",
    "                elif align == \"right\":\n",
    "                    cur_x = x + (w - lw)\n",
    "                else:\n",
    "                    cur_x = x\n",
    "                draw.text((cur_x, cur_y), ln, font=font, fill=(0,0,0,255))\n",
    "                cur_y += int(fs * line_spacing)\n",
    "            return\n",
    "    draw.text((x, y), text.split(\"\\n\")[0][:30]+\"…\", font=_load_font(font_path, min_font), fill=(0,0,0,255))\n",
    "\n",
    "def _stroke(draw, box, color=(0,0,0,255), width=2):  # [NEW] 偵錯描框\n",
    "    x,y,w,h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    draw.rectangle([x,y,x+w,y+h], outline=color, width=width)\n",
    "\n",
    "def _clip(v, lo, hi):  # [NEW]\n",
    "    return max(lo, min(hi, v))\n",
    "\n",
    "# =================== 特徵工程（與訓練一致） ===================\n",
    "FEATURE_ORDER = [\n",
    "    \"title_len\", \"bullets_len\", \"bullets_lines\",\n",
    "    \"vip_digits\", \"unit_digits\", \"nonvip_digits\",\n",
    "    \"has_badge\",\n",
    "]\n",
    "\n",
    "def build_features(meta_row: dict):\n",
    "    title  = safe_str(meta_row.get(\"title\", \"\"))\n",
    "    bullets = safe_str(meta_row.get(\"bullets\", \"\"))\n",
    "    vip    = safe_str(meta_row.get(\"vip_price\", \"\"))\n",
    "    unitp  = safe_str(meta_row.get(\"unit_price\", \"\"))\n",
    "    nonvip = safe_str(meta_row.get(\"non_vip_price\", \"\"))\n",
    "    has_badge = int(str(meta_row.get(\"has_badge\", 0)).strip() not in [\"\", \"0\", \"False\", \"false\"])\n",
    "\n",
    "    feats = {\n",
    "        \"title_len\": len(title),\n",
    "        \"bullets_len\": len(bullets),\n",
    "        \"bullets_lines\": len([b for b in re.split(r\"[;\\n]\", bullets) if b.strip()]),\n",
    "        \"vip_digits\": count_digits(vip),\n",
    "        \"unit_digits\": count_digits(unitp),\n",
    "        \"nonvip_digits\": count_digits(nonvip),\n",
    "        \"has_badge\": has_badge,\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "def build_features_from_row(row: pd.Series, resolved_icon_path: str) -> dict:\n",
    "    title   = _safe(row.get(MAP_TEXT[\"Product Position\"], \"\"))\n",
    "    bullets = _safe(row.get(MAP_TEXT[\"FAB Position\"], \"\"))\n",
    "    vip     = _safe(row.get(MAP_TEXT[\"VIP Price Position\"], \"\"))\n",
    "    unitp   = _safe(row.get(MAP_TEXT[\"Non VIP Price Position\"], \"\"))\n",
    "    orig    = _safe(row.get(MAP_TEXT[\"Original Price Position\"], \"\"))\n",
    "    has_icon = int(Path(_safe(resolved_icon_path)).exists()) if resolved_icon_path else 0\n",
    "\n",
    "    return {\n",
    "        \"title_len\": len(title),\n",
    "        \"bullets_len\": len(bullets),\n",
    "        \"bullets_lines\": len([b for b in bullets.split(\";\") if b.strip()]),\n",
    "        \"vip_digits\": _count_digits(vip),\n",
    "        \"unit_digits\": _count_digits(unitp),\n",
    "        \"nonvip_digits\": _count_digits(unitp),  # [FIX] 與訓練一致（non_vip_price）\n",
    "        \"has_badge\": has_icon,\n",
    "    }\n",
    "\n",
    "# =================== 產生訓練 CSV ===================\n",
    "def run_preprocess(label_studio_json: Path, initial_boxes_json: Path, out_csv: Path, meta_csv: Path|None=None):\n",
    "    init_cfg = read_json_file(initial_boxes_json)\n",
    "    Tw = int(init_cfg[\"canvas\"][\"width\"])\n",
    "    Th = int(init_cfg[\"canvas\"][\"height\"])\n",
    "    init_boxes = init_cfg[\"boxes\"]\n",
    "    classes = list(init_boxes.keys())\n",
    "\n",
    "    meta_df = None\n",
    "    if meta_csv and Path(meta_csv).exists():\n",
    "        meta_df = pd.read_csv(meta_csv)\n",
    "\n",
    "    tasks = read_json_file(label_studio_json)\n",
    "\n",
    "    rows = []\n",
    "    for t in tasks:\n",
    "        img_field = t.get(\"file_upload\") or t.get(\"data\", {}).get(\"image\") or t.get(\"id\")\n",
    "        image_id = Path(str(img_field)).stem\n",
    "\n",
    "        annos = t.get(\"annotations\") or t.get(\"completions\") or []\n",
    "        if not annos: continue\n",
    "        res = annos[0].get(\"result\", [])\n",
    "\n",
    "        gt_scaled = {}\n",
    "        for r in res:\n",
    "            if r.get(\"type\") not in (\"rectanglelabels\", \"rectangles\"): continue\n",
    "            label, rpct, ow, oh = parse_ls_rect(r)\n",
    "            if label not in classes: continue\n",
    "            rect_px = pct_to_px(rpct, ow, oh)\n",
    "            rect_tpl = resize_rect(rect_px, from_w=ow, from_h=oh, to_w=Tw, to_h=Th)\n",
    "            gt_scaled[label] = rect_tpl\n",
    "\n",
    "        row = {\"image_id\": image_id}\n",
    "\n",
    "        if meta_df is not None and \"image_id\" in meta_df.columns:\n",
    "            m = meta_df.loc[meta_df[\"image_id\"] == image_id]\n",
    "            feats = build_features(m.iloc[0].to_dict()) if not m.empty else build_features({})\n",
    "        else:\n",
    "            feats = build_features({})\n",
    "        row.update(feats)\n",
    "\n",
    "        for cls in classes:\n",
    "            init = init_boxes[cls]\n",
    "            gt = gt_scaled.get(cls)\n",
    "            if gt is None:\n",
    "                d = {\"dx\": 0.0, \"dy\": 0.0, \"dlogw\": 0.0, \"dlogh\": 0.0}\n",
    "            else:\n",
    "                d = delta_from(gt, init, Tw, Th)\n",
    "            row[f\"{cls}_dx\"]    = d[\"dx\"]\n",
    "            row[f\"{cls}_dy\"]    = d[\"dy\"]\n",
    "            row[f\"{cls}_dlogw\"] = d[\"dlogw\"]\n",
    "            row[f\"{cls}_dlogh\"] = d[\"dlogh\"]\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv, index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "    print(f\"[OK] Saved {out_csv}  rows={len(df)}\")\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "\n",
    "    # [NEW] 存「訓練時」的類別順序\n",
    "    with open(Path(out_csv).with_suffix(\".classes.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(classes, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"[INFO] Saved class order -> {Path(out_csv).with_suffix('.classes.json')}\")\n",
    "    return df\n",
    "\n",
    "# =================== 模型訓練（tanh + 標籤縮放） ===================\n",
    "def train_model():\n",
    "    df = pd.read_csv(OUT_CSV)\n",
    "\n",
    "    X = df.drop(columns=[c for c in df.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\")) or c==\"image_id\"])\n",
    "    Y = df[[c for c in df.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\"))]]\n",
    "\n",
    "    # [NEW] Label scaling：把標籤壓到 ~[-1,1]\n",
    "    Y_scaled = Y.copy()\n",
    "    for c in Y.columns:\n",
    "        if c.endswith((\"_dx\", \"_dy\")):\n",
    "            Y_scaled[c] = Y[c] / DX_DY_SCALE\n",
    "        else:\n",
    "            Y_scaled[c] = Y[c] / DLOG_SCALE\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val   = scaler.transform(X_val)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(Y_train.shape[1], activation='tanh')  # [NEW] 限制輸出在 [-1,1]\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss='mse',\n",
    "        metrics=[MeanSquaredError(), MeanAbsoluteError()]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, Y_train,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        epochs=50,\n",
    "        batch_size=16,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.save(MODEL_PATH)\n",
    "    with open(SCALER_PATH, \"wb\") as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    print(\"[OK] Model & scaler saved.\")\n",
    "\n",
    "# =================== 模板與初始盒 ===================\n",
    "def load_template_and_boxes():\n",
    "    tpl = Image.open(TEMPLATE_PATH).convert(\"RGBA\")\n",
    "    tw, th = tpl.size\n",
    "    init_cfg = json.loads(Path(INITIAL_BOXES_PATH).read_text(encoding=\"utf-8\"))\n",
    "    cw, ch = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    if (tw, th) != (cw, ch):\n",
    "        sx, sy = tw/float(cw), th/float(ch)\n",
    "        for _, r in init_cfg[\"boxes\"].items():\n",
    "            r[\"x\"], r[\"y\"] = r[\"x\"]*sx, r[\"y\"]*sy\n",
    "            r[\"w\"], r[\"h\"] = r[\"w\"]*sx, r[\"h\"]*sy\n",
    "        init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"] = tw, th\n",
    "        print(f\"[INFO] Scaled initial boxes to {tw}x{th}\")\n",
    "    return tpl, init_cfg\n",
    "\n",
    "def load_model_and_scaler():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH) if Path(MODEL_PATH).exists() else None\n",
    "    scaler = pickle.load(open(SCALER_PATH, \"rb\")) if Path(SCALER_PATH).exists() else None\n",
    "    if model is None:  print(\"[WARN] MODEL not found → zero offsets\")\n",
    "    if scaler is None: print(\"[WARN] SCALER not found → use raw features\")\n",
    "    return model, scaler\n",
    "\n",
    "# =================== 推論（還原縮放） ===================\n",
    "def predict_offsets(model, scaler, feats: dict, classes: list) -> np.ndarray:\n",
    "    # [FIX] DataFrame + 指定欄名，避免 sklearn warning\n",
    "    X_df = pd.DataFrame([feats], columns=FEATURE_ORDER).astype(float)\n",
    "    X_scaled = scaler.transform(X_df) if scaler is not None else X_df.values\n",
    "    if model is not None:\n",
    "        pred_scaled = model.predict(X_scaled, verbose=0)[0]\n",
    "    else:\n",
    "        pred_scaled = np.zeros(len(classes)*4, dtype=float)\n",
    "\n",
    "    # 還原尺度\n",
    "    restored = []\n",
    "    for i in range(len(classes)):\n",
    "        dx = pred_scaled[i*4+0] * DX_DY_SCALE\n",
    "        dy = pred_scaled[i*4+1] * DX_DY_SCALE\n",
    "        dw = pred_scaled[i*4+2] * DLOG_SCALE\n",
    "        dh = pred_scaled[i*4+3] * DLOG_SCALE\n",
    "        restored.extend([dx, dy, dw, dh])\n",
    "    return np.array(restored, dtype=float)\n",
    "\n",
    "# =================== 幾何 / 佈局 ===================\n",
    "def apply_offset(init_box, delta, W, H):\n",
    "    dx, dy, dlogw, dlogh = map(float, delta)\n",
    "\n",
    "    # [NEW] 位移限制（避免飛出半張圖；可依據資料調整）\n",
    "    dx = _clip(dx, -0.5, 0.5)\n",
    "    dy = _clip(dy, -0.5, 0.5)\n",
    "\n",
    "    # [NEW] 尺寸縮放限制（0.5x ~ 2x）\n",
    "    sx = math.exp(_clip(dlogw, math.log(0.5), math.log(2.0)))\n",
    "    sy = math.exp(_clip(dlogh, math.log(0.5), math.log(2.0)))\n",
    "\n",
    "    x = init_box[\"x\"] + dx * W\n",
    "    y = init_box[\"y\"] + dy * H\n",
    "    w = max(24, init_box[\"w\"] * sx)  # 最小寬/高\n",
    "    h = max(24, init_box[\"h\"] * sy)\n",
    "\n",
    "    # [NEW] 裁進畫布\n",
    "    x = _clip(x, 0, W - w)\n",
    "    y = _clip(y, 0, H - h)\n",
    "\n",
    "    return {\"x\": x, \"y\": y, \"w\": w, \"h\": h}\n",
    "\n",
    "# =================== 主流程（推論 & 畫圖） ===================\n",
    "def main_render():\n",
    "    # 讀 Excel\n",
    "    xls = pd.ExcelFile(EXCEL_PATH)\n",
    "    df_user = pd.read_excel(xls, sheet_name=SHEET_USER)\n",
    "    df_img  = pd.read_excel(xls, sheet_name=SHEET_IMG)\n",
    "    df_icon = pd.read_excel(xls, sheet_name=SHEET_ICON)\n",
    "\n",
    "    img_lookup  = {_norm_key(r[SKU_IMG_SKU_COL]): str(r[SKU_IMG_LINK_COL]).strip()\n",
    "                   for _, r in df_img.iterrows() if SKU_IMG_SKU_COL in r and SKU_IMG_LINK_COL in r}\n",
    "    icon_lookup = {_norm_key(r[SKU_ICON_NAME_COL]): str(r[SKU_ICON_LINK_COL]).strip()\n",
    "                   for _, r in df_icon.iterrows() if SKU_ICON_NAME_COL in r and SKU_ICON_LINK_COL in r}\n",
    "\n",
    "    template_rgba, init_cfg = load_template_and_boxes()\n",
    "    W, H = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    INIT_BOXES = init_cfg[\"boxes\"]\n",
    "\n",
    "    # [NEW] 讀回訓練時的類別順序（避免對錯框）\n",
    "    if CLASS_ORDER_FILE.exists():\n",
    "        train_classes = json.loads(CLASS_ORDER_FILE.read_text(encoding=\"utf-8\"))\n",
    "        if set(train_classes) != set(INIT_BOXES.keys()):\n",
    "            raise ValueError(f\"Classes mismatch.\\nTrain:{train_classes}\\nInfer:{list(INIT_BOXES.keys())}\")\n",
    "        CLASSES = train_classes[:]\n",
    "    else:\n",
    "        CLASSES = list(INIT_BOXES.keys())\n",
    "\n",
    "    model, scaler = load_model_and_scaler()\n",
    "    printed_pred_once = False\n",
    "\n",
    "    for idx, row in df_user.iterrows():\n",
    "        sku_key  = _norm_key(row.get(COL_PRODUCT_SKU, \"\"))\n",
    "        icon_key = _norm_key(row.get(COL_ICON_NAME, \"\"))\n",
    "\n",
    "        prod_img_path = img_lookup.get(sku_key, \"\")\n",
    "        icon_img_path = icon_lookup.get(icon_key, \"\")\n",
    "\n",
    "        # 特徵\n",
    "        feats = build_features_from_row(row, resolved_icon_path=icon_img_path)\n",
    "\n",
    "        # 預測 offsets（還原尺度）\n",
    "        if USE_MODEL and (model is not None) and (scaler is not None):\n",
    "            pred = predict_offsets(model, scaler, feats, CLASSES)\n",
    "            pred = pred * BLEND  # [NEW] 降暴（可逐步拉到 1.0）\n",
    "            if PRINT_FIRST_PRED and (not printed_pred_once):\n",
    "                print(\"Pred deltas (first row, after BLEND):\", pred[:min(12, len(pred))])\n",
    "                printed_pred_once = True\n",
    "        else:\n",
    "            pred = np.zeros(len(CLASSES)*4, dtype=float)\n",
    "\n",
    "        # 轉成 per-class 的 delta\n",
    "        deltas = {cls: pred[i*4:(i+1)*4] for i, cls in enumerate(CLASSES)}\n",
    "        final_boxes = {cls: apply_offset(INIT_BOXES[cls], deltas[cls], W, H) for cls in CLASSES}\n",
    "\n",
    "        # 繪圖\n",
    "        canvas = template_rgba.copy()\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "        if DRAW_DEBUG_BOXES:\n",
    "            for k,b in final_boxes.items():\n",
    "                _stroke(draw, b)\n",
    "\n",
    "        paste_image_into_box(canvas, prod_img_path, final_boxes[\"Product Image Position\"])\n",
    "        paste_image_into_box(canvas, icon_img_path,  final_boxes[\"Icon Position\"])\n",
    "\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Brand Position\"], \"\"),          final_boxes[\"Brand Position\"],          font_path=FONT_BOLD_PATH,   max_font=72)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Product Position\"], \"\"),        final_boxes[\"Product Position\"],        font_path=FONT_REGULAR_PATH, max_font=64)\n",
    "        fab_text = str(row.get(MAP_TEXT[\"FAB Position\"], \"\") or \"\").replace(\";\", \"\\n\")\n",
    "        draw_text_in_box(draw, fab_text,                                        final_boxes[\"FAB Position\"],            font_path=FONT_REGULAR_PATH, max_font=44)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"VIP Price Position\"], \"\"),      final_boxes[\"VIP Price Position\"],      font_path=FONT_BOLD_PATH,    max_font=100)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Non VIP Price Position\"], \"\"),  final_boxes[\"Non VIP Price Position\"],  font_path=FONT_REGULAR_PATH, max_font=36)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Original Price Position\"], \"\"), final_boxes[\"Original Price Position\"], font_path=FONT_REGULAR_PATH, max_font=32)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Sales Period Position\"], \"\"),   final_boxes[\"Sales Period Position\"],   font_path=FONT_REGULAR_PATH, max_font=28, align=\"right\")\n",
    "\n",
    "        out_path = OUTPUT_DIR / f\"card_cn_{idx+1:03d}.png\"\n",
    "        canvas.convert(\"RGB\").save(out_path, quality=95)\n",
    "        print(\"Saved:\", out_path)\n",
    "\n",
    "# =================== 可直接使用的入口 ===================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) 只需重生訓練資料時開啟：\n",
    "    run_preprocess(Path(\"Objects_positions.json\"), Path(INITIAL_BOXES_PATH), Path(OUT_CSV), meta_csv=None)\n",
    "\n",
    "    # 2) 需要重訓時開啟（建議 baseline 調好後重訓）：\n",
    "    train_model()\n",
    "\n",
    "    # 3) 出圖\n",
    "    main_render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "89378aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved offsets_for_tf.csv rows=29\n",
      "[INFO] Augmented 29→319\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/boardclick/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.6948 - mean_absolute_error: 1.0028 - mean_squared_error: 1.6948 - val_loss: 1.8303 - val_mean_absolute_error: 1.0315 - val_mean_squared_error: 1.8303\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6780 - mean_absolute_error: 0.9977 - mean_squared_error: 1.6780 - val_loss: 1.8129 - val_mean_absolute_error: 1.0262 - val_mean_squared_error: 1.8129\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6617 - mean_absolute_error: 0.9927 - mean_squared_error: 1.6617 - val_loss: 1.7958 - val_mean_absolute_error: 1.0210 - val_mean_squared_error: 1.7958\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6458 - mean_absolute_error: 0.9878 - mean_squared_error: 1.6458 - val_loss: 1.7792 - val_mean_absolute_error: 1.0159 - val_mean_squared_error: 1.7792\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6305 - mean_absolute_error: 0.9831 - mean_squared_error: 1.6305 - val_loss: 1.7629 - val_mean_absolute_error: 1.0110 - val_mean_squared_error: 1.7629\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6154 - mean_absolute_error: 0.9785 - mean_squared_error: 1.6154 - val_loss: 1.7472 - val_mean_absolute_error: 1.0062 - val_mean_squared_error: 1.7472\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6009 - mean_absolute_error: 0.9741 - mean_squared_error: 1.6009 - val_loss: 1.7319 - val_mean_absolute_error: 1.0016 - val_mean_squared_error: 1.7319\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5867 - mean_absolute_error: 0.9697 - mean_squared_error: 1.5867 - val_loss: 1.7172 - val_mean_absolute_error: 0.9972 - val_mean_squared_error: 1.7172\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5731 - mean_absolute_error: 0.9655 - mean_squared_error: 1.5731 - val_loss: 1.7028 - val_mean_absolute_error: 0.9928 - val_mean_squared_error: 1.7028\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5599 - mean_absolute_error: 0.9615 - mean_squared_error: 1.5599 - val_loss: 1.6888 - val_mean_absolute_error: 0.9885 - val_mean_squared_error: 1.6888\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5469 - mean_absolute_error: 0.9575 - mean_squared_error: 1.5469 - val_loss: 1.6754 - val_mean_absolute_error: 0.9844 - val_mean_squared_error: 1.6754\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5345 - mean_absolute_error: 0.9537 - mean_squared_error: 1.5345 - val_loss: 1.6623 - val_mean_absolute_error: 0.9804 - val_mean_squared_error: 1.6623\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5224 - mean_absolute_error: 0.9500 - mean_squared_error: 1.5224 - val_loss: 1.6496 - val_mean_absolute_error: 0.9766 - val_mean_squared_error: 1.6496\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5107 - mean_absolute_error: 0.9464 - mean_squared_error: 1.5107 - val_loss: 1.6373 - val_mean_absolute_error: 0.9729 - val_mean_squared_error: 1.6373\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4994 - mean_absolute_error: 0.9429 - mean_squared_error: 1.4994 - val_loss: 1.6252 - val_mean_absolute_error: 0.9693 - val_mean_squared_error: 1.6252\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4884 - mean_absolute_error: 0.9395 - mean_squared_error: 1.4884 - val_loss: 1.6137 - val_mean_absolute_error: 0.9658 - val_mean_squared_error: 1.6137\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4778 - mean_absolute_error: 0.9362 - mean_squared_error: 1.4778 - val_loss: 1.6025 - val_mean_absolute_error: 0.9625 - val_mean_squared_error: 1.6025\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4675 - mean_absolute_error: 0.9331 - mean_squared_error: 1.4675 - val_loss: 1.5917 - val_mean_absolute_error: 0.9592 - val_mean_squared_error: 1.5917\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4576 - mean_absolute_error: 0.9300 - mean_squared_error: 1.4576 - val_loss: 1.5811 - val_mean_absolute_error: 0.9560 - val_mean_squared_error: 1.5811\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4479 - mean_absolute_error: 0.9270 - mean_squared_error: 1.4479 - val_loss: 1.5709 - val_mean_absolute_error: 0.9529 - val_mean_squared_error: 1.5709\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4386 - mean_absolute_error: 0.9241 - mean_squared_error: 1.4386 - val_loss: 1.5610 - val_mean_absolute_error: 0.9499 - val_mean_squared_error: 1.5610\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4296 - mean_absolute_error: 0.9213 - mean_squared_error: 1.4296 - val_loss: 1.5515 - val_mean_absolute_error: 0.9469 - val_mean_squared_error: 1.5515\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4209 - mean_absolute_error: 0.9186 - mean_squared_error: 1.4209 - val_loss: 1.5422 - val_mean_absolute_error: 0.9441 - val_mean_squared_error: 1.5422\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4124 - mean_absolute_error: 0.9159 - mean_squared_error: 1.4124 - val_loss: 1.5333 - val_mean_absolute_error: 0.9413 - val_mean_squared_error: 1.5333\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4043 - mean_absolute_error: 0.9134 - mean_squared_error: 1.4043 - val_loss: 1.5246 - val_mean_absolute_error: 0.9386 - val_mean_squared_error: 1.5246\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3964 - mean_absolute_error: 0.9109 - mean_squared_error: 1.3964 - val_loss: 1.5162 - val_mean_absolute_error: 0.9360 - val_mean_squared_error: 1.5162\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3888 - mean_absolute_error: 0.9085 - mean_squared_error: 1.3888 - val_loss: 1.5080 - val_mean_absolute_error: 0.9335 - val_mean_squared_error: 1.5080\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3813 - mean_absolute_error: 0.9062 - mean_squared_error: 1.3813 - val_loss: 1.5003 - val_mean_absolute_error: 0.9310 - val_mean_squared_error: 1.5003\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3742 - mean_absolute_error: 0.9039 - mean_squared_error: 1.3742 - val_loss: 1.4926 - val_mean_absolute_error: 0.9286 - val_mean_squared_error: 1.4926\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3673 - mean_absolute_error: 0.9017 - mean_squared_error: 1.3673 - val_loss: 1.4852 - val_mean_absolute_error: 0.9263 - val_mean_squared_error: 1.4852\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3606 - mean_absolute_error: 0.8996 - mean_squared_error: 1.3606 - val_loss: 1.4779 - val_mean_absolute_error: 0.9240 - val_mean_squared_error: 1.4779\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3541 - mean_absolute_error: 0.8975 - mean_squared_error: 1.3541 - val_loss: 1.4711 - val_mean_absolute_error: 0.9218 - val_mean_squared_error: 1.4711\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3479 - mean_absolute_error: 0.8955 - mean_squared_error: 1.3479 - val_loss: 1.4644 - val_mean_absolute_error: 0.9197 - val_mean_squared_error: 1.4644\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3418 - mean_absolute_error: 0.8936 - mean_squared_error: 1.3418 - val_loss: 1.4579 - val_mean_absolute_error: 0.9176 - val_mean_squared_error: 1.4579\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3359 - mean_absolute_error: 0.8917 - mean_squared_error: 1.3359 - val_loss: 1.4517 - val_mean_absolute_error: 0.9156 - val_mean_squared_error: 1.4517\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3302 - mean_absolute_error: 0.8899 - mean_squared_error: 1.3302 - val_loss: 1.4456 - val_mean_absolute_error: 0.9136 - val_mean_squared_error: 1.4456\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3247 - mean_absolute_error: 0.8881 - mean_squared_error: 1.3247 - val_loss: 1.4396 - val_mean_absolute_error: 0.9117 - val_mean_squared_error: 1.4396\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3193 - mean_absolute_error: 0.8864 - mean_squared_error: 1.3193 - val_loss: 1.4340 - val_mean_absolute_error: 0.9098 - val_mean_squared_error: 1.4340\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3142 - mean_absolute_error: 0.8848 - mean_squared_error: 1.3142 - val_loss: 1.4284 - val_mean_absolute_error: 0.9080 - val_mean_squared_error: 1.4284\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3093 - mean_absolute_error: 0.8832 - mean_squared_error: 1.3093 - val_loss: 1.4229 - val_mean_absolute_error: 0.9063 - val_mean_squared_error: 1.4229\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3044 - mean_absolute_error: 0.8816 - mean_squared_error: 1.3044 - val_loss: 1.4178 - val_mean_absolute_error: 0.9046 - val_mean_squared_error: 1.4178\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2998 - mean_absolute_error: 0.8801 - mean_squared_error: 1.2998 - val_loss: 1.4127 - val_mean_absolute_error: 0.9029 - val_mean_squared_error: 1.4127\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2951 - mean_absolute_error: 0.8786 - mean_squared_error: 1.2951 - val_loss: 1.4078 - val_mean_absolute_error: 0.9014 - val_mean_squared_error: 1.4078\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2907 - mean_absolute_error: 0.8772 - mean_squared_error: 1.2907 - val_loss: 1.4032 - val_mean_absolute_error: 0.8998 - val_mean_squared_error: 1.4032\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2865 - mean_absolute_error: 0.8758 - mean_squared_error: 1.2865 - val_loss: 1.3986 - val_mean_absolute_error: 0.8983 - val_mean_squared_error: 1.3986\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2823 - mean_absolute_error: 0.8744 - mean_squared_error: 1.2823 - val_loss: 1.3942 - val_mean_absolute_error: 0.8969 - val_mean_squared_error: 1.3942\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2783 - mean_absolute_error: 0.8732 - mean_squared_error: 1.2783 - val_loss: 1.3897 - val_mean_absolute_error: 0.8954 - val_mean_squared_error: 1.3897\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2744 - mean_absolute_error: 0.8719 - mean_squared_error: 1.2744 - val_loss: 1.3855 - val_mean_absolute_error: 0.8940 - val_mean_squared_error: 1.3855\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2707 - mean_absolute_error: 0.8707 - mean_squared_error: 1.2707 - val_loss: 1.3814 - val_mean_absolute_error: 0.8927 - val_mean_squared_error: 1.3814\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2670 - mean_absolute_error: 0.8695 - mean_squared_error: 1.2670 - val_loss: 1.3774 - val_mean_absolute_error: 0.8914 - val_mean_squared_error: 1.3774\n",
      "[OK] Model saved\n",
      "Pred deltas (first row, scaled back): [ 0.36447355  0.98114973 -0.9998476  -0.7875153  -0.9999791  -0.8588515\n",
      " -0.98990905  0.99302804  0.66861    -0.06957391  0.91311455 -0.05312146]\n",
      "Saved: out_cards_cn/card_cn_001.png\n",
      "Saved: out_cards_cn/card_cn_002.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Label Studio → offsets_for_tf.csv → Augmentation → Train(tanh+scaling) → Render\n",
    "包含：\n",
    "- [FIX] nonvip_digits 特徵一致\n",
    "- [FIX] 用 DataFrame 餵 scaler.transform() 避免 sklearn warning\n",
    "- [NEW] 類別順序 *.classes.json 存取/檢查，避免訓練/推論順序不一致\n",
    "- [NEW] 模型輸出層 tanh + 標籤縮放（dx,dy=0.3；dlog=0.4）\n",
    "- [NEW] Augmentation（擾動 baseline offsets）以擴增資料量\n",
    "\"\"\"\n",
    "\n",
    "import json, csv, re, argparse, sys, math, random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "import pickle\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "import unicodedata\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# =================== 全域設定 ===================\n",
    "USE_MODEL = True\n",
    "BLEND = 0.2\n",
    "DRAW_DEBUG_BOXES = True\n",
    "PRINT_FIRST_PRED = True\n",
    "\n",
    "# Label scaling（對應 tanh 輸出），推論要乘回\n",
    "DX_DY_SCALE = 0.1\n",
    "DLOG_SCALE  = 0.25\n",
    "\n",
    "EXCEL_PATH = \"Board Click SKU.xlsx\"\n",
    "SHEET_USER = \"User_Input\"\n",
    "SHEET_IMG  = \"SKU_Image\"\n",
    "SHEET_ICON = \"SKU_Icon\"\n",
    "\n",
    "TEMPLATE_PATH = \"sasa_pink_1280.png\"\n",
    "INITIAL_BOXES_PATH = \"Initial_boxes.json\"\n",
    "\n",
    "MODEL_PATH = \"layout_model.keras\"\n",
    "SCALER_PATH = \"scaler.pkl\"\n",
    "\n",
    "OUT_CSV = \"offsets_for_tf.csv\"\n",
    "CLASS_ORDER_FILE = Path(OUT_CSV).with_suffix(\".classes.json\")  # [NEW]\n",
    "\n",
    "OUTPUT_DIR = Path(\"out_cards_cn\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MAP_TEXT = {\n",
    "    \"Brand Position\":          \"Brand\",\n",
    "    \"VIP Price Position\":      \"VIP價\",\n",
    "    \"Non VIP Price Position\":  \"優惠價\",\n",
    "    \"Original Price Position\": \"建議價\",\n",
    "    \"Product Position\":        \"Product name\",\n",
    "    \"Sales Period Position\":   \"優惠期\",\n",
    "    \"FAB Position\":            \"FAB\",\n",
    "}\n",
    "COL_PRODUCT_SKU = \"Product SKU\"\n",
    "COL_ICON_NAME   = \"Icon\"\n",
    "\n",
    "SKU_IMG_SKU_COL   = \"Product SKU\"\n",
    "SKU_IMG_LINK_COL  = \"Image\"\n",
    "SKU_ICON_NAME_COL = \"Icon\"\n",
    "SKU_ICON_LINK_COL = \"Icon Image\"\n",
    "\n",
    "# 字型（請改成你電腦的實際字型路徑）\n",
    "FONT_REGULAR_PATH = Path.home() / \"Library/Fonts/NotoSansCJKsc-Regular.otf\"\n",
    "FONT_BOLD_PATH    = Path.home() / \"Library/Fonts/NotoSansCJKsc-Bold.otf\"\n",
    "\n",
    "# =================== 工具 ===================\n",
    "def safe_str(x): \n",
    "    return \"\" if (x is None or (isinstance(x,float) and pd.isna(x))) else str(x)\n",
    "\n",
    "def count_digits(s): \n",
    "    return sum(ch.isdigit() for ch in safe_str(s))\n",
    "\n",
    "def read_json_file(path: Path):\n",
    "    text = path.read_text(encoding=\"utf-8\").strip()\n",
    "    return json.loads(text)\n",
    "\n",
    "def parse_ls_rect(item):\n",
    "    v = item[\"value\"]\n",
    "    label = v[\"rectanglelabels\"][0] if isinstance(v.get(\"rectanglelabels\"), list) else v.get(\"labels\", [\"\"])[0]\n",
    "    rect_pct = dict(x=v[\"x\"], y=v[\"y\"], w=v[\"width\"], h=v[\"height\"])\n",
    "    ow = item.get(\"original_width\") or item.get(\"image_original_width\")\n",
    "    oh = item.get(\"original_height\") or item.get(\"image_original_height\")\n",
    "    return label, rect_pct, int(ow), int(oh)\n",
    "\n",
    "def pct_to_px(rpct, ow, oh):\n",
    "    return {\"x\": rpct[\"x\"]/100.0*ow, \"y\": rpct[\"y\"]/100.0*oh, \"w\": rpct[\"w\"]/100.0*ow, \"h\": rpct[\"h\"]/100.0*oh}\n",
    "\n",
    "def resize_rect(rect, from_w, from_h, to_w, to_h):\n",
    "    sx, sy = to_w/float(from_w), to_h/float(from_h)\n",
    "    return {\"x\": rect[\"x\"]*sx, \"y\": rect[\"y\"]*sy, \"w\": rect[\"w\"]*sx, \"h\": rect[\"h\"]*sy}\n",
    "\n",
    "def delta_from(gt, init, W, H):\n",
    "    w0 = max(1e-6, float(init[\"w\"]))\n",
    "    h0 = max(1e-6, float(init[\"h\"]))\n",
    "    return {\n",
    "        \"dx\":   (float(gt[\"x\"]) - float(init[\"x\"])) / float(W),\n",
    "        \"dy\":   (float(gt[\"y\"]) - float(init[\"y\"])) / float(H),\n",
    "        \"dlogw\": float(np.log(max(1e-6,float(gt[\"w\"])) / w0)),\n",
    "        \"dlogh\": float(np.log(max(1e-6,float(gt[\"h\"])) / h0)),\n",
    "    }\n",
    "\n",
    "def _load_font(path, size): return ImageFont.truetype(str(path), size)\n",
    "def _safe(s): return \"\" if (s is None or (isinstance(s,float) and pd.isna(s))) else str(s)\n",
    "def _count_digits(s): return sum(ch.isdigit() for ch in _safe(s))\n",
    "\n",
    "def _norm_key(x):\n",
    "    s = \"\" if pd.isna(x) else str(x)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    return s.strip().casefold()\n",
    "\n",
    "def _drive_share_to_direct(u: str) -> str:\n",
    "    if not u: return u\n",
    "    m = re.search(r\"/d/([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    m = re.search(r\"[?&]id=([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    return u\n",
    "\n",
    "def load_image_any(path_or_url: str):\n",
    "    try:\n",
    "        s = str(path_or_url).strip()\n",
    "        if s.startswith(\"http\"):\n",
    "            resp = requests.get(_drive_share_to_direct(s), timeout=15)\n",
    "            resp.raise_for_status()\n",
    "            return Image.open(BytesIO(resp.content)).convert(\"RGBA\")\n",
    "        p = Path(s)\n",
    "        if p.exists(): return Image.open(p).convert(\"RGBA\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] cannot load image:\", path_or_url, e)\n",
    "    return None\n",
    "\n",
    "def paste_image_into_box(canvas_rgba, path_or_url, box, padding=6):\n",
    "    im = load_image_any(path_or_url)\n",
    "    if im is None: return\n",
    "    x,y,w,h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    w2,h2 = max(1,w-padding*2), max(1,h-padding*2)\n",
    "    ratio = min(w2/im.width, h2/im.height)\n",
    "    im = im.resize((max(1,int(im.width*ratio)), max(1,int(im.height*ratio))), Image.LANCZOS)\n",
    "    ox = x+(w-im.width)//2\n",
    "    oy = y+(h-im.height)//2\n",
    "    canvas_rgba.alpha_composite(im,(ox,oy))\n",
    "\n",
    "def draw_text_in_box(draw,text,box,font_path,max_font=64,min_font=16,align=\"left\",line_spacing=1.15):\n",
    "    if not text or str(text).strip()==\"\": return\n",
    "    x,y,w,h = int(box[\"x\"]),int(box[\"y\"]),int(box[\"w\"]),int(box[\"h\"])\n",
    "    text = str(text)\n",
    "    for fs in range(max_font,min_font-1,-2):\n",
    "        font = _load_font(font_path, fs)\n",
    "        approx_chars = max(1,int(w/(fs*0.55)))\n",
    "        lines=[]\n",
    "        for raw in text.split(\"\\n\"):\n",
    "            lines += (textwrap.wrap(raw,width=approx_chars) if approx_chars>1 else [raw])\n",
    "        bboxes=[draw.textbbox((0,0),ln,font=font) for ln in lines]\n",
    "        total_h=int(sum(bb[3]-bb[1] for bb in bboxes)+(len(lines)-1)*fs*(line_spacing-1))\n",
    "        if total_h<=h:\n",
    "            cur_y=y+(h-total_h)//2\n",
    "            for ln in lines:\n",
    "                bb=draw.textbbox((0,0),ln,font=font)\n",
    "                lw=bb[2]-bb[0]\n",
    "                cur_x=x if align==\"left\" else (x+(w-lw)//2 if align==\"center\" else x+(w-lw))\n",
    "                draw.text((cur_x,cur_y),ln,font=font,fill=(0,0,0,255))\n",
    "                cur_y+=int(fs*line_spacing)\n",
    "            return\n",
    "\n",
    "def _stroke(draw, box, color=(0,0,0,255), width=2):\n",
    "    x,y,w,h = int(box[\"x\"]),int(box[\"y\"]),int(box[\"w\"]),int(box[\"h\"])\n",
    "    draw.rectangle([x,y,x+w,y+h], outline=color, width=width)\n",
    "\n",
    "def _clip(v, lo, hi): return max(lo, min(hi,v))\n",
    "\n",
    "# =================== 特徵 ===================\n",
    "FEATURE_ORDER = [\"title_len\",\"bullets_len\",\"bullets_lines\",\"vip_digits\",\"unit_digits\",\"nonvip_digits\",\"has_badge\"]\n",
    "\n",
    "def build_features(meta_row: dict):\n",
    "    return {\n",
    "        \"title_len\": len(safe_str(meta_row.get(\"title\",\"\"))),\n",
    "        \"bullets_len\": len(safe_str(meta_row.get(\"bullets\",\"\"))),\n",
    "        \"bullets_lines\": len([b for b in re.split(r\"[;\\n]\", safe_str(meta_row.get(\"bullets\",\"\"))) if b.strip()]),\n",
    "        \"vip_digits\": count_digits(meta_row.get(\"vip_price\",\"\")),\n",
    "        \"unit_digits\": count_digits(meta_row.get(\"unit_price\",\"\")),\n",
    "        \"nonvip_digits\": count_digits(meta_row.get(\"non_vip_price\",\"\")),\n",
    "        \"has_badge\": int(str(meta_row.get(\"has_badge\",0)).strip() not in [\"\",\"0\",\"False\",\"false\"]),\n",
    "    }\n",
    "\n",
    "def build_features_from_row(row: pd.Series, resolved_icon_path: str) -> dict:\n",
    "    return {\n",
    "        \"title_len\": len(_safe(row.get(MAP_TEXT[\"Product Position\"],\"\"))),\n",
    "        \"bullets_len\": len(_safe(row.get(MAP_TEXT[\"FAB Position\"],\"\"))),\n",
    "        \"bullets_lines\": len([b for b in _safe(row.get(MAP_TEXT[\"FAB Position\"],\"\")).split(\";\") if b.strip()]),\n",
    "        \"vip_digits\": _count_digits(row.get(MAP_TEXT[\"VIP Price Position\"],\"\")),\n",
    "        \"unit_digits\": _count_digits(row.get(MAP_TEXT[\"Non VIP Price Position\"],\"\")),\n",
    "        \"nonvip_digits\": _count_digits(row.get(MAP_TEXT[\"Non VIP Price Position\"],\"\")),  # [FIX]\n",
    "        \"has_badge\": int(Path(_safe(resolved_icon_path)).exists()) if resolved_icon_path else 0,\n",
    "    }\n",
    "\n",
    "# =================== Preprocess → CSV ===================\n",
    "def run_preprocess(label_studio_json: Path, initial_boxes_json: Path, out_csv: Path, meta_csv: Path|None=None):\n",
    "    init_cfg = read_json_file(initial_boxes_json)\n",
    "    Tw, Th = int(init_cfg[\"canvas\"][\"width\"]), int(init_cfg[\"canvas\"][\"height\"])\n",
    "    init_boxes = init_cfg[\"boxes\"]\n",
    "    classes = list(init_boxes.keys())\n",
    "\n",
    "    tasks = read_json_file(label_studio_json)\n",
    "    rows=[]\n",
    "    for t in tasks:\n",
    "        annos = t.get(\"annotations\") or []\n",
    "        if not annos: continue\n",
    "        res = annos[0].get(\"result\", [])\n",
    "        gt_scaled={}\n",
    "        for r in res:\n",
    "            if r.get(\"type\") not in (\"rectanglelabels\",\"rectangles\"): continue\n",
    "            label, rpct, ow, oh = parse_ls_rect(r)\n",
    "            if label not in classes: continue\n",
    "            rect_px = pct_to_px(rpct, ow, oh)\n",
    "            rect_tpl = resize_rect(rect_px, ow, oh, Tw, Th)\n",
    "            gt_scaled[label]=rect_tpl\n",
    "        row={\"image_id\":t.get(\"id\")}\n",
    "        feats=build_features({})\n",
    "        row.update(feats)\n",
    "        for cls in classes:\n",
    "            init=init_boxes[cls]; gt=gt_scaled.get(cls)\n",
    "            d=delta_from(gt,init,Tw,Th) if gt else {\"dx\":0,\"dy\":0,\"dlogw\":0,\"dlogh\":0}\n",
    "            for k,v in d.items(): row[f\"{cls}_{k}\"]=v\n",
    "        rows.append(row)\n",
    "    df=pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv,index=False)\n",
    "    class_file = out_csv.with_suffix(\".classes.json\")\n",
    "    json.dump(classes, open(class_file, \"w\", encoding=\"utf-8\"), ensure_ascii=False, indent=2) # [NEW]\n",
    "    print(f\"[OK] Saved {out_csv} rows={len(df)}\")\n",
    "    return df\n",
    "\n",
    "# =================== Augmentation ===================\n",
    "def augment_offsets(df, classes, num_aug=10):\n",
    "    aug_rows=[]\n",
    "    for _, row in df.iterrows():\n",
    "        for _ in range(num_aug):\n",
    "            new_row=row.copy()\n",
    "            for cls in classes:\n",
    "                new_row[f\"{cls}_dx\"]=row[f\"{cls}_dx\"]+random.uniform(-0.15,0.15)\n",
    "                new_row[f\"{cls}_dy\"]=row[f\"{cls}_dy\"]+random.uniform(-0.15,0.15)\n",
    "                new_row[f\"{cls}_dlogw\"]=row[f\"{cls}_dlogw\"]+random.uniform(-0.2,0.2)\n",
    "                new_row[f\"{cls}_dlogh\"]=row[f\"{cls}_dlogh\"]+random.uniform(-0.2,0.2)\n",
    "            aug_rows.append(new_row)\n",
    "    return pd.concat([df,pd.DataFrame(aug_rows)],ignore_index=True)\n",
    "\n",
    "# =================== 訓練（tanh + label scaling） ===================\n",
    "def train_model():\n",
    "    df=pd.read_csv(OUT_CSV)\n",
    "    classes=json.load(open(CLASS_ORDER_FILE, \"r\", encoding=\"utf-8\"))\n",
    "    df_aug=augment_offsets(df,classes,num_aug=10)\n",
    "    print(f\"[INFO] Augmented {len(df)}→{len(df_aug)}\")\n",
    "    X=df_aug.drop(columns=[c for c in df_aug.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\")) or c==\"image_id\"])\n",
    "    Y=df_aug[[c for c in df_aug.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\"))]]\n",
    "    Y_scaled=Y.copy()\n",
    "    for c in Y.columns:\n",
    "        if c.endswith((\"_dx\",\"_dy\")): Y_scaled[c]=Y[c]/DX_DY_SCALE\n",
    "        else: Y_scaled[c]=Y[c]/DLOG_SCALE\n",
    "    Xtr,Xv,Ytr,Yv=train_test_split(X,Y_scaled,test_size=0.2,random_state=42)\n",
    "    scaler=StandardScaler(); Xtr=scaler.fit_transform(Xtr); Xv=scaler.transform(Xv)\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128,activation='relu',input_shape=(Xtr.shape[1],)),\n",
    "        tf.keras.layers.Dense(64,activation='relu'),\n",
    "        tf.keras.layers.Dense(Ytr.shape[1],activation='tanh')  # [NEW]\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),loss='mse',metrics=[MeanSquaredError(),MeanAbsoluteError()])\n",
    "    model.fit(Xtr,Ytr,validation_data=(Xv,Yv),epochs=50,batch_size=16,verbose=1)\n",
    "    model.save(MODEL_PATH); pickle.dump(scaler,open(SCALER_PATH,\"wb\"))\n",
    "    print(\"[OK] Model saved\")\n",
    "\n",
    "# =================== 幾何 / 佈局 ===================\n",
    "def apply_offset(init_box, delta, W, H):\n",
    "    dx, dy, dlogw, dlogh = map(float, delta)\n",
    "    # （可選）安全範圍限制\n",
    "    dx = _clip(dx, -0.5, 0.5)          # [NEW] 避免飛太遠\n",
    "    dy = _clip(dy, -0.5, 0.5)          # [NEW]\n",
    "    sx = math.exp(_clip(dlogw, math.log(0.5), math.log(2.0)))  # [NEW]\n",
    "    sy = math.exp(_clip(dlogh, math.log(0.5), math.log(2.0)))  # [NEW]\n",
    "    x = init_box[\"x\"] + dx * W\n",
    "    y = init_box[\"y\"] + dy * H\n",
    "    w = max(24, init_box[\"w\"] * sx)\n",
    "    h = max(24, init_box[\"h\"] * sy)\n",
    "    x = _clip(x, 0, W - w)             # [NEW] 裁進畫布\n",
    "    y = _clip(y, 0, H - h)             # [NEW]\n",
    "    return {\"x\": x, \"y\": y, \"w\": w, \"h\": h}\n",
    "\n",
    "# =================== 模型 + Scaler 載入 ===================\n",
    "def load_template_and_boxes():\n",
    "    tpl = Image.open(TEMPLATE_PATH).convert(\"RGBA\")\n",
    "    tw, th = tpl.size\n",
    "    init_cfg = json.loads(Path(INITIAL_BOXES_PATH).read_text(encoding=\"utf-8\"))\n",
    "    cw, ch = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    if (tw, th) != (cw, ch):\n",
    "        sx, sy = tw/float(cw), th/float(ch)\n",
    "        for _, r in init_cfg[\"boxes\"].items():\n",
    "            r[\"x\"], r[\"y\"] = r[\"x\"]*sx, r[\"y\"]*sy\n",
    "            r[\"w\"], r[\"h\"] = r[\"w\"]*sx, r[\"h\"]*sy\n",
    "        init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"] = tw, th\n",
    "        print(f\"[INFO] Scaled initial boxes to {tw}x{th}\")\n",
    "    return tpl, init_cfg\n",
    "\n",
    "def load_model_and_scaler():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH) if Path(MODEL_PATH).exists() else None\n",
    "    scaler = pickle.load(open(SCALER_PATH,\"rb\")) if Path(SCALER_PATH).exists() else None\n",
    "    if model is None:  print(\"[WARN] MODEL not found → zero offsets\")\n",
    "    if scaler is None: print(\"[WARN] SCALER not found → use raw features\")\n",
    "    return model, scaler\n",
    "\n",
    "# =================== 渲染主程式 ===================\n",
    "def main_render():\n",
    "    # 讀 Excel\n",
    "    xls = pd.ExcelFile(EXCEL_PATH)\n",
    "    df_user = pd.read_excel(xls, sheet_name=SHEET_USER)\n",
    "    df_img  = pd.read_excel(xls, sheet_name=SHEET_IMG)\n",
    "    df_icon = pd.read_excel(xls, sheet_name=SHEET_ICON)\n",
    "\n",
    "    # 建查表\n",
    "    img_lookup  = {_norm_key(r[SKU_IMG_SKU_COL]): str(r[SKU_IMG_LINK_COL]).strip() for _, r in df_img.iterrows()}\n",
    "    icon_lookup = {_norm_key(r[SKU_ICON_NAME_COL]): str(r[SKU_ICON_LINK_COL]).strip() for _, r in df_icon.iterrows()}\n",
    "\n",
    "    # 載入模板與模型\n",
    "    template_rgba, init_cfg = load_template_and_boxes()\n",
    "    W, H = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    INIT_BOXES = init_cfg[\"boxes\"]\n",
    "\n",
    "    # [FIX] 讀回訓練時類別順序，並檢查集合一致\n",
    "    if CLASS_ORDER_FILE.exists():\n",
    "        train_classes = json.load(open(CLASS_ORDER_FILE, \"r\", encoding=\"utf-8\"))\n",
    "        if set(train_classes) != set(INIT_BOXES.keys()):\n",
    "            raise ValueError(f\"Classes mismatch.\\nTrain: {train_classes}\\nInfer: {list(INIT_BOXES.keys())}\")\n",
    "        CLASSES = train_classes[:]\n",
    "    else:\n",
    "        CLASSES = list(INIT_BOXES.keys())\n",
    "\n",
    "    model, scaler = load_model_and_scaler()\n",
    "\n",
    "    # 逐列生成\n",
    "    for idx, row in df_user.iterrows():\n",
    "        sku_key  = _norm_key(row.get(COL_PRODUCT_SKU, \"\"))\n",
    "        icon_key = _norm_key(row.get(COL_ICON_NAME, \"\"))\n",
    "        prod_img_path = img_lookup.get(sku_key, \"\")\n",
    "        icon_img_path = icon_lookup.get(icon_key, \"\")\n",
    "\n",
    "        # 特徵 → DataFrame 給 scaler（避免 sklearn warning）\n",
    "        feats = build_features_from_row(row, resolved_icon_path=icon_img_path)\n",
    "        X_df = pd.DataFrame([feats], columns=FEATURE_ORDER).astype(float)  # [FIX]\n",
    "        X_in = scaler.transform(X_df) if scaler is not None else X_df.values\n",
    "\n",
    "        # baseline offsets (全 0)\n",
    "        deltas_base = {cls: [0.0,0.0,0.0,0.0] for cls in CLASSES}\n",
    "\n",
    "        # 預測 offsets（tanh 輸出需乘回 label scaling）\n",
    "        if USE_MODEL and model is not None:\n",
    "            pred = model.predict(X_in, verbose=0)[0]\n",
    "            deltas_pred = {}\n",
    "            for i, cls in enumerate(CLASSES):\n",
    "                dx = float(pred[i*4+0]) * DX_DY_SCALE\n",
    "                dy = float(pred[i*4+1]) * DX_DY_SCALE\n",
    "                dw = float(pred[i*4+2]) * DLOG_SCALE\n",
    "                dh = float(pred[i*4+3]) * DLOG_SCALE\n",
    "                deltas_pred[cls] = [dx,dy,dw,dh]\n",
    "        else:\n",
    "            deltas_pred = deltas_base\n",
    "\n",
    "        if idx == 0 and PRINT_FIRST_PRED and USE_MODEL and (model is not None):  # [FIX]\n",
    "            print(\"Pred deltas (first row, scaled back):\", pred[:min(12, len(pred))])\n",
    "\n",
    "        # blend baseline 與 model\n",
    "        deltas_final = {}\n",
    "        for cls in CLASSES:\n",
    "            db = deltas_base[cls]; dp = deltas_pred[cls]\n",
    "            deltas_final[cls] = [(1-BLEND)*db[i] + BLEND*dp[i] for i in range(4)]\n",
    "\n",
    "        final_boxes = {cls: apply_offset(INIT_BOXES[cls], deltas_final[cls], W, H) for cls in CLASSES}\n",
    "\n",
    "        # 繪圖\n",
    "        canvas = template_rgba.copy()\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "        paste_image_into_box(canvas, prod_img_path, final_boxes[\"Product Image Position\"])\n",
    "        paste_image_into_box(canvas, icon_img_path,  final_boxes[\"Icon Position\"])\n",
    "\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Brand Position\"], \"\"),          final_boxes[\"Brand Position\"],          font_path=FONT_BOLD_PATH,   max_font=72)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Product Position\"], \"\"),        final_boxes[\"Product Position\"],        font_path=FONT_REGULAR_PATH,max_font=64)\n",
    "        fab_text = str(row.get(MAP_TEXT[\"FAB Position\"], \"\") or \"\").replace(\";\", \"\\n\")\n",
    "        draw_text_in_box(draw, fab_text,                                        final_boxes[\"FAB Position\"],            font_path=FONT_REGULAR_PATH,max_font=44)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"VIP Price Position\"], \"\"),      final_boxes[\"VIP Price Position\"],      font_path=FONT_BOLD_PATH,   max_font=100)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Non VIP Price Position\"], \"\"),  final_boxes[\"Non VIP Price Position\"],  font_path=FONT_REGULAR_PATH,max_font=36)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Original Price Position\"], \"\"), final_boxes[\"Original Price Position\"], font_path=FONT_REGULAR_PATH,max_font=32)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Sales Period Position\"], \"\"),   final_boxes[\"Sales Period Position\"],   font_path=FONT_REGULAR_PATH,max_font=28, align=\"right\")\n",
    "\n",
    "        if DRAW_DEBUG_BOXES:\n",
    "            for cls, box in final_boxes.items():\n",
    "                _stroke(draw, box, (255,0,0,180), 2)\n",
    "\n",
    "        out_path = OUTPUT_DIR / f\"card_cn_{idx+1:03d}.png\"\n",
    "        canvas.convert(\"RGB\").save(out_path, quality=95)\n",
    "        print(\"Saved:\", out_path)\n",
    "\n",
    "# =================== 主程式 ===================\n",
    "if __name__ == \"__main__\":\n",
    "    # --- 首次完整流程（生資料 → 訓練 → 出圖），跑完再註解 ---\n",
    "    run_preprocess(Path(\"Objects_positions.json\"), Path(INITIAL_BOXES_PATH), Path(OUT_CSV), meta_csv=None)\n",
    "    train_model()\n",
    "    # main_render()\n",
    "\n",
    "    # --- 日常出圖（已經有模型與 scaler） ---\n",
    "    main_render()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardclick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
