{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df090ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv, re, argparse, sys, math, random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "import pickle\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "import unicodedata\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472249e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 全域設定 ===================\n",
    "USE_MODEL = True\n",
    "BLEND = 0.2\n",
    "DRAW_DEBUG_BOXES = True\n",
    "PRINT_FIRST_PRED = True\n",
    "\n",
    "# Label scaling（對應 tanh 輸出），推論要乘回\n",
    "DX_DY_SCALE = 0.1\n",
    "DLOG_SCALE  = 0.25\n",
    "\n",
    "EXCEL_PATH = \"Board Click SKU.xlsx\"\n",
    "SHEET_USER = \"User_Input\"\n",
    "SHEET_IMG  = \"SKU_Image\"\n",
    "SHEET_ICON = \"SKU_Icon\"\n",
    "\n",
    "TEMPLATE_PATH = \"sasa_pink_1280.png\"\n",
    "INITIAL_BOXES_PATH = \"Initial_boxes.json\"\n",
    "\n",
    "MODEL_PATH = \"layout_model.keras\"\n",
    "SCALER_PATH = \"scaler.pkl\"\n",
    "\n",
    "OUT_CSV = \"offsets_for_tf.csv\"\n",
    "CLASS_ORDER_FILE = Path(OUT_CSV).with_suffix(\".classes.json\")  # [NEW]\n",
    "\n",
    "OUTPUT_DIR = Path(\"out_cards_cn\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MAP_TEXT = {\n",
    "    \"Brand Position\":          \"Brand\",\n",
    "    \"VIP Price Position\":      \"VIP價\",\n",
    "    \"Non VIP Price Position\":  \"優惠價\",\n",
    "    \"Original Price Position\": \"建議價\",\n",
    "    \"Product Position\":        \"Product name\",\n",
    "    \"Sales Period Position\":   \"優惠期\",\n",
    "    \"FAB Position\":            \"FAB\",\n",
    "}\n",
    "COL_PRODUCT_SKU = \"Product SKU\"\n",
    "COL_ICON_NAME   = \"Icon\"\n",
    "\n",
    "SKU_IMG_SKU_COL   = \"Product SKU\"\n",
    "SKU_IMG_LINK_COL  = \"Image\"\n",
    "SKU_ICON_NAME_COL = \"Icon\"\n",
    "SKU_ICON_LINK_COL = \"Icon Image\"\n",
    "\n",
    "# 字型（請改成你電腦的實際字型路徑）\n",
    "FONT_REGULAR_PATH = Path.home() / \"Library/Fonts/NotoSansCJKsc-Regular.otf\"\n",
    "FONT_BOLD_PATH    = Path.home() / \"Library/Fonts/NotoSansCJKsc-Bold.otf\"\n",
    "\n",
    "# =================== 工具 ===================\n",
    "def safe_str(x): \n",
    "    return \"\" if (x is None or (isinstance(x,float) and pd.isna(x))) else str(x)\n",
    "\n",
    "def count_digits(s): \n",
    "    return sum(ch.isdigit() for ch in safe_str(s))\n",
    "\n",
    "def read_json_file(path: Path):\n",
    "    text = path.read_text(encoding=\"utf-8\").strip()\n",
    "    return json.loads(text)\n",
    "\n",
    "def parse_ls_rect(item):\n",
    "    v = item[\"value\"]\n",
    "    label = v[\"rectanglelabels\"][0] if isinstance(v.get(\"rectanglelabels\"), list) else v.get(\"labels\", [\"\"])[0]\n",
    "    rect_pct = dict(x=v[\"x\"], y=v[\"y\"], w=v[\"width\"], h=v[\"height\"])\n",
    "    ow = item.get(\"original_width\") or item.get(\"image_original_width\")\n",
    "    oh = item.get(\"original_height\") or item.get(\"image_original_height\")\n",
    "    return label, rect_pct, int(ow), int(oh)\n",
    "\n",
    "def pct_to_px(rpct, ow, oh):\n",
    "    return {\"x\": rpct[\"x\"]/100.0*ow, \"y\": rpct[\"y\"]/100.0*oh, \"w\": rpct[\"w\"]/100.0*ow, \"h\": rpct[\"h\"]/100.0*oh}\n",
    "\n",
    "def resize_rect(rect, from_w, from_h, to_w, to_h):\n",
    "    sx, sy = to_w/float(from_w), to_h/float(from_h)\n",
    "    return {\"x\": rect[\"x\"]*sx, \"y\": rect[\"y\"]*sy, \"w\": rect[\"w\"]*sx, \"h\": rect[\"h\"]*sy}\n",
    "\n",
    "def delta_from(gt, init, W, H):\n",
    "    w0 = max(1e-6, float(init[\"w\"]))\n",
    "    h0 = max(1e-6, float(init[\"h\"]))\n",
    "    return {\n",
    "        \"dx\":   (float(gt[\"x\"]) - float(init[\"x\"])) / float(W),\n",
    "        \"dy\":   (float(gt[\"y\"]) - float(init[\"y\"])) / float(H),\n",
    "        \"dlogw\": float(np.log(max(1e-6,float(gt[\"w\"])) / w0)),\n",
    "        \"dlogh\": float(np.log(max(1e-6,float(gt[\"h\"])) / h0)),\n",
    "    }\n",
    "\n",
    "def _load_font(path, size): return ImageFont.truetype(str(path), size)\n",
    "def _safe(s): return \"\" if (s is None or (isinstance(s,float) and pd.isna(s))) else str(s)\n",
    "def _count_digits(s): return sum(ch.isdigit() for ch in _safe(s))\n",
    "\n",
    "def _norm_key(x):\n",
    "    s = \"\" if pd.isna(x) else str(x)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    return s.strip().casefold()\n",
    "\n",
    "def _drive_share_to_direct(u: str) -> str:\n",
    "    if not u: return u\n",
    "    m = re.search(r\"/d/([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    m = re.search(r\"[?&]id=([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    return u\n",
    "\n",
    "def load_image_any(path_or_url: str):\n",
    "    try:\n",
    "        s = str(path_or_url).strip()\n",
    "        if s.startswith(\"http\"):\n",
    "            resp = requests.get(_drive_share_to_direct(s), timeout=15)\n",
    "            resp.raise_for_status()\n",
    "            return Image.open(BytesIO(resp.content)).convert(\"RGBA\")\n",
    "        p = Path(s)\n",
    "        if p.exists(): return Image.open(p).convert(\"RGBA\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] cannot load image:\", path_or_url, e)\n",
    "    return None\n",
    "\n",
    "def paste_image_into_box(canvas_rgba, path_or_url, box, padding=6):\n",
    "    im = load_image_any(path_or_url)\n",
    "    if im is None: return\n",
    "    x,y,w,h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    w2,h2 = max(1,w-padding*2), max(1,h-padding*2)\n",
    "    ratio = min(w2/im.width, h2/im.height)\n",
    "    im = im.resize((max(1,int(im.width*ratio)), max(1,int(im.height*ratio))), Image.LANCZOS)\n",
    "    ox = x+(w-im.width)//2\n",
    "    oy = y+(h-im.height)//2\n",
    "    canvas_rgba.alpha_composite(im,(ox,oy))\n",
    "\n",
    "def draw_text_in_box(draw,text,box,font_path,max_font=64,min_font=16,align=\"left\",line_spacing=1.15):\n",
    "    if not text or str(text).strip()==\"\": return\n",
    "    x,y,w,h = int(box[\"x\"]),int(box[\"y\"]),int(box[\"w\"]),int(box[\"h\"])\n",
    "    text = str(text)\n",
    "    for fs in range(max_font,min_font-1,-2):\n",
    "        font = _load_font(font_path, fs)\n",
    "        approx_chars = max(1,int(w/(fs*0.55)))\n",
    "        lines=[]\n",
    "        for raw in text.split(\"\\n\"):\n",
    "            lines += (textwrap.wrap(raw,width=approx_chars) if approx_chars>1 else [raw])\n",
    "        bboxes=[draw.textbbox((0,0),ln,font=font) for ln in lines]\n",
    "        total_h=int(sum(bb[3]-bb[1] for bb in bboxes)+(len(lines)-1)*fs*(line_spacing-1))\n",
    "        if total_h<=h:\n",
    "            cur_y=y+(h-total_h)//2\n",
    "            for ln in lines:\n",
    "                bb=draw.textbbox((0,0),ln,font=font)\n",
    "                lw=bb[2]-bb[0]\n",
    "                cur_x=x if align==\"left\" else (x+(w-lw)//2 if align==\"center\" else x+(w-lw))\n",
    "                draw.text((cur_x,cur_y),ln,font=font,fill=(0,0,0,255))\n",
    "                cur_y+=int(fs*line_spacing)\n",
    "            return\n",
    "\n",
    "def _stroke(draw, box, color=(0,0,0,255), width=2):\n",
    "    x,y,w,h = int(box[\"x\"]),int(box[\"y\"]),int(box[\"w\"]),int(box[\"h\"])\n",
    "    draw.rectangle([x,y,x+w,y+h], outline=color, width=width)\n",
    "\n",
    "def _clip(v, lo, hi): return max(lo, min(hi,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 特徵 ===================\n",
    "FEATURE_ORDER = [\"title_len\",\"bullets_len\",\"bullets_lines\",\"vip_digits\",\"unit_digits\",\"nonvip_digits\",\"has_badge\"]\n",
    "\n",
    "def build_features(meta_row: dict):\n",
    "    return {\n",
    "        \"title_len\": len(safe_str(meta_row.get(\"title\",\"\"))),\n",
    "        \"bullets_len\": len(safe_str(meta_row.get(\"bullets\",\"\"))),\n",
    "        \"bullets_lines\": len([b for b in re.split(r\"[;\\n]\", safe_str(meta_row.get(\"bullets\",\"\"))) if b.strip()]),\n",
    "        \"vip_digits\": count_digits(meta_row.get(\"vip_price\",\"\")),\n",
    "        \"unit_digits\": count_digits(meta_row.get(\"unit_price\",\"\")),\n",
    "        \"nonvip_digits\": count_digits(meta_row.get(\"non_vip_price\",\"\")),\n",
    "        \"has_badge\": int(str(meta_row.get(\"has_badge\",0)).strip() not in [\"\",\"0\",\"False\",\"false\"]),\n",
    "    }\n",
    "\n",
    "def build_features_from_row(row: pd.Series, resolved_icon_path: str) -> dict:\n",
    "    return {\n",
    "        \"title_len\": len(_safe(row.get(MAP_TEXT[\"Product Position\"],\"\"))),\n",
    "        \"bullets_len\": len(_safe(row.get(MAP_TEXT[\"FAB Position\"],\"\"))),\n",
    "        \"bullets_lines\": len([b for b in _safe(row.get(MAP_TEXT[\"FAB Position\"],\"\")).split(\";\") if b.strip()]),\n",
    "        \"vip_digits\": _count_digits(row.get(MAP_TEXT[\"VIP Price Position\"],\"\")),\n",
    "        \"unit_digits\": _count_digits(row.get(MAP_TEXT[\"Non VIP Price Position\"],\"\")),\n",
    "        \"nonvip_digits\": _count_digits(row.get(MAP_TEXT[\"Non VIP Price Position\"],\"\")),  # [FIX]\n",
    "        \"has_badge\": int(Path(_safe(resolved_icon_path)).exists()) if resolved_icon_path else 0,\n",
    "    }\n",
    "\n",
    "# =================== Preprocess → CSV ===================\n",
    "def run_preprocess(label_studio_json: Path, initial_boxes_json: Path, out_csv: Path, meta_csv: Path|None=None):\n",
    "    init_cfg = read_json_file(initial_boxes_json)\n",
    "    Tw, Th = int(init_cfg[\"canvas\"][\"width\"]), int(init_cfg[\"canvas\"][\"height\"])\n",
    "    init_boxes = init_cfg[\"boxes\"]\n",
    "    classes = list(init_boxes.keys())\n",
    "\n",
    "    tasks = read_json_file(label_studio_json)\n",
    "    rows=[]\n",
    "    for t in tasks:\n",
    "        annos = t.get(\"annotations\") or []\n",
    "        if not annos: continue\n",
    "        res = annos[0].get(\"result\", [])\n",
    "        gt_scaled={}\n",
    "        for r in res:\n",
    "            if r.get(\"type\") not in (\"rectanglelabels\",\"rectangles\"): continue\n",
    "            label, rpct, ow, oh = parse_ls_rect(r)\n",
    "            if label not in classes: continue\n",
    "            rect_px = pct_to_px(rpct, ow, oh)\n",
    "            rect_tpl = resize_rect(rect_px, ow, oh, Tw, Th)\n",
    "            gt_scaled[label]=rect_tpl\n",
    "        row={\"image_id\":t.get(\"id\")}\n",
    "        feats=build_features({})\n",
    "        row.update(feats)\n",
    "        for cls in classes:\n",
    "            init=init_boxes[cls]; gt=gt_scaled.get(cls)\n",
    "            d=delta_from(gt,init,Tw,Th) if gt else {\"dx\":0,\"dy\":0,\"dlogw\":0,\"dlogh\":0}\n",
    "            for k,v in d.items(): row[f\"{cls}_{k}\"]=v\n",
    "        rows.append(row)\n",
    "    df=pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv,index=False)\n",
    "    class_file = out_csv.with_suffix(\".classes.json\")\n",
    "    json.dump(classes, open(class_file, \"w\", encoding=\"utf-8\"), ensure_ascii=False, indent=2) # [NEW]\n",
    "    print(f\"[OK] Saved {out_csv} rows={len(df)}\")\n",
    "    return df\n",
    "\n",
    "# =================== Augmentation ===================\n",
    "def augment_offsets(df, classes, num_aug=10):\n",
    "    aug_rows=[]\n",
    "    for _, row in df.iterrows():\n",
    "        for _ in range(num_aug):\n",
    "            new_row=row.copy()\n",
    "            for cls in classes:\n",
    "                new_row[f\"{cls}_dx\"]=row[f\"{cls}_dx\"]+random.uniform(-0.15,0.15)\n",
    "                new_row[f\"{cls}_dy\"]=row[f\"{cls}_dy\"]+random.uniform(-0.15,0.15)\n",
    "                new_row[f\"{cls}_dlogw\"]=row[f\"{cls}_dlogw\"]+random.uniform(-0.2,0.2)\n",
    "                new_row[f\"{cls}_dlogh\"]=row[f\"{cls}_dlogh\"]+random.uniform(-0.2,0.2)\n",
    "            aug_rows.append(new_row)\n",
    "    return pd.concat([df,pd.DataFrame(aug_rows)],ignore_index=True)\n",
    "\n",
    "# =================== 訓練（tanh + label scaling） ===================\n",
    "def train_model():\n",
    "    df=pd.read_csv(OUT_CSV)\n",
    "    classes=json.load(open(CLASS_ORDER_FILE, \"r\", encoding=\"utf-8\"))\n",
    "    df_aug=augment_offsets(df,classes,num_aug=10)\n",
    "    print(f\"[INFO] Augmented {len(df)}→{len(df_aug)}\")\n",
    "    X=df_aug.drop(columns=[c for c in df_aug.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\")) or c==\"image_id\"])\n",
    "    Y=df_aug[[c for c in df_aug.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\"))]]\n",
    "    Y_scaled=Y.copy()\n",
    "    for c in Y.columns:\n",
    "        if c.endswith((\"_dx\",\"_dy\")): Y_scaled[c]=Y[c]/DX_DY_SCALE\n",
    "        else: Y_scaled[c]=Y[c]/DLOG_SCALE\n",
    "    Xtr,Xv,Ytr,Yv=train_test_split(X,Y_scaled,test_size=0.2,random_state=42)\n",
    "    scaler=StandardScaler(); Xtr=scaler.fit_transform(Xtr); Xv=scaler.transform(Xv)\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128,activation='relu',input_shape=(Xtr.shape[1],)),\n",
    "        tf.keras.layers.Dense(64,activation='relu'),\n",
    "        tf.keras.layers.Dense(Ytr.shape[1],activation='tanh')  # [NEW]\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),loss='mse',metrics=[MeanSquaredError(),MeanAbsoluteError()])\n",
    "    model.fit(Xtr,Ytr,validation_data=(Xv,Yv),epochs=50,batch_size=16,verbose=1)\n",
    "    model.save(MODEL_PATH); pickle.dump(scaler,open(SCALER_PATH,\"wb\"))\n",
    "    print(\"[OK] Model saved\")\n",
    "\n",
    "# =================== 幾何 / 佈局 ===================\n",
    "def apply_offset(init_box, delta, W, H):\n",
    "    dx, dy, dlogw, dlogh = map(float, delta)\n",
    "    # （可選）安全範圍限制\n",
    "    dx = _clip(dx, -0.5, 0.5)          # [NEW] 避免飛太遠\n",
    "    dy = _clip(dy, -0.5, 0.5)          # [NEW]\n",
    "    sx = math.exp(_clip(dlogw, math.log(0.5), math.log(2.0)))  # [NEW]\n",
    "    sy = math.exp(_clip(dlogh, math.log(0.5), math.log(2.0)))  # [NEW]\n",
    "    x = init_box[\"x\"] + dx * W\n",
    "    y = init_box[\"y\"] + dy * H\n",
    "    w = max(24, init_box[\"w\"] * sx)\n",
    "    h = max(24, init_box[\"h\"] * sy)\n",
    "    x = _clip(x, 0, W - w)             # [NEW] 裁進畫布\n",
    "    y = _clip(y, 0, H - h)             # [NEW]\n",
    "    return {\"x\": x, \"y\": y, \"w\": w, \"h\": h}\n",
    "\n",
    "# =================== 模型 + Scaler 載入 ===================\n",
    "def load_template_and_boxes():\n",
    "    tpl = Image.open(TEMPLATE_PATH).convert(\"RGBA\")\n",
    "    tw, th = tpl.size\n",
    "    init_cfg = json.loads(Path(INITIAL_BOXES_PATH).read_text(encoding=\"utf-8\"))\n",
    "    cw, ch = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    if (tw, th) != (cw, ch):\n",
    "        sx, sy = tw/float(cw), th/float(ch)\n",
    "        for _, r in init_cfg[\"boxes\"].items():\n",
    "            r[\"x\"], r[\"y\"] = r[\"x\"]*sx, r[\"y\"]*sy\n",
    "            r[\"w\"], r[\"h\"] = r[\"w\"]*sx, r[\"h\"]*sy\n",
    "        init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"] = tw, th\n",
    "        print(f\"[INFO] Scaled initial boxes to {tw}x{th}\")\n",
    "    return tpl, init_cfg\n",
    "\n",
    "def load_model_and_scaler():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH) if Path(MODEL_PATH).exists() else None\n",
    "    scaler = pickle.load(open(SCALER_PATH,\"rb\")) if Path(SCALER_PATH).exists() else None\n",
    "    if model is None:  print(\"[WARN] MODEL not found → zero offsets\")\n",
    "    if scaler is None: print(\"[WARN] SCALER not found → use raw features\")\n",
    "    return model, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8dd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 渲染主程式 ===================\n",
    "def main_render():\n",
    "    # 讀 Excel\n",
    "    xls = pd.ExcelFile(EXCEL_PATH)\n",
    "    df_user = pd.read_excel(xls, sheet_name=SHEET_USER)\n",
    "    df_img  = pd.read_excel(xls, sheet_name=SHEET_IMG)\n",
    "    df_icon = pd.read_excel(xls, sheet_name=SHEET_ICON)\n",
    "\n",
    "    # 建查表\n",
    "    img_lookup  = {_norm_key(r[SKU_IMG_SKU_COL]): str(r[SKU_IMG_LINK_COL]).strip() for _, r in df_img.iterrows()}\n",
    "    icon_lookup = {_norm_key(r[SKU_ICON_NAME_COL]): str(r[SKU_ICON_LINK_COL]).strip() for _, r in df_icon.iterrows()}\n",
    "\n",
    "    # 載入模板與模型\n",
    "    template_rgba, init_cfg = load_template_and_boxes()\n",
    "    W, H = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    INIT_BOXES = init_cfg[\"boxes\"]\n",
    "\n",
    "    # [FIX] 讀回訓練時類別順序，並檢查集合一致\n",
    "    if CLASS_ORDER_FILE.exists():\n",
    "        train_classes = json.load(open(CLASS_ORDER_FILE, \"r\", encoding=\"utf-8\"))\n",
    "        if set(train_classes) != set(INIT_BOXES.keys()):\n",
    "            raise ValueError(f\"Classes mismatch.\\nTrain: {train_classes}\\nInfer: {list(INIT_BOXES.keys())}\")\n",
    "        CLASSES = train_classes[:]\n",
    "    else:\n",
    "        CLASSES = list(INIT_BOXES.keys())\n",
    "\n",
    "    model, scaler = load_model_and_scaler()\n",
    "\n",
    "    # 逐列生成\n",
    "    for idx, row in df_user.iterrows():\n",
    "        sku_key  = _norm_key(row.get(COL_PRODUCT_SKU, \"\"))\n",
    "        icon_key = _norm_key(row.get(COL_ICON_NAME, \"\"))\n",
    "        prod_img_path = img_lookup.get(sku_key, \"\")\n",
    "        icon_img_path = icon_lookup.get(icon_key, \"\")\n",
    "\n",
    "        # 特徵 → DataFrame 給 scaler（避免 sklearn warning）\n",
    "        feats = build_features_from_row(row, resolved_icon_path=icon_img_path)\n",
    "        X_df = pd.DataFrame([feats], columns=FEATURE_ORDER).astype(float)  # [FIX]\n",
    "        X_in = scaler.transform(X_df) if scaler is not None else X_df.values\n",
    "\n",
    "        # baseline offsets (全 0)\n",
    "        deltas_base = {cls: [0.0,0.0,0.0,0.0] for cls in CLASSES}\n",
    "\n",
    "        # 預測 offsets（tanh 輸出需乘回 label scaling）\n",
    "        if USE_MODEL and model is not None:\n",
    "            pred = model.predict(X_in, verbose=0)[0]\n",
    "            deltas_pred = {}\n",
    "            for i, cls in enumerate(CLASSES):\n",
    "                dx = float(pred[i*4+0]) * DX_DY_SCALE\n",
    "                dy = float(pred[i*4+1]) * DX_DY_SCALE\n",
    "                dw = float(pred[i*4+2]) * DLOG_SCALE\n",
    "                dh = float(pred[i*4+3]) * DLOG_SCALE\n",
    "                deltas_pred[cls] = [dx,dy,dw,dh]\n",
    "        else:\n",
    "            deltas_pred = deltas_base\n",
    "\n",
    "        if idx == 0 and PRINT_FIRST_PRED and USE_MODEL and (model is not None):  # [FIX]\n",
    "            print(\"Pred deltas (first row, scaled back):\", pred[:min(12, len(pred))])\n",
    "\n",
    "        # blend baseline 與 model\n",
    "        deltas_final = {}\n",
    "        for cls in CLASSES:\n",
    "            db = deltas_base[cls]; dp = deltas_pred[cls]\n",
    "            deltas_final[cls] = [(1-BLEND)*db[i] + BLEND*dp[i] for i in range(4)]\n",
    "\n",
    "        final_boxes = {cls: apply_offset(INIT_BOXES[cls], deltas_final[cls], W, H) for cls in CLASSES}\n",
    "\n",
    "        # 繪圖\n",
    "        canvas = template_rgba.copy()\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "        paste_image_into_box(canvas, prod_img_path, final_boxes[\"Product Image Position\"])\n",
    "        paste_image_into_box(canvas, icon_img_path,  final_boxes[\"Icon Position\"])\n",
    "\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Brand Position\"], \"\"),          final_boxes[\"Brand Position\"],          font_path=FONT_BOLD_PATH,   max_font=72)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Product Position\"], \"\"),        final_boxes[\"Product Position\"],        font_path=FONT_REGULAR_PATH,max_font=64)\n",
    "        fab_text = str(row.get(MAP_TEXT[\"FAB Position\"], \"\") or \"\").replace(\";\", \"\\n\")\n",
    "        draw_text_in_box(draw, fab_text,                                        final_boxes[\"FAB Position\"],            font_path=FONT_REGULAR_PATH,max_font=44)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"VIP Price Position\"], \"\"),      final_boxes[\"VIP Price Position\"],      font_path=FONT_BOLD_PATH,   max_font=100)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Non VIP Price Position\"], \"\"),  final_boxes[\"Non VIP Price Position\"],  font_path=FONT_REGULAR_PATH,max_font=36)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Original Price Position\"], \"\"), final_boxes[\"Original Price Position\"], font_path=FONT_REGULAR_PATH,max_font=32)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Sales Period Position\"], \"\"),   final_boxes[\"Sales Period Position\"],   font_path=FONT_REGULAR_PATH,max_font=28, align=\"right\")\n",
    "\n",
    "        if DRAW_DEBUG_BOXES:\n",
    "            for cls, box in final_boxes.items():\n",
    "                _stroke(draw, box, (255,0,0,180), 2)\n",
    "\n",
    "        out_path = OUTPUT_DIR / f\"card_cn_{idx+1:03d}.png\"\n",
    "        canvas.convert(\"RGB\").save(out_path, quality=95)\n",
    "        print(\"Saved:\", out_path)\n",
    "\n",
    "# =================== 主程式 ===================\n",
    "if __name__ == \"__main__\":\n",
    "    # --- 首次完整流程（生資料 → 訓練 → 出圖），跑完再註解 ---\n",
    "    run_preprocess(Path(\"Objects_positions.json\"), Path(INITIAL_BOXES_PATH), Path(OUT_CSV), meta_csv=None)\n",
    "    train_model()\n",
    "    # main_render()\n",
    "\n",
    "    # --- 日常出圖（已經有模型與 scaler） ---\n",
    "    main_render()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
