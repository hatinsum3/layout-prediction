{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df090ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv, re, argparse, sys, math, random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "import pickle\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "import unicodedata\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472249e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 全域設定 ===================\n",
    "USE_MODEL = True\n",
    "BLEND = 0.2\n",
    "DRAW_DEBUG_BOXES = False\n",
    "PRINT_FIRST_PRED = True\n",
    "\n",
    "# Label scaling（對應 tanh 輸出），推論要乘回\n",
    "DX_DY_SCALE = 0.1\n",
    "DLOG_SCALE  = 0.25\n",
    "\n",
    "EXCEL_PATH = \"Board Click SKU.xlsx\"\n",
    "SHEET_USER = \"User_Input\"\n",
    "SHEET_IMG  = \"SKU_Image\"\n",
    "SHEET_ICON = \"SKU_Icon\"\n",
    "\n",
    "TEMPLATE_PATH = \"sasa_pink_1280.png\"\n",
    "INITIAL_BOXES_PATH = \"Initial_boxes.json\"\n",
    "\n",
    "MODEL_PATH = \"layout_model.keras\"\n",
    "SCALER_PATH = \"scaler.pkl\"\n",
    "\n",
    "OUT_CSV = \"offsets_for_tf.csv\"\n",
    "CLASS_ORDER_FILE = Path(OUT_CSV).with_suffix(\".classes.json\")  # [NEW]\n",
    "\n",
    "OUTPUT_DIR = Path(\"out_cards_cn\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MAP_TEXT = {\n",
    "    \"Brand Position\":          \"Brand\",\n",
    "    \"VIP Price Position\":      \"VIP價\",\n",
    "    \"Non VIP Price Position\":  \"優惠價\",\n",
    "    \"Original Price Position\": \"建議價\",\n",
    "    \"Product Position\":        \"Product name\",\n",
    "    \"Sales Period Position\":   \"優惠期\",\n",
    "    \"FAB Position\":            \"FAB\",\n",
    "}\n",
    "COL_PRODUCT_SKU = \"Product SKU\"\n",
    "COL_ICON_NAME   = \"Icon\"\n",
    "\n",
    "SKU_IMG_SKU_COL   = \"Product SKU\"\n",
    "SKU_IMG_LINK_COL  = \"Image\"\n",
    "SKU_ICON_NAME_COL = \"Icon\"\n",
    "SKU_ICON_LINK_COL = \"Icon Image\"\n",
    "\n",
    "# 字型\n",
    "FONT_REGULAR_PATH = Path.home() / \"Library/Fonts/NotoSansCJKsc-Regular.otf\"\n",
    "FONT_BOLD_PATH    = Path.home() / \"Library/Fonts/NotoSansCJKsc-Bold.otf\"\n",
    "\n",
    "# =================== 工具 ===================\n",
    "def safe_str(x): \n",
    "    return \"\" if (x is None or (isinstance(x,float) and pd.isna(x))) else str(x)\n",
    "\n",
    "def count_digits(s): \n",
    "    return sum(ch.isdigit() for ch in safe_str(s))\n",
    "\n",
    "def read_json_file(path: Path):\n",
    "    text = path.read_text(encoding=\"utf-8\").strip()\n",
    "    return json.loads(text)\n",
    "\n",
    "def parse_ls_rect(item):\n",
    "    v = item[\"value\"]\n",
    "    label = v[\"rectanglelabels\"][0] if isinstance(v.get(\"rectanglelabels\"), list) else v.get(\"labels\", [\"\"])[0]\n",
    "    rect_pct = dict(x=v[\"x\"], y=v[\"y\"], w=v[\"width\"], h=v[\"height\"])\n",
    "    ow = item.get(\"original_width\") or item.get(\"image_original_width\")\n",
    "    oh = item.get(\"original_height\") or item.get(\"image_original_height\")\n",
    "    return label, rect_pct, int(ow), int(oh)\n",
    "\n",
    "def pct_to_px(rpct, ow, oh):\n",
    "    return {\"x\": rpct[\"x\"]/100.0*ow, \"y\": rpct[\"y\"]/100.0*oh, \"w\": rpct[\"w\"]/100.0*ow, \"h\": rpct[\"h\"]/100.0*oh}\n",
    "\n",
    "def resize_rect(rect, from_w, from_h, to_w, to_h):\n",
    "    sx, sy = to_w/float(from_w), to_h/float(from_h)\n",
    "    return {\"x\": rect[\"x\"]*sx, \"y\": rect[\"y\"]*sy, \"w\": rect[\"w\"]*sx, \"h\": rect[\"h\"]*sy}\n",
    "\n",
    "def delta_from(gt, init, W, H):\n",
    "    w0 = max(1e-6, float(init[\"w\"]))\n",
    "    h0 = max(1e-6, float(init[\"h\"]))\n",
    "    return {\n",
    "        \"dx\":   (float(gt[\"x\"]) - float(init[\"x\"])) / float(W),\n",
    "        \"dy\":   (float(gt[\"y\"]) - float(init[\"y\"])) / float(H),\n",
    "        \"dlogw\": float(np.log(max(1e-6,float(gt[\"w\"])) / w0)),\n",
    "        \"dlogh\": float(np.log(max(1e-6,float(gt[\"h\"])) / h0)),\n",
    "    }\n",
    "\n",
    "def _load_font(path, size): return ImageFont.truetype(str(path), size)\n",
    "def _safe(s): return \"\" if (s is None or (isinstance(s,float) and pd.isna(s))) else str(s)\n",
    "def _count_digits(s): return sum(ch.isdigit() for ch in _safe(s))\n",
    "\n",
    "def _norm_key(x):\n",
    "    s = \"\" if pd.isna(x) else str(x)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    return s.strip().casefold()\n",
    "\n",
    "def _drive_share_to_direct(u: str) -> str:\n",
    "    if not u: return u\n",
    "    m = re.search(r\"/d/([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    m = re.search(r\"[?&]id=([A-Za-z0-9_-]+)\", u)\n",
    "    if m: return f\"https://drive.google.com/uc?export=download&id={m.group(1)}\"\n",
    "    return u\n",
    "\n",
    "def load_image_any(path_or_url: str):\n",
    "    try:\n",
    "        s = str(path_or_url).strip()\n",
    "        if s.startswith(\"http\"):\n",
    "            resp = requests.get(_drive_share_to_direct(s), timeout=15)\n",
    "            resp.raise_for_status()\n",
    "            return Image.open(BytesIO(resp.content)).convert(\"RGBA\")\n",
    "        p = Path(s)\n",
    "        if p.exists(): return Image.open(p).convert(\"RGBA\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] cannot load image:\", path_or_url, e)\n",
    "    return None\n",
    "\n",
    "def paste_image_into_box(canvas_rgba, path_or_url, box, padding=6):\n",
    "    im = load_image_any(path_or_url)\n",
    "    if im is None: return\n",
    "    x,y,w,h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "    w2,h2 = max(1,w-padding*2), max(1,h-padding*2)\n",
    "    ratio = min(w2/im.width, h2/im.height)\n",
    "    im = im.resize((max(1,int(im.width*ratio)), max(1,int(im.height*ratio))), Image.LANCZOS)\n",
    "    ox = x+(w-im.width)//2\n",
    "    oy = y+(h-im.height)//2\n",
    "    canvas_rgba.alpha_composite(im,(ox,oy))\n",
    "\n",
    "def draw_text_in_box(draw,text,box,font_path,max_font=64,min_font=16,align=\"left\",line_spacing=1.15):\n",
    "    if not text or str(text).strip()==\"\": return\n",
    "    x,y,w,h = int(box[\"x\"]),int(box[\"y\"]),int(box[\"w\"]),int(box[\"h\"])\n",
    "    text = str(text)\n",
    "    for fs in range(max_font,min_font-1,-2):\n",
    "        font = _load_font(font_path, fs)\n",
    "        approx_chars = max(1,int(w/(fs*0.55)))\n",
    "        lines=[]\n",
    "        for raw in text.split(\"\\n\"):\n",
    "            lines += (textwrap.wrap(raw,width=approx_chars) if approx_chars>1 else [raw])\n",
    "        bboxes=[draw.textbbox((0,0),ln,font=font) for ln in lines]\n",
    "        total_h=int(sum(bb[3]-bb[1] for bb in bboxes)+(len(lines)-1)*fs*(line_spacing-1))\n",
    "        if total_h<=h:\n",
    "            cur_y=y+(h-total_h)//2\n",
    "            for ln in lines:\n",
    "                bb=draw.textbbox((0,0),ln,font=font)\n",
    "                lw=bb[2]-bb[0]\n",
    "                cur_x=x if align==\"left\" else (x+(w-lw)//2 if align==\"center\" else x+(w-lw))\n",
    "                draw.text((cur_x,cur_y),ln,font=font,fill=(0,0,0,255))\n",
    "                cur_y+=int(fs*line_spacing)\n",
    "            return\n",
    "\n",
    "def _stroke(draw, box, color=(0,0,0,255), width=2):\n",
    "    x,y,w,h = int(box[\"x\"]),int(box[\"y\"]),int(box[\"w\"]),int(box[\"h\"])\n",
    "    draw.rectangle([x,y,x+w,y+h], outline=color, width=width)\n",
    "\n",
    "def _clip(v, lo, hi): return max(lo, min(hi,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 特徵 ===================\n",
    "FEATURE_ORDER = [\"title_len\",\"bullets_len\",\"bullets_lines\",\"vip_digits\",\"unit_digits\",\"nonvip_digits\",\"has_badge\"]\n",
    "\n",
    "def build_features(meta_row: dict):\n",
    "    return {\n",
    "        \"title_len\": len(safe_str(meta_row.get(\"title\",\"\"))),\n",
    "        \"bullets_len\": len(safe_str(meta_row.get(\"bullets\",\"\"))),\n",
    "        \"bullets_lines\": len([b for b in re.split(r\"[;\\n]\", safe_str(meta_row.get(\"bullets\",\"\"))) if b.strip()]),\n",
    "        \"vip_digits\": count_digits(meta_row.get(\"vip_price\",\"\")),\n",
    "        \"unit_digits\": count_digits(meta_row.get(\"unit_price\",\"\")),\n",
    "        \"nonvip_digits\": count_digits(meta_row.get(\"non_vip_price\",\"\")),\n",
    "        \"has_badge\": int(str(meta_row.get(\"has_badge\",0)).strip() not in [\"\",\"0\",\"False\",\"false\"]),\n",
    "    }\n",
    "\n",
    "def build_features_from_row(row: pd.Series, resolved_icon_path: str) -> dict:\n",
    "    return {\n",
    "        \"title_len\": len(_safe(row.get(MAP_TEXT[\"Product Position\"],\"\"))),\n",
    "        \"bullets_len\": len(_safe(row.get(MAP_TEXT[\"FAB Position\"],\"\"))),\n",
    "        \"bullets_lines\": len([b for b in _safe(row.get(MAP_TEXT[\"FAB Position\"],\"\")).split(\";\") if b.strip()]),\n",
    "        \"vip_digits\": _count_digits(row.get(MAP_TEXT[\"VIP Price Position\"],\"\")),\n",
    "        \"unit_digits\": _count_digits(row.get(MAP_TEXT[\"Non VIP Price Position\"],\"\")),\n",
    "        \"nonvip_digits\": _count_digits(row.get(MAP_TEXT[\"Non VIP Price Position\"],\"\")),  # [FIX]\n",
    "        \"has_badge\": int(Path(_safe(resolved_icon_path)).exists()) if resolved_icon_path else 0,\n",
    "    }\n",
    "\n",
    "# =================== Preprocess → CSV ===================\n",
    "def run_preprocess(label_studio_json: Path, initial_boxes_json: Path, out_csv: Path, meta_csv: Path|None=None):\n",
    "    init_cfg = read_json_file(initial_boxes_json)\n",
    "    Tw, Th = int(init_cfg[\"canvas\"][\"width\"]), int(init_cfg[\"canvas\"][\"height\"])\n",
    "    init_boxes = init_cfg[\"boxes\"]\n",
    "    classes = list(init_boxes.keys())\n",
    "\n",
    "    tasks = read_json_file(label_studio_json)\n",
    "    rows=[]\n",
    "    for t in tasks:\n",
    "        annos = t.get(\"annotations\") or []\n",
    "        if not annos: continue\n",
    "        res = annos[0].get(\"result\", [])\n",
    "        gt_scaled={}\n",
    "        for r in res:\n",
    "            if r.get(\"type\") not in (\"rectanglelabels\",\"rectangles\"): continue\n",
    "            label, rpct, ow, oh = parse_ls_rect(r)\n",
    "            if label not in classes: continue\n",
    "            rect_px = pct_to_px(rpct, ow, oh)\n",
    "            rect_tpl = resize_rect(rect_px, ow, oh, Tw, Th)\n",
    "            gt_scaled[label]=rect_tpl\n",
    "        row={\"image_id\":t.get(\"id\")}\n",
    "        feats=build_features({})\n",
    "        row.update(feats)\n",
    "        for cls in classes:\n",
    "            init=init_boxes[cls]; gt=gt_scaled.get(cls)\n",
    "            d=delta_from(gt,init,Tw,Th) if gt else {\"dx\":0,\"dy\":0,\"dlogw\":0,\"dlogh\":0}\n",
    "            for k,v in d.items(): row[f\"{cls}_{k}\"]=v\n",
    "        rows.append(row)\n",
    "    df=pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv,index=False)\n",
    "    class_file = out_csv.with_suffix(\".classes.json\")\n",
    "    json.dump(classes, open(class_file, \"w\", encoding=\"utf-8\"), ensure_ascii=False, indent=2) # [NEW]\n",
    "    print(f\"[OK] Saved {out_csv} rows={len(df)}\")\n",
    "    return df\n",
    "\n",
    "# =================== Augmentation ===================\n",
    "def augment_offsets(df, classes, num_aug=10):\n",
    "    aug_rows=[]\n",
    "    for _, row in df.iterrows():\n",
    "        for _ in range(num_aug):\n",
    "            new_row=row.copy()\n",
    "            for cls in classes:\n",
    "                new_row[f\"{cls}_dx\"]=row[f\"{cls}_dx\"]+random.uniform(-0.15,0.15)\n",
    "                new_row[f\"{cls}_dy\"]=row[f\"{cls}_dy\"]+random.uniform(-0.15,0.15)\n",
    "                new_row[f\"{cls}_dlogw\"]=row[f\"{cls}_dlogw\"]+random.uniform(-0.2,0.2)\n",
    "                new_row[f\"{cls}_dlogh\"]=row[f\"{cls}_dlogh\"]+random.uniform(-0.2,0.2)\n",
    "            aug_rows.append(new_row)\n",
    "    return pd.concat([df,pd.DataFrame(aug_rows)],ignore_index=True)\n",
    "\n",
    "# =================== 訓練（tanh + label scaling） ===================\n",
    "def train_model():\n",
    "    df=pd.read_csv(OUT_CSV)\n",
    "    classes=json.load(open(CLASS_ORDER_FILE, \"r\", encoding=\"utf-8\"))\n",
    "    df_aug=augment_offsets(df,classes,num_aug=10)\n",
    "    print(f\"[INFO] Augmented {len(df)}→{len(df_aug)}\")\n",
    "    X=df_aug.drop(columns=[c for c in df_aug.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\")) or c==\"image_id\"])\n",
    "    Y=df_aug[[c for c in df_aug.columns if c.endswith((\"_dx\",\"_dy\",\"_dlogw\",\"_dlogh\"))]]\n",
    "    Y_scaled=Y.copy()\n",
    "    for c in Y.columns:\n",
    "        if c.endswith((\"_dx\",\"_dy\")): Y_scaled[c]=Y[c]/DX_DY_SCALE\n",
    "        else: Y_scaled[c]=Y[c]/DLOG_SCALE\n",
    "    Xtr,Xv,Ytr,Yv=train_test_split(X,Y_scaled,test_size=0.2,random_state=42)\n",
    "    scaler=StandardScaler(); Xtr=scaler.fit_transform(Xtr); Xv=scaler.transform(Xv)\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128,activation='relu',input_shape=(Xtr.shape[1],)),\n",
    "        tf.keras.layers.Dense(64,activation='relu'),\n",
    "        tf.keras.layers.Dense(Ytr.shape[1],activation='tanh')  # [NEW]\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),loss='mse',metrics=[MeanSquaredError(),MeanAbsoluteError()])\n",
    "    model.fit(Xtr,Ytr,validation_data=(Xv,Yv),epochs=50,batch_size=16,verbose=1)\n",
    "    model.save(MODEL_PATH); pickle.dump(scaler,open(SCALER_PATH,\"wb\"))\n",
    "    print(\"[OK] Model saved\")\n",
    "\n",
    "# =================== 幾何 / 佈局 ===================\n",
    "def apply_offset(init_box, delta, W, H):\n",
    "    dx, dy, dlogw, dlogh = map(float, delta)\n",
    "    # （可選）安全範圍限制\n",
    "    dx = _clip(dx, -0.5, 0.5)          # [NEW] \n",
    "    dy = _clip(dy, -0.5, 0.5)          # [NEW]\n",
    "    sx = math.exp(_clip(dlogw, math.log(0.5), math.log(2.0)))  # [NEW]\n",
    "    sy = math.exp(_clip(dlogh, math.log(0.5), math.log(2.0)))  # [NEW]\n",
    "    x = init_box[\"x\"] + dx * W\n",
    "    y = init_box[\"y\"] + dy * H\n",
    "    w = max(24, init_box[\"w\"] * sx)\n",
    "    h = max(24, init_box[\"h\"] * sy)\n",
    "    x = _clip(x, 0, W - w)             # [NEW] \n",
    "    y = _clip(y, 0, H - h)             # [NEW]\n",
    "    return {\"x\": x, \"y\": y, \"w\": w, \"h\": h}\n",
    "\n",
    "# =================== 模型 + Scaler 載入 ===================\n",
    "def load_template_and_boxes():\n",
    "    tpl = Image.open(TEMPLATE_PATH).convert(\"RGBA\")\n",
    "    tw, th = tpl.size\n",
    "    init_cfg = json.loads(Path(INITIAL_BOXES_PATH).read_text(encoding=\"utf-8\"))\n",
    "    cw, ch = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    if (tw, th) != (cw, ch):\n",
    "        sx, sy = tw/float(cw), th/float(ch)\n",
    "        for _, r in init_cfg[\"boxes\"].items():\n",
    "            r[\"x\"], r[\"y\"] = r[\"x\"]*sx, r[\"y\"]*sy\n",
    "            r[\"w\"], r[\"h\"] = r[\"w\"]*sx, r[\"h\"]*sy\n",
    "        init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"] = tw, th\n",
    "        print(f\"[INFO] Scaled initial boxes to {tw}x{th}\")\n",
    "    return tpl, init_cfg\n",
    "\n",
    "def load_model_and_scaler():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH) if Path(MODEL_PATH).exists() else None\n",
    "    scaler = pickle.load(open(SCALER_PATH,\"rb\")) if Path(SCALER_PATH).exists() else None\n",
    "    if model is None:  print(\"[WARN] MODEL not found → zero offsets\")\n",
    "    if scaler is None: print(\"[WARN] SCALER not found → use raw features\")\n",
    "    return model, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8dd4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved offsets_for_tf.csv rows=29\n",
      "[INFO] Augmented 29→319\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/boardclick/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6977 - mean_absolute_error: 1.0058 - mean_squared_error: 1.6977 - val_loss: 1.8264 - val_mean_absolute_error: 1.0306 - val_mean_squared_error: 1.8264\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6808 - mean_absolute_error: 1.0008 - mean_squared_error: 1.6808 - val_loss: 1.8088 - val_mean_absolute_error: 1.0253 - val_mean_squared_error: 1.8088\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6645 - mean_absolute_error: 0.9959 - mean_squared_error: 1.6645 - val_loss: 1.7915 - val_mean_absolute_error: 1.0202 - val_mean_squared_error: 1.7915\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6485 - mean_absolute_error: 0.9912 - mean_squared_error: 1.6485 - val_loss: 1.7747 - val_mean_absolute_error: 1.0152 - val_mean_squared_error: 1.7747\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6331 - mean_absolute_error: 0.9865 - mean_squared_error: 1.6331 - val_loss: 1.7582 - val_mean_absolute_error: 1.0103 - val_mean_squared_error: 1.7582\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6179 - mean_absolute_error: 0.9820 - mean_squared_error: 1.6179 - val_loss: 1.7426 - val_mean_absolute_error: 1.0056 - val_mean_squared_error: 1.7426\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6034 - mean_absolute_error: 0.9777 - mean_squared_error: 1.6034 - val_loss: 1.7272 - val_mean_absolute_error: 1.0011 - val_mean_squared_error: 1.7272\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5893 - mean_absolute_error: 0.9736 - mean_squared_error: 1.5893 - val_loss: 1.7123 - val_mean_absolute_error: 0.9966 - val_mean_squared_error: 1.7123\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5756 - mean_absolute_error: 0.9694 - mean_squared_error: 1.5756 - val_loss: 1.6977 - val_mean_absolute_error: 0.9923 - val_mean_squared_error: 1.6977\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5622 - mean_absolute_error: 0.9655 - mean_squared_error: 1.5622 - val_loss: 1.6836 - val_mean_absolute_error: 0.9882 - val_mean_squared_error: 1.6836\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5493 - mean_absolute_error: 0.9616 - mean_squared_error: 1.5493 - val_loss: 1.6699 - val_mean_absolute_error: 0.9841 - val_mean_squared_error: 1.6699\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5368 - mean_absolute_error: 0.9579 - mean_squared_error: 1.5368 - val_loss: 1.6567 - val_mean_absolute_error: 0.9802 - val_mean_squared_error: 1.6567\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5247 - mean_absolute_error: 0.9543 - mean_squared_error: 1.5247 - val_loss: 1.6438 - val_mean_absolute_error: 0.9764 - val_mean_squared_error: 1.6438\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5128 - mean_absolute_error: 0.9508 - mean_squared_error: 1.5128 - val_loss: 1.6315 - val_mean_absolute_error: 0.9728 - val_mean_squared_error: 1.6315\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5016 - mean_absolute_error: 0.9474 - mean_squared_error: 1.5016 - val_loss: 1.6192 - val_mean_absolute_error: 0.9691 - val_mean_squared_error: 1.6192\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4906 - mean_absolute_error: 0.9441 - mean_squared_error: 1.4906 - val_loss: 1.6074 - val_mean_absolute_error: 0.9656 - val_mean_squared_error: 1.6074\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4798 - mean_absolute_error: 0.9409 - mean_squared_error: 1.4798 - val_loss: 1.5962 - val_mean_absolute_error: 0.9622 - val_mean_squared_error: 1.5962\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4695 - mean_absolute_error: 0.9377 - mean_squared_error: 1.4695 - val_loss: 1.5851 - val_mean_absolute_error: 0.9589 - val_mean_squared_error: 1.5851\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4594 - mean_absolute_error: 0.9346 - mean_squared_error: 1.4594 - val_loss: 1.5745 - val_mean_absolute_error: 0.9558 - val_mean_squared_error: 1.5745\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4499 - mean_absolute_error: 0.9317 - mean_squared_error: 1.4499 - val_loss: 1.5642 - val_mean_absolute_error: 0.9527 - val_mean_squared_error: 1.5642\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4404 - mean_absolute_error: 0.9289 - mean_squared_error: 1.4404 - val_loss: 1.5541 - val_mean_absolute_error: 0.9498 - val_mean_squared_error: 1.5541\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4314 - mean_absolute_error: 0.9261 - mean_squared_error: 1.4314 - val_loss: 1.5445 - val_mean_absolute_error: 0.9470 - val_mean_squared_error: 1.5445\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4226 - mean_absolute_error: 0.9234 - mean_squared_error: 1.4226 - val_loss: 1.5350 - val_mean_absolute_error: 0.9442 - val_mean_squared_error: 1.5350\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4141 - mean_absolute_error: 0.9208 - mean_squared_error: 1.4141 - val_loss: 1.5260 - val_mean_absolute_error: 0.9416 - val_mean_squared_error: 1.5260\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4059 - mean_absolute_error: 0.9182 - mean_squared_error: 1.4059 - val_loss: 1.5172 - val_mean_absolute_error: 0.9390 - val_mean_squared_error: 1.5172\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3979 - mean_absolute_error: 0.9157 - mean_squared_error: 1.3979 - val_loss: 1.5087 - val_mean_absolute_error: 0.9366 - val_mean_squared_error: 1.5087\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3903 - mean_absolute_error: 0.9134 - mean_squared_error: 1.3903 - val_loss: 1.5004 - val_mean_absolute_error: 0.9342 - val_mean_squared_error: 1.5004\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3828 - mean_absolute_error: 0.9110 - mean_squared_error: 1.3828 - val_loss: 1.4925 - val_mean_absolute_error: 0.9319 - val_mean_squared_error: 1.4925\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3756 - mean_absolute_error: 0.9088 - mean_squared_error: 1.3756 - val_loss: 1.4848 - val_mean_absolute_error: 0.9297 - val_mean_squared_error: 1.4848\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3687 - mean_absolute_error: 0.9067 - mean_squared_error: 1.3687 - val_loss: 1.4773 - val_mean_absolute_error: 0.9275 - val_mean_squared_error: 1.4773\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3619 - mean_absolute_error: 0.9045 - mean_squared_error: 1.3619 - val_loss: 1.4700 - val_mean_absolute_error: 0.9254 - val_mean_squared_error: 1.4700\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3554 - mean_absolute_error: 0.9025 - mean_squared_error: 1.3554 - val_loss: 1.4630 - val_mean_absolute_error: 0.9233 - val_mean_squared_error: 1.4630\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3491 - mean_absolute_error: 0.9005 - mean_squared_error: 1.3491 - val_loss: 1.4563 - val_mean_absolute_error: 0.9214 - val_mean_squared_error: 1.4563\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3430 - mean_absolute_error: 0.8986 - mean_squared_error: 1.3430 - val_loss: 1.4497 - val_mean_absolute_error: 0.9194 - val_mean_squared_error: 1.4497\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3371 - mean_absolute_error: 0.8968 - mean_squared_error: 1.3371 - val_loss: 1.4432 - val_mean_absolute_error: 0.9175 - val_mean_squared_error: 1.4432\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3313 - mean_absolute_error: 0.8950 - mean_squared_error: 1.3313 - val_loss: 1.4370 - val_mean_absolute_error: 0.9157 - val_mean_squared_error: 1.4370\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3258 - mean_absolute_error: 0.8933 - mean_squared_error: 1.3258 - val_loss: 1.4310 - val_mean_absolute_error: 0.9139 - val_mean_squared_error: 1.4310\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3204 - mean_absolute_error: 0.8916 - mean_squared_error: 1.3204 - val_loss: 1.4252 - val_mean_absolute_error: 0.9123 - val_mean_squared_error: 1.4252\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3152 - mean_absolute_error: 0.8900 - mean_squared_error: 1.3152 - val_loss: 1.4196 - val_mean_absolute_error: 0.9106 - val_mean_squared_error: 1.4196\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3102 - mean_absolute_error: 0.8884 - mean_squared_error: 1.3102 - val_loss: 1.4142 - val_mean_absolute_error: 0.9091 - val_mean_squared_error: 1.4142\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3053 - mean_absolute_error: 0.8868 - mean_squared_error: 1.3053 - val_loss: 1.4090 - val_mean_absolute_error: 0.9075 - val_mean_squared_error: 1.4090\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3006 - mean_absolute_error: 0.8853 - mean_squared_error: 1.3006 - val_loss: 1.4039 - val_mean_absolute_error: 0.9060 - val_mean_squared_error: 1.4039\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2960 - mean_absolute_error: 0.8839 - mean_squared_error: 1.2960 - val_loss: 1.3989 - val_mean_absolute_error: 0.9045 - val_mean_squared_error: 1.3989\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2916 - mean_absolute_error: 0.8825 - mean_squared_error: 1.2916 - val_loss: 1.3941 - val_mean_absolute_error: 0.9031 - val_mean_squared_error: 1.3941\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2873 - mean_absolute_error: 0.8811 - mean_squared_error: 1.2873 - val_loss: 1.3894 - val_mean_absolute_error: 0.9017 - val_mean_squared_error: 1.3894\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2831 - mean_absolute_error: 0.8798 - mean_squared_error: 1.2831 - val_loss: 1.3849 - val_mean_absolute_error: 0.9004 - val_mean_squared_error: 1.3849\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2790 - mean_absolute_error: 0.8785 - mean_squared_error: 1.2790 - val_loss: 1.3806 - val_mean_absolute_error: 0.8991 - val_mean_squared_error: 1.3806\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2751 - mean_absolute_error: 0.8773 - mean_squared_error: 1.2751 - val_loss: 1.3762 - val_mean_absolute_error: 0.8979 - val_mean_squared_error: 1.3762\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2713 - mean_absolute_error: 0.8761 - mean_squared_error: 1.2713 - val_loss: 1.3721 - val_mean_absolute_error: 0.8967 - val_mean_squared_error: 1.3721\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2676 - mean_absolute_error: 0.8749 - mean_squared_error: 1.2676 - val_loss: 1.3681 - val_mean_absolute_error: 0.8955 - val_mean_squared_error: 1.3681\n",
      "[OK] Model saved\n",
      "Pred deltas (first row, scaled back): [-0.9990176   0.99998665  0.01510285 -0.99794996 -0.9513734  -0.6316739\n",
      " -0.7061853   0.15839505 -0.99974453  0.98408866 -0.4456656  -0.9819372 ]\n",
      "Saved: out_cards_cn/card_cn_001.png\n",
      "Saved: out_cards_cn/card_cn_002.png\n"
     ]
    }
   ],
   "source": [
    "# =================== 渲染主程式 ===================\n",
    "def main_render():\n",
    "    xls = pd.ExcelFile(EXCEL_PATH)\n",
    "    df_user = pd.read_excel(xls, sheet_name=SHEET_USER)\n",
    "    df_img  = pd.read_excel(xls, sheet_name=SHEET_IMG)\n",
    "    df_icon = pd.read_excel(xls, sheet_name=SHEET_ICON)\n",
    "\n",
    "    # 建查表\n",
    "    img_lookup  = {_norm_key(r[SKU_IMG_SKU_COL]): str(r[SKU_IMG_LINK_COL]).strip() for _, r in df_img.iterrows()}\n",
    "    icon_lookup = {_norm_key(r[SKU_ICON_NAME_COL]): str(r[SKU_ICON_LINK_COL]).strip() for _, r in df_icon.iterrows()}\n",
    "\n",
    "    # 載入模板與模型\n",
    "    template_rgba, init_cfg = load_template_and_boxes()\n",
    "    W, H = init_cfg[\"canvas\"][\"width\"], init_cfg[\"canvas\"][\"height\"]\n",
    "    INIT_BOXES = init_cfg[\"boxes\"]\n",
    "\n",
    "    # [FIX] 讀回訓練時類別順序，並檢查集合一致\n",
    "    if CLASS_ORDER_FILE.exists():\n",
    "        train_classes = json.load(open(CLASS_ORDER_FILE, \"r\", encoding=\"utf-8\"))\n",
    "        if set(train_classes) != set(INIT_BOXES.keys()):\n",
    "            raise ValueError(f\"Classes mismatch.\\nTrain: {train_classes}\\nInfer: {list(INIT_BOXES.keys())}\")\n",
    "        CLASSES = train_classes[:]\n",
    "    else:\n",
    "        CLASSES = list(INIT_BOXES.keys())\n",
    "\n",
    "    model, scaler = load_model_and_scaler()\n",
    "\n",
    "    # 逐列生成\n",
    "    for idx, row in df_user.iterrows():\n",
    "        sku_key  = _norm_key(row.get(COL_PRODUCT_SKU, \"\"))\n",
    "        icon_key = _norm_key(row.get(COL_ICON_NAME, \"\"))\n",
    "        prod_img_path = img_lookup.get(sku_key, \"\")\n",
    "        icon_img_path = icon_lookup.get(icon_key, \"\")\n",
    "\n",
    "        # 特徵 → DataFrame 給 scaler（避免 sklearn warning）\n",
    "        feats = build_features_from_row(row, resolved_icon_path=icon_img_path)\n",
    "        X_df = pd.DataFrame([feats], columns=FEATURE_ORDER).astype(float)  # [FIX]\n",
    "        X_in = scaler.transform(X_df) if scaler is not None else X_df.values\n",
    "\n",
    "        # baseline offsets (全 0)\n",
    "        deltas_base = {cls: [0.0,0.0,0.0,0.0] for cls in CLASSES}\n",
    "\n",
    "        # 預測 offsets（tanh 輸出需乘回 label scaling）\n",
    "        if USE_MODEL and model is not None:\n",
    "            pred = model.predict(X_in, verbose=0)[0]\n",
    "            deltas_pred = {}\n",
    "            for i, cls in enumerate(CLASSES):\n",
    "                dx = float(pred[i*4+0]) * DX_DY_SCALE\n",
    "                dy = float(pred[i*4+1]) * DX_DY_SCALE\n",
    "                dw = float(pred[i*4+2]) * DLOG_SCALE\n",
    "                dh = float(pred[i*4+3]) * DLOG_SCALE\n",
    "                deltas_pred[cls] = [dx,dy,dw,dh]\n",
    "        else:\n",
    "            deltas_pred = deltas_base\n",
    "\n",
    "        if idx == 0 and PRINT_FIRST_PRED and USE_MODEL and (model is not None):  # [FIX]\n",
    "            print(\"Pred deltas (first row, scaled back):\", pred[:min(12, len(pred))])\n",
    "\n",
    "        # blend baseline 與 model\n",
    "        deltas_final = {}\n",
    "        for cls in CLASSES:\n",
    "            db = deltas_base[cls]; dp = deltas_pred[cls]\n",
    "            deltas_final[cls] = [(1-BLEND)*db[i] + BLEND*dp[i] for i in range(4)]\n",
    "\n",
    "        final_boxes = {cls: apply_offset(INIT_BOXES[cls], deltas_final[cls], W, H) for cls in CLASSES}\n",
    "\n",
    "        # 繪圖\n",
    "        canvas = template_rgba.copy()\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "        paste_image_into_box(canvas, prod_img_path, final_boxes[\"Product Image Position\"])\n",
    "        paste_image_into_box(canvas, icon_img_path,  final_boxes[\"Icon Position\"])\n",
    "\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Brand Position\"], \"\"),          final_boxes[\"Brand Position\"],          font_path=FONT_BOLD_PATH,   max_font=72)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Product Position\"], \"\"),        final_boxes[\"Product Position\"],        font_path=FONT_REGULAR_PATH,max_font=64)\n",
    "        fab_text = str(row.get(MAP_TEXT[\"FAB Position\"], \"\") or \"\").replace(\";\", \"\\n\")\n",
    "        draw_text_in_box(draw, fab_text,                                        final_boxes[\"FAB Position\"],            font_path=FONT_REGULAR_PATH,max_font=44)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"VIP Price Position\"], \"\"),      final_boxes[\"VIP Price Position\"],      font_path=FONT_BOLD_PATH,   max_font=100)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Non VIP Price Position\"], \"\"),  final_boxes[\"Non VIP Price Position\"],  font_path=FONT_REGULAR_PATH,max_font=36)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Original Price Position\"], \"\"), final_boxes[\"Original Price Position\"], font_path=FONT_REGULAR_PATH,max_font=32)\n",
    "        draw_text_in_box(draw, row.get(MAP_TEXT[\"Sales Period Position\"], \"\"),   final_boxes[\"Sales Period Position\"],   font_path=FONT_REGULAR_PATH,max_font=28, align=\"right\")\n",
    "\n",
    "        if DRAW_DEBUG_BOXES:\n",
    "            for cls, box in final_boxes.items():\n",
    "                _stroke(draw, box, (255,0,0,180), 2)\n",
    "\n",
    "        out_path = OUTPUT_DIR / f\"card_cn_{idx+1:03d}.png\"\n",
    "        canvas.convert(\"RGB\").save(out_path, quality=95)\n",
    "        print(\"Saved:\", out_path)\n",
    "\n",
    "# =================== 主程式 ===================\n",
    "if __name__ == \"__main__\":\n",
    "    run_preprocess(Path(\"Objects_positions.json\"), Path(INITIAL_BOXES_PATH), Path(OUT_CSV), meta_csv=None)\n",
    "    train_model()\n",
    "    main_render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boardclick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
